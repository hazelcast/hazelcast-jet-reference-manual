<!DOCTYPE html>
<!--[if lt IE 7]>       <html class="no-js ie6 oldie" lang="en"> <![endif]-->
<!--[if IE 7]>          <html class="no-js ie7 oldie" lang="en"> <![endif]-->
<!--[if IE 8]>          <html class="no-js ie8 oldie" lang="en"> <![endif]-->
<!--[if gt IE 8]><!-->  <html class="no-js" lang="en"> <!--<![endif]-->
<head>
    <title>Translating to Jet DAG - Hazelcast Jet Reference Manual</title>
    <meta name="description" content="Hazelcast Jet Reference Manual" />
    <meta name="author" content="Hazelcast">
    <meta charset="UTF-8">
    <link rel="icon" href="../../themes/daux/img/favicon.png" type="image/x-icon">
    <!-- Mobile -->
    <meta name="apple-mobile-web-app-capable" content="yes" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <!-- Font -->
    <link href='https://fonts.googleapis.com/css?family=Roboto+Slab:400,100,300,700&subset=latin,cyrillic-ext,cyrillic' rel='stylesheet' type='text/css'>
    <!-- CSS -->
    <link href='../../themes/daux/css/theme-blue.min.css' rel='stylesheet' type='text/css'>
            <!-- Tipue Search -->
        <link href="../../tipuesearch/tipuesearch.css" rel="stylesheet">
    
    <!--[if lt IE 9]>
    <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
</head>
<body class="">
    
<header class="Navbar hidden-print">
    <div>
      <div class="sitebar"></div>
        <div>  
          <div style="float:left">
            <a href="http://jet.hazelcast.org/"><img src="logo.png" style="padding-bottom:8px;"/></a>
          </div>
          <div>
            <a class="Navbar__branda" href="../../index.html">Reference Manual <span style="font-size:14px">for release 0.3.1</span></a>
          </div>
        </div>
    <div class="Search">
        <svg class="Search__icon" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 451 451"><path d="M447.05 428l-109.6-109.6c29.4-33.8 47.2-77.9 47.2-126.1C384.65 86.2 298.35 0 192.35 0 86.25 0 .05 86.3.05 192.3s86.3 192.3 192.3 192.3c48.2 0 92.3-17.8 126.1-47.2L428.05 447c2.6 2.6 6.1 4 9.5 4s6.9-1.3 9.5-4c5.2-5.2 5.2-13.8 0-19zM26.95 192.3c0-91.2 74.2-165.3 165.3-165.3 91.2 0 165.3 74.2 165.3 165.3s-74.1 165.4-165.3 165.4c-91.1 0-165.3-74.2-165.3-165.4z"/></svg>
        <input type="search" id="tipue_search_input" class="Search__field" placeholder="Search..." autocomplete="on" results=25 autosave=text_search>
    </div>


</div></header>
<div class="Columns content">
    <aside class="Columns__left Collapsible">
        <div class="Collapsible__container">
            <button type="button" class="Button Collapsible__trigger">
                <span class="Collapsible__trigger--bar"></span>
                <span class="Collapsible__trigger--bar"></span>
                <span class="Collapsible__trigger--bar"></span>
            </button>
        </div>

        <div class="Collapsible__content">
            <!-- Navigation -->
            <ul class='Nav'><li class='Nav__item '><a href="../../Preface.html">Preface</a></li><li class='Nav__item  has-children'><a href="../../Introduction/index.html" class="folder"><i class="Nav__arrow">&nbsp;</i>Introduction</a><ul class='Nav'><li class='Nav__item '><a href="../../Introduction/Data_Processing_Model.html">Data Processing Model</a></li><li class='Nav__item '><a href="../../Introduction/Clustering_and_Discovery.html">Clustering and Discovery</a></li><li class='Nav__item '><a href="../../Introduction/Members_and_Clients.html">Members and Clients</a></li><li class='Nav__item '><a href="../../Introduction/Relationship_with_Hazelcast_IMDG.html">Relationship with Hazelcast IMDG</a></li><li class='Nav__item '><a href="../../Introduction/Fault_Detection.html">Fault Detection</a></li><li class='Nav__item '><a href="../../Introduction/Elasticity.html">Elasticity</a></li></ul></li><li class='Nav__item '><a href="../../Getting_Started.html">Getting Started</a></li><li class='Nav__item  has-children'><a href="../../Hazelcast_Jet_101_-Word_Counting_Batch_Job/index.html" class="folder"><i class="Nav__arrow">&nbsp;</i>Hazelcast Jet 101 -Word Counting Batch Job</a><ul class='Nav'><li class='Nav__item '><a href="../../Hazelcast_Jet_101_-Word_Counting_Batch_Job/Modeling_Word_Count_in_terms_of_a_DAG.html">Modeling Word Count in terms of a DAG</a></li><li class='Nav__item '><a href="../../Hazelcast_Jet_101_-Word_Counting_Batch_Job/Implementing_And_Running_the_DAG.html">Implementing And Running the DAG</a></li></ul></li><li class='Nav__item  has-children'><a href="../../Understanding_Jet_Architecture_and_API/index.html" class="folder"><i class="Nav__arrow">&nbsp;</i>Understanding Jet Architecture and API</a><ul class='Nav'><li class='Nav__item '><a href="../../Understanding_Jet_Architecture_and_API/DAG.html">DAG</a></li><li class='Nav__item '><a href="../../Understanding_Jet_Architecture_and_API/Job.html">Job</a></li><li class='Nav__item '><a href="../../Understanding_Jet_Architecture_and_API/Vertex.html">Vertex</a></li><li class='Nav__item  has-children'><a href="../../Understanding_Jet_Architecture_and_API/Processor/index.html" class="folder"><i class="Nav__arrow">&nbsp;</i>Processor</a><ul class='Nav'><li class='Nav__item '><a href="../../Understanding_Jet_Architecture_and_API/Processor/Cooperative_Multithreading.html">Cooperative Multithreading</a></li><li class='Nav__item '><a href="../../Understanding_Jet_Architecture_and_API/Processor/Outbox.html">Outbox</a></li><li class='Nav__item '><a href="../../Understanding_Jet_Architecture_and_API/Processor/Data-Processing_Callbacks.html">Data-Processing Callbacks</a></li></ul></li><li class='Nav__item '><a href="../../Understanding_Jet_Architecture_and_API/Creating_and_Initializing_Jobs.html">Creating and Initializing Jobs</a></li><li class='Nav__item  has-children'><a href="../../Understanding_Jet_Architecture_and_API/Convenience_API_to_Implement_a_Processor/AbstractProcessor.html" class="folder"><i class="Nav__arrow">&nbsp;</i>Convenience API to Implement a Processor</a><ul class='Nav'><li class='Nav__item '><a href="../../Understanding_Jet_Architecture_and_API/Convenience_API_to_Implement_a_Processor/AbstractProcessor.html">AbstractProcessor</a></li><li class='Nav__item '><a href="../../Understanding_Jet_Architecture_and_API/Convenience_API_to_Implement_a_Processor/Traverser.html">Traverser</a></li><li class='Nav__item '><a href="../../Understanding_Jet_Architecture_and_API/Convenience_API_to_Implement_a_Processor/Simple_Example.html">Simple Example</a></li><li class='Nav__item '><a href="../../Understanding_Jet_Architecture_and_API/Convenience_API_to_Implement_a_Processor/Processor_Utility_Class.html">Processor Utility Class</a></li></ul></li><li class='Nav__item  has-children'><a href="../../Understanding_Jet_Architecture_and_API/Edge/index.html" class="folder"><i class="Nav__arrow">&nbsp;</i>Edge</a><ul class='Nav'><li class='Nav__item '><a href="../../Understanding_Jet_Architecture_and_API/Edge/Priority.html">Priority</a></li><li class='Nav__item '><a href="../../Understanding_Jet_Architecture_and_API/Edge/Local_and_Distributed_Edges.html">Local and Distributed Edges</a></li><li class='Nav__item '><a href="../../Understanding_Jet_Architecture_and_API/Edge/Forwarding_Patterns.html">Forwarding Patterns</a></li><li class='Nav__item '><a href="../../Understanding_Jet_Architecture_and_API/Edge/Buffered_Edges.html">Buffered Edges</a></li><li class='Nav__item '><a href="../../Understanding_Jet_Architecture_and_API/Edge/Tuning_Edges.html">Tuning Edges</a></li></ul></li></ul></li><li class='Nav__item Nav__item--open has-children'><a href="../../Advanced_Tutorial_-_Inverted_TF-IDF_Index/index.html" class="folder"><i class="Nav__arrow">&nbsp;</i>Advanced Tutorial - Inverted TF-IDF Index</a><ul class='Nav'><li class='Nav__item '><a href="../../Advanced_Tutorial_-_Inverted_TF-IDF_Index/Building_Inverted_Index_with_Java_Streams.html">Building Inverted Index with Java Streams</a></li><li class='Nav__item Nav__item--open'><a href="../../Advanced_Tutorial_-_Inverted_TF-IDF_Index/Translating_to_Jet_DAG/index.html" class="folder"><i class="Nav__arrow">&nbsp;</i>Translating to Jet DAG</a><ul class='Nav'></ul></li></ul></li><li class='Nav__item  has-children'><a href="../../Understanding_Configuration/index.html" class="folder"><i class="Nav__arrow">&nbsp;</i>Understanding Configuration</a><ul class='Nav'><li class='Nav__item '><a href="../../Understanding_Configuration/Configuring_Programatically.html">Configuring Programatically</a></li><li class='Nav__item '><a href="../../Understanding_Configuration/Configuring_Declaratively.html">Configuring Declaratively</a></li><li class='Nav__item '><a href="../../Understanding_Configuration/Configuring_Underlying_Hazelcast_Instance.html">Configuring Underlying Hazelcast Instance</a></li></ul></li><li class='Nav__item  has-children'><a href="../../Implementing_Custom_Sources_and_Sinks/index.html" class="folder"><i class="Nav__arrow">&nbsp;</i>Implementing Custom Sources and Sinks</a><ul class='Nav'><li class='Nav__item '><a href="../../Implementing_Custom_Sources_and_Sinks/Sources.html">Sources</a></li><li class='Nav__item '><a href="../../Implementing_Custom_Sources_and_Sinks/Example_-_Distributed_Integer_Generator.html">Example - Distributed Integer Generator</a></li><li class='Nav__item '><a href="../../Implementing_Custom_Sources_and_Sinks/Sinks.html">Sinks</a></li><li class='Nav__item '><a href="../../Implementing_Custom_Sources_and_Sinks/Example_-_File_Writer.html">Example - File Writer</a></li></ul></li><li class='Nav__item  has-children'><a href="../../java-util-stream_Support_for_Hazelcast_IMDG/index.html" class="folder"><i class="Nav__arrow">&nbsp;</i>java-util-stream Support for Hazelcast IMDG</a><ul class='Nav'><li class='Nav__item '><a href="../../java-util-stream_Support_for_Hazelcast_IMDG/Simple_Example.html">Simple Example</a></li><li class='Nav__item '><a href="../../java-util-stream_Support_for_Hazelcast_IMDG/Serializable_Lambda_Functions.html">Serializable Lambda Functions</a></li><li class='Nav__item '><a href="../../java-util-stream_Support_for_Hazelcast_IMDG/Distributed_Collectors.html">Distributed Collectors</a></li><li class='Nav__item '><a href="../../java-util-stream_Support_for_Hazelcast_IMDG/Word_Count.html">Word Count</a></li><li class='Nav__item '><a href="../../java-util-stream_Support_for_Hazelcast_IMDG/Implementation_Notes.html">Implementation Notes</a></li></ul></li><li class='Nav__item  has-children'><a href="../../Additional_Modules/index.html" class="folder"><i class="Nav__arrow">&nbsp;</i>Additional Modules</a><ul class='Nav'><li class='Nav__item  has-children'><a href="../../Additional_Modules/hazelcast-jet-hadoop/index.html" class="folder"><i class="Nav__arrow">&nbsp;</i>hazelcast-jet-hadoop</a><ul class='Nav'><li class='Nav__item '><a href="../../Additional_Modules/hazelcast-jet-hadoop/ReadHdfsP.html">ReadHdfsP</a></li><li class='Nav__item '><a href="../../Additional_Modules/hazelcast-jet-hadoop/WriteHdfsP.html">WriteHdfsP</a></li><li class='Nav__item '><a href="../../Additional_Modules/hazelcast-jet-hadoop/Serialization_of_Writables.html">Serialization of Writables</a></li></ul></li><li class='Nav__item  has-children'><a href="../../Additional_Modules/hazelcast-jet-kafka/index.html" class="folder"><i class="Nav__arrow">&nbsp;</i>hazelcast-jet-kafka</a><ul class='Nav'><li class='Nav__item '><a href="../../Additional_Modules/hazelcast-jet-kafka/StreamKafkaP.html">StreamKafkaP</a></li><li class='Nav__item '><a href="../../Additional_Modules/hazelcast-jet-kafka/WriteKafkaP.html">WriteKafkaP</a></li></ul></li></ul></li><li class='Nav__item  has-children'><a href="../../Best_Practices/index.html" class="folder"><i class="Nav__arrow">&nbsp;</i>Best Practices</a><ul class='Nav'><li class='Nav__item '><a href="../../Best_Practices/Jobs.html">Jobs</a></li></ul></li></ul>

            <div class="Links">
                                    <hr/>
                                            <a href="https://github.com/hazelcast/hazelcast-jet" target="_blank">GitHub Repo</a>
                        <br />
                                            <a href="https://github.com/hazelcast/hazelcast-jet/issues/new" target="_blank">Send Us a Fix</a>
                        <br />
                                            <a href="http://jet.hazelcast.org/documentation/" target="_blank">Go to Jet documentation</a>
                        <br />
                                    
                                    <div class="CodeToggler">
                        <hr/>
                                                    <a class="CodeToggler__button CodeToggler__button--main" href="#">Show Code Blocks Inline</a><br>
                                            </div>
                
                            </div>
        </div>
    </aside>
    <div class="Columns__right ">
        <div class="Columns__right__content">
            <div class="doc_content">
                <article class="Page">

    <div class="Page__header">
        <h1><a href="../../Advanced_Tutorial_-_Inverted_TF-IDF_Index/index.html">Advanced Tutorial - Inverted TF-IDF Index</a> <svg class="Page__header--separator" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 477.175 477.175"><path d="M360.73 229.075l-225.1-225.1c-5.3-5.3-13.8-5.3-19.1 0s-5.3 13.8 0 19.1l215.5 215.5-215.5 215.5c-5.3 5.3-5.3 13.8 0 19.1 2.6 2.6 6.1 4 9.5 4 3.4 0 6.9-1.3 9.5-4l225.1-225.1c5.3-5.2 5.3-13.8.1-19z"/></svg> <a href="../../Advanced_Tutorial_-_Inverted_TF-IDF_Index/Translating_to_Jet_DAG/index.html">Translating to Jet DAG</a></h1>
                    </div>


    <div class="s-content">
        <p>The general outline of most DAGs is a cascade of vertices starting from
a source and ending in a sink. Each grouping operation will typically be
done in its own vertex. We have two such operations: the first one
prepares the TF map and the second one builds the inverted index.</p>
<p>Flatmap-like operations (this also encompasses <em>map</em> and <em>filter</em> as
special cases) are simple to  distribute because they operate on each
item independently. Such an operation can be attached to the work of an
existing vertex; however concerns like blocking I/O and load balancing
encourage the use of dedicated flatmapping vertices. In our case we'll
have one flatmapping vertex that transforms a filename into a stream of
the file's lines and another one that tokenizes a line into a stream of
its words. The file-reading vertex will have to use <em>non-cooperative</em>
processors due to the blocking I/O and while a processor is blocking to
read more lines, the tokenizing processors can run at full speed,
processing the lines already read.</p>
<p>This is the outline of the DAG's &quot;backbone&quot; --- the main cascade where
the data flows from the source to the sink:</p>
<ol>
<li>The data source is a Hazelcast <code>IMap</code> which holds a mapping from
document ID to its filename. The source vertex will emit all the map's
entries, but only a subset on each cluster member.</li>
<li>
<code>doc-lines</code> opens each file named by the map entry and emits all its
lines in the <code>(docId, line)</code> format.</li>
<li>
<code>tokenize</code> transforms each line into a sequence of its words, again
paired with the document ID: <code>(docId, word)</code>.</li>
<li>
<code>tf</code> builds a set of all distinct tuples and maintains the count
of each tuple's occurrences (its TF score).</li>
<li>
<code>tf-idf</code> takes that set, groups the tuples by word, and calculates
the TF-IDF scores. It emits the results to the sink, which saves them
to a distributed <code>IMap</code>.</li>
</ol>
<p>To this cascade we add a <code>stopword-source</code> which reads the stopwords
file, parses it into a <code>HashSet</code>, and sends the whole set as a single
item to the <code>tokenize</code> vertex. We also add a vertex that takes the data
from <code>doc-source</code> and simply counts its items; this is the total
document count used in the TF-IDF formula. It feeds this result into
<code>tf-idf</code>. We end up with this DAG:</p>
<pre><code>            ------------              -----------------
           | doc-source |            | stopword-source |
            ------------              -----------------
         0  /           \ 1                   |
           /       (docId, docName)           |
          /                \                  |
         /                  V         (set-of-stopwords)
 (docId, docName)         -----------         |
        |                | doc-lines |        |
        |                 -----------         |
        |                     |               |
        |                (docId, line)        |
   -----------                |               |
  | doc-count |               V  1            |
   -----------            ----------    0     |
        |                | tokenize | &lt;------/
        |                 ----------
        |                     |
     (count)            (docId, word)
        |                     |
        |                     V
        |                   ----
        |                  | tf |
        |                   ----
        |                     |
        |           ((docId, word), count)
        |                     |
        | 0    --------    1  |
         \--&gt; | tf-idf | &lt;---/
               --------
                  |
   (word, list(docId, tfidf-score)
                  |
                  V
               ------
              | sink |
               ------
</code></pre>
<p>The source vertex reads a Hazelcast IMap so we just use the processor
provided in Jet:</p>
<pre><code class="language-java">dag.newVertex(&quot;doc-source&quot;, Processors.readMap(DOCID_NAME));
</code></pre>
<p>The stopwords-producing vertex has a custom processor:</p>
<pre><code class="language-java">dag.newVertex(&quot;stopword-source&quot;, StopwordsP::new);
</code></pre>
<p>The processor's implementation is quite simple:</p>
<pre><code class="language-java">private static class StopwordsP extends AbstractProcessor {
    @Override
    public boolean complete() {
        emit(docLines(&quot;stopwords.txt&quot;).collect(toSet()));
        return true;
    }
}
</code></pre>
<p>It emits a single item: the <code>HashSet</code> built directly from the stream
of a text file's lines.</p>
<p>The <code>doc-count</code> processor can again be built from the primitives
provided in the Jet's library:</p>
<pre><code class="language-java">dag.newVertex(&quot;doc-count&quot;, Processors.accumulate(() -&gt; 0L, (count, x) -&gt; count + 1));
</code></pre>
<p>The <code>doc-lines</code> processor is more of a mouthful, but still built from
existing primitives:</p>
<pre><code class="language-java">dag.newVertex(&quot;doc-lines&quot;,
    nonCooperative(
        Processors.flatMap((Entry&lt;Long, String&gt; e) -&gt;
            traverseStream(docLines(&quot;books/&quot; + e.getValue())
                           .map(line -&gt; entry(e.getKey(), line))))));
</code></pre>
<p>Let's break down this expression... <code>Processors.flatMap</code> returns a
standard processor that emits an arbitrary number of items for each
received item. The user supplies a function of the shape <code>inputItem -&gt; Traverser(outputItems)</code> and the processor takes care of all the logic
required to cooperatively emit those items while respecting the output
buffer limits.</p>
<p>This is the user-supplied expression evaluated for each incoming item:</p>
<pre><code class="language-java">traverseStream(docLines(&quot;books/&quot; + e.getValue())
               .map(line -&gt; entry(e.getKey(), line))))
</code></pre>
<p><code>traverseStream</code> converts a <code>java.util.Stream</code> to <code>Traverser</code> so the
inner part builds the stream: <code>docLines()</code> simply  returns</p>
<pre><code class="language-java">Files.lines(Paths.get(TfIdf.class.getResource(name).toURI()))
</code></pre>
<p>and then the mapping stage is applied, which creates a pair <code>(docId, line)</code>. Finally, the whole processor expression is wrapped into a call
of <code>nonCooperative()</code> which will declare the processor non-cooperative,
as required by the fact that it does blocking file I/O.</p>
<p><code>tokenizer</code> is another custom vertex:</p>
<pre><code class="language-java">dag.newVertex(&quot;tokenize&quot;, TokenizeP::new);

private static class TokenizeP extends AbstractProcessor {
    private Set&lt;String&gt; stopwords;
    private final FlatMapper&lt;Entry&lt;Long, String&gt;, Entry&lt;Long, String&gt;&gt; flatMapper =
        flatMapper(e -&gt; traverseStream(
                   Arrays.stream(DELIMITER.split(e.getValue()))
                         .filter(word -&gt; !stopwords.contains(word))
                         .map(word -&gt; entry(e.getKey(), word))));

    @Override
    protected boolean tryProcess0(@Nonnull Object item) {
        stopwords = (Set&lt;String&gt;) item;
        return true;
    }

    @Override
    protected boolean tryProcess1(@Nonnull Object item) {
        return flatMapper.tryProcess((Entry&lt;Long, String&gt;) item);
    }
}
</code></pre>
<p>This is a processor that must deal with two different inbound edges. It
receives the stopword set over edge 0 and then it does a flatmapping
operation on edge 1. The logic presented here uses the same approach as
the implementation of the provided <code>Processors.flatMap()</code> processor:
there is a single instance of <code>FlatMapper</code> that holds the business logic
of the transformation, and the <code>tryProcess1()</code> callback method directly
delegates into it. If <code>FlatMapper</code> is done emitting the previous items,
it will accept the new item, apply the user-provided transformation, and
start emitting the output items. If the buffer state prevents it from
emitting all the pending items, it will return <code>false</code>, which will make
the framework call the same <code>tryProcess1</code> method later, with the same
input item.</p>
<p>Let's show the code that creates the <code>tokenize</code>'s two inbound edges:</p>
<pre><code class="language-java">dag.edge(between(stopwordSource, tokenize).broadcast().priority(-1))
   .edge(from(docLines).to(tokenize, 1));
</code></pre>
<p>Especially note the <code>.priority(-1)</code> part: this ensures that there will
be no attempt to deliver any data coming from <code>docLines</code> before all the
data from <code>stopwordSource</code> is already delivered. The processor would
fail if it had to tokenize a line before it has its stopword set in
place.</p>
<p><code>tf</code> is another simple vertex, built purely from the provided
primitives:</p>
<pre><code class="language-java">dag.newVertex(&quot;tf&quot;, groupAndAccumulate(() -&gt; 0L, (count, x) -&gt; count + 1));
</code></pre>
<p><code>tf-idf</code> is the most complex processor:</p>
<pre><code class="language-java">dag.newVertex(&quot;tf-idf&quot;, TfIdfP::new);

private static class TfIdfP extends AbstractProcessor {
    private double logDocCount;

    private final Map&lt;String, List&lt;Entry&lt;Long, Double&gt;&gt;&gt; wordDocTf = new HashMap&lt;&gt;();
    private final Traverser&lt;Entry&lt;String, List&lt;Entry&lt;Long, Double&gt;&gt;&gt;&gt; invertedIndexTraverser =
            lazy(() -&gt; traverseIterable(wordDocTf.entrySet()).map(this::toInvertedIndexEntry));

    @Override
    protected boolean tryProcess0(@Nonnull Object item) throws Exception {
        logDocCount = Math.log((Long) item);
        return true;
    }

    @Override
    protected boolean tryProcess1(@Nonnull Object item) throws Exception {
        final Entry&lt;Entry&lt;Long, String&gt;, Long&gt; e = (Entry&lt;Entry&lt;Long, String&gt;, Long&gt;) item;
        final long docId = e.getKey().getKey();
        final String word = e.getKey().getValue();
        final long tf = e.getValue();
        wordDocTf.computeIfAbsent(word, w -&gt; new ArrayList&lt;&gt;())
                 .add(entry(docId, (double) tf));
        return true;
    }

    @Override
    public boolean complete() {
        return emitCooperatively(invertedIndexTraverser);
    }

    private Entry&lt;String, List&lt;Entry&lt;Long, Double&gt;&gt;&gt; toInvertedIndexEntry(
            Entry&lt;String, List&lt;Entry&lt;Long, Double&gt;&gt;&gt; wordDocTf
    ) {
        final String word = wordDocTf.getKey();
        final List&lt;Entry&lt;Long, Double&gt;&gt; docidTfs = wordDocTf.getValue();
        return entry(word, docScores(docidTfs));
    }

    private List&lt;Entry&lt;Long, Double&gt;&gt; docScores(List&lt;Entry&lt;Long, Double&gt;&gt; docidTfs) {
        final double logDf = Math.log(docidTfs.size());
        return docidTfs.stream()
                       .map(tfe -&gt; tfidfEntry(logDf, tfe))
                       .collect(toList());
    }

    private Entry&lt;Long, Double&gt; tfidfEntry(double logDf, Entry&lt;Long, Double&gt; docidTf) {
        final Long docId = docidTf.getKey();
        final double tf = docidTf.getValue();
        final double idf = logDocCount - logDf;
        return entry(docId, tf * idf);
    }
}
</code></pre>
<p>This is quite a lot of code, but each of the three pieces is not too
difficult to follow:</p>
<ol>
<li>
<code>tryProcess0()</code> accepts a single item, the total document count.</li>
<li>
<code>tryProcess1()</code> performs a boilerplate <code>groupBy</code> operation,
collecting a list of items under each key.</li>
<li>
<code>complete()</code> outputs the accumulated results, also applying the
final transformation on each one: replacing the TF score with the final
TF-IDF score. It relies on a <em>lazy</em> traverser, which holds a
<code>Supplier&lt;Traverser&gt;</code> and will obtain the inner traverser from it the
first time <code>next()</code> is called. This makes it very simple to write code
that obtains a traverser from a map after it has been populated.</li>
</ol>
<p>Finally, our DAG is terminated by a sink vertex:</p>
<pre><code class="language-java">dag.newVertex(&quot;sink&quot;, Processors.writeMap(INVERTED_INDEX));
</code></pre>
    </div>

        <nav>
        <ul class="Pager">
            <li class=Pager--prev><a href="../../Advanced_Tutorial_-_Inverted_TF-IDF_Index/Building_Inverted_Index_with_Java_Streams.html">Previous</a></li>            <li class=Pager--next><a href="../../Understanding_Configuration/index.html">Next</a></li>        </ul>
    </nav>
    </article>

            </div>
        </div>
    </div>
</div>

    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-12653604-10', '');
    ga('send', 'pageview');
</script>

    <!-- jQuery -->
    <script src="../../themes/daux/js/jquery-1.11.3.min.js"></script>

    <!-- hightlight.js -->
    <script src="../../themes/daux/js/highlight.pack.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>

    <!-- JS -->
    
    <script src="../../themes/daux/js/daux.js"></script>

            <!-- Tipue Search -->
        <script type="text/javascript" src="../../tipuesearch/tipuesearch.js"></script>

        <script>
            window.onunload = function(){}; // force $(document).ready to be called on back/forward navigation in firefox
            $(function() {
                tipuesearch({
                    'base_url': '../../'
                });
            });
        </script>
    
</body>
</html>
