<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<!--[if IE]><meta http-equiv="X-UA-Compatible" content="IE=edge"><![endif]-->
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Asciidoctor 1.5.3">
<title>Under the Hood</title>
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700">
<style>
/* Asciidoctor default stylesheet | MIT License | http://asciidoctor.org */
/* Remove comment around @import statement below when using as a custom stylesheet */
/*@import "https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700";*/
article,aside,details,figcaption,figure,footer,header,hgroup,main,nav,section,summary{display:block}
audio,canvas,video{display:inline-block}
audio:not([controls]){display:none;height:0}
[hidden],template{display:none}
script{display:none!important}
html{font-family:sans-serif;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}
body{margin:0}
a{background:transparent}
a:focus{outline:thin dotted}
a:active,a:hover{outline:0}
h1{font-size:2em;margin:.67em 0}
abbr[title]{border-bottom:1px dotted}
b,strong{font-weight:bold}
dfn{font-style:italic}
hr{-moz-box-sizing:content-box;box-sizing:content-box;height:0}
mark{background:#ff0;color:#000}
code,kbd,pre,samp{font-family:monospace;font-size:1em}
pre{white-space:pre-wrap}
q{quotes:"\201C" "\201D" "\2018" "\2019"}
small{font-size:80%}
sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}
sup{top:-.5em}
sub{bottom:-.25em}
img{border:0}
svg:not(:root){overflow:hidden}
figure{margin:0}
fieldset{border:1px solid silver;margin:0 2px;padding:.35em .625em .75em}
legend{border:0;padding:0}
button,input,select,textarea{font-family:inherit;font-size:100%;margin:0}
button,input{line-height:normal}
button,select{text-transform:none}
button,html input[type="button"],input[type="reset"],input[type="submit"]{-webkit-appearance:button;cursor:pointer}
button[disabled],html input[disabled]{cursor:default}
input[type="checkbox"],input[type="radio"]{box-sizing:border-box;padding:0}
input[type="search"]{-webkit-appearance:textfield;-moz-box-sizing:content-box;-webkit-box-sizing:content-box;box-sizing:content-box}
input[type="search"]::-webkit-search-cancel-button,input[type="search"]::-webkit-search-decoration{-webkit-appearance:none}
button::-moz-focus-inner,input::-moz-focus-inner{border:0;padding:0}
textarea{overflow:auto;vertical-align:top}
table{border-collapse:collapse;border-spacing:0}
*,*:before,*:after{-moz-box-sizing:border-box;-webkit-box-sizing:border-box;box-sizing:border-box}
html,body{font-size:100%}
body{background:#fff;color:rgba(0,0,0,.8);padding:0;margin:0;font-family:"Noto Serif","DejaVu Serif",serif;font-weight:400;font-style:normal;line-height:1;position:relative;cursor:auto}
a:hover{cursor:pointer}
img,object,embed{max-width:100%;height:auto}
object,embed{height:100%}
img{-ms-interpolation-mode:bicubic}
.left{float:left!important}
.right{float:right!important}
.text-left{text-align:left!important}
.text-right{text-align:right!important}
.text-center{text-align:center!important}
.text-justify{text-align:justify!important}
.hide{display:none}
body{-webkit-font-smoothing:antialiased}
img,object,svg{display:inline-block;vertical-align:middle}
textarea{height:auto;min-height:50px}
select{width:100%}
.center{margin-left:auto;margin-right:auto}
.spread{width:100%}
p.lead,.paragraph.lead>p,#preamble>.sectionbody>.paragraph:first-of-type p{font-size:1.21875em;line-height:1.6}
.subheader,.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{line-height:1.45;color:#7a2518;font-weight:400;margin-top:0;margin-bottom:.25em}
div,dl,dt,dd,ul,ol,li,h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6,pre,form,p,blockquote,th,td{margin:0;padding:0;direction:ltr}
a{color:#2156a5;text-decoration:underline;line-height:inherit}
a:hover,a:focus{color:#1d4b8f}
a img{border:none}
p{font-family:inherit;font-weight:400;font-size:1em;line-height:1.6;margin-bottom:1.25em;text-rendering:optimizeLegibility}
p aside{font-size:.875em;line-height:1.35;font-style:italic}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{font-family:"Open Sans","DejaVu Sans",sans-serif;font-weight:300;font-style:normal;color:#ba3925;text-rendering:optimizeLegibility;margin-top:1em;margin-bottom:.5em;line-height:1.0125em}
h1 small,h2 small,h3 small,#toctitle small,.sidebarblock>.content>.title small,h4 small,h5 small,h6 small{font-size:60%;color:#e99b8f;line-height:0}
h1{font-size:2.125em}
h2{font-size:1.6875em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.375em}
h4,h5{font-size:1.125em}
h6{font-size:1em}
hr{border:solid #ddddd8;border-width:1px 0 0;clear:both;margin:1.25em 0 1.1875em;height:0}
em,i{font-style:italic;line-height:inherit}
strong,b{font-weight:bold;line-height:inherit}
small{font-size:60%;line-height:inherit}
code{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;font-weight:400;color:rgba(0,0,0,.9)}
ul,ol,dl{font-size:1em;line-height:1.6;margin-bottom:1.25em;list-style-position:outside;font-family:inherit}
ul,ol,ul.no-bullet,ol.no-bullet{margin-left:1.5em}
ul li ul,ul li ol{margin-left:1.25em;margin-bottom:0;font-size:1em}
ul.square li ul,ul.circle li ul,ul.disc li ul{list-style:inherit}
ul.square{list-style-type:square}
ul.circle{list-style-type:circle}
ul.disc{list-style-type:disc}
ul.no-bullet{list-style:none}
ol li ul,ol li ol{margin-left:1.25em;margin-bottom:0}
dl dt{margin-bottom:.3125em;font-weight:bold}
dl dd{margin-bottom:1.25em}
abbr,acronym{text-transform:uppercase;font-size:90%;color:rgba(0,0,0,.8);border-bottom:1px dotted #ddd;cursor:help}
abbr{text-transform:none}
blockquote{margin:0 0 1.25em;padding:.5625em 1.25em 0 1.1875em;border-left:1px solid #ddd}
blockquote cite{display:block;font-size:.9375em;color:rgba(0,0,0,.6)}
blockquote cite:before{content:"\2014 \0020"}
blockquote cite a,blockquote cite a:visited{color:rgba(0,0,0,.6)}
blockquote,blockquote p{line-height:1.6;color:rgba(0,0,0,.85)}
@media only screen and (min-width:768px){h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2}
h1{font-size:2.75em}
h2{font-size:2.3125em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.6875em}
h4{font-size:1.4375em}}
table{background:#fff;margin-bottom:1.25em;border:solid 1px #dedede}
table thead,table tfoot{background:#f7f8f7;font-weight:bold}
table thead tr th,table thead tr td,table tfoot tr th,table tfoot tr td{padding:.5em .625em .625em;font-size:inherit;color:rgba(0,0,0,.8);text-align:left}
table tr th,table tr td{padding:.5625em .625em;font-size:inherit;color:rgba(0,0,0,.8)}
table tr.even,table tr.alt,table tr:nth-of-type(even){background:#f8f8f7}
table thead tr th,table tfoot tr th,table tbody tr td,table tr td,table tfoot tr td{display:table-cell;line-height:1.6}
body{tab-size:4}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2;word-spacing:-.05em}
h1 strong,h2 strong,h3 strong,#toctitle strong,.sidebarblock>.content>.title strong,h4 strong,h5 strong,h6 strong{font-weight:400}
.clearfix:before,.clearfix:after,.float-group:before,.float-group:after{content:" ";display:table}
.clearfix:after,.float-group:after{clear:both}
*:not(pre)>code{font-size:.9375em;font-style:normal!important;letter-spacing:0;padding:.1em .5ex;word-spacing:-.15em;background-color:#f7f7f8;-webkit-border-radius:4px;border-radius:4px;line-height:1.45;text-rendering:optimizeSpeed}
pre,pre>code{line-height:1.45;color:rgba(0,0,0,.9);font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;font-weight:400;text-rendering:optimizeSpeed}
.keyseq{color:rgba(51,51,51,.8)}
kbd{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;display:inline-block;color:rgba(0,0,0,.8);font-size:.65em;line-height:1.45;background-color:#f7f7f7;border:1px solid #ccc;-webkit-border-radius:3px;border-radius:3px;-webkit-box-shadow:0 1px 0 rgba(0,0,0,.2),0 0 0 .1em white inset;box-shadow:0 1px 0 rgba(0,0,0,.2),0 0 0 .1em #fff inset;margin:0 .15em;padding:.2em .5em;vertical-align:middle;position:relative;top:-.1em;white-space:nowrap}
.keyseq kbd:first-child{margin-left:0}
.keyseq kbd:last-child{margin-right:0}
.menuseq,.menu{color:rgba(0,0,0,.8)}
b.button:before,b.button:after{position:relative;top:-1px;font-weight:400}
b.button:before{content:"[";padding:0 3px 0 2px}
b.button:after{content:"]";padding:0 2px 0 3px}
p a>code:hover{color:rgba(0,0,0,.9)}
#header,#content,#footnotes,#footer{width:100%;margin-left:auto;margin-right:auto;margin-top:0;margin-bottom:0;max-width:62.5em;*zoom:1;position:relative;padding-left:.9375em;padding-right:.9375em}
#header:before,#header:after,#content:before,#content:after,#footnotes:before,#footnotes:after,#footer:before,#footer:after{content:" ";display:table}
#header:after,#content:after,#footnotes:after,#footer:after{clear:both}
#content{margin-top:1.25em}
#content:before{content:none}
#header>h1:first-child{color:rgba(0,0,0,.85);margin-top:2.25rem;margin-bottom:0}
#header>h1:first-child+#toc{margin-top:8px;border-top:1px solid #ddddd8}
#header>h1:only-child,body.toc2 #header>h1:nth-last-child(2){border-bottom:1px solid #ddddd8;padding-bottom:8px}
#header .details{border-bottom:1px solid #ddddd8;line-height:1.45;padding-top:.25em;padding-bottom:.25em;padding-left:.25em;color:rgba(0,0,0,.6);display:-ms-flexbox;display:-webkit-flex;display:flex;-ms-flex-flow:row wrap;-webkit-flex-flow:row wrap;flex-flow:row wrap}
#header .details span:first-child{margin-left:-.125em}
#header .details span.email a{color:rgba(0,0,0,.85)}
#header .details br{display:none}
#header .details br+span:before{content:"\00a0\2013\00a0"}
#header .details br+span.author:before{content:"\00a0\22c5\00a0";color:rgba(0,0,0,.85)}
#header .details br+span#revremark:before{content:"\00a0|\00a0"}
#header #revnumber{text-transform:capitalize}
#header #revnumber:after{content:"\00a0"}
#content>h1:first-child:not([class]){color:rgba(0,0,0,.85);border-bottom:1px solid #ddddd8;padding-bottom:8px;margin-top:0;padding-top:1rem;margin-bottom:1.25rem}
#toc{border-bottom:1px solid #efefed;padding-bottom:.5em}
#toc>ul{margin-left:.125em}
#toc ul.sectlevel0>li>a{font-style:italic}
#toc ul.sectlevel0 ul.sectlevel1{margin:.5em 0}
#toc ul{font-family:"Open Sans","DejaVu Sans",sans-serif;list-style-type:none}
#toc li{line-height:1.3334;margin-top:.3334em}
#toc a{text-decoration:none}
#toc a:active{text-decoration:underline}
#toctitle{color:#7a2518;font-size:1.2em}
@media only screen and (min-width:768px){#toctitle{font-size:1.375em}
body.toc2{padding-left:15em;padding-right:0}
#toc.toc2{margin-top:0!important;background-color:#f8f8f7;position:fixed;width:15em;left:0;top:0;border-right:1px solid #efefed;border-top-width:0!important;border-bottom-width:0!important;z-index:1000;padding:1.25em 1em;height:100%;overflow:auto}
#toc.toc2 #toctitle{margin-top:0;margin-bottom:.8rem;font-size:1.2em}
#toc.toc2>ul{font-size:.9em;margin-bottom:0}
#toc.toc2 ul ul{margin-left:0;padding-left:1em}
#toc.toc2 ul.sectlevel0 ul.sectlevel1{padding-left:0;margin-top:.5em;margin-bottom:.5em}
body.toc2.toc-right{padding-left:0;padding-right:15em}
body.toc2.toc-right #toc.toc2{border-right-width:0;border-left:1px solid #efefed;left:auto;right:0}}
@media only screen and (min-width:1280px){body.toc2{padding-left:20em;padding-right:0}
#toc.toc2{width:20em}
#toc.toc2 #toctitle{font-size:1.375em}
#toc.toc2>ul{font-size:.95em}
#toc.toc2 ul ul{padding-left:1.25em}
body.toc2.toc-right{padding-left:0;padding-right:20em}}
#content #toc{border-style:solid;border-width:1px;border-color:#e0e0dc;margin-bottom:1.25em;padding:1.25em;background:#f8f8f7;-webkit-border-radius:4px;border-radius:4px}
#content #toc>:first-child{margin-top:0}
#content #toc>:last-child{margin-bottom:0}
#footer{max-width:100%;background-color:rgba(0,0,0,.8);padding:1.25em}
#footer-text{color:rgba(255,255,255,.8);line-height:1.44}
.sect1{padding-bottom:.625em}
@media only screen and (min-width:768px){.sect1{padding-bottom:1.25em}}
.sect1+.sect1{border-top:1px solid #efefed}
#content h1>a.anchor,h2>a.anchor,h3>a.anchor,#toctitle>a.anchor,.sidebarblock>.content>.title>a.anchor,h4>a.anchor,h5>a.anchor,h6>a.anchor{position:absolute;z-index:1001;width:1.5ex;margin-left:-1.5ex;display:block;text-decoration:none!important;visibility:hidden;text-align:center;font-weight:400}
#content h1>a.anchor:before,h2>a.anchor:before,h3>a.anchor:before,#toctitle>a.anchor:before,.sidebarblock>.content>.title>a.anchor:before,h4>a.anchor:before,h5>a.anchor:before,h6>a.anchor:before{content:"\00A7";font-size:.85em;display:block;padding-top:.1em}
#content h1:hover>a.anchor,#content h1>a.anchor:hover,h2:hover>a.anchor,h2>a.anchor:hover,h3:hover>a.anchor,#toctitle:hover>a.anchor,.sidebarblock>.content>.title:hover>a.anchor,h3>a.anchor:hover,#toctitle>a.anchor:hover,.sidebarblock>.content>.title>a.anchor:hover,h4:hover>a.anchor,h4>a.anchor:hover,h5:hover>a.anchor,h5>a.anchor:hover,h6:hover>a.anchor,h6>a.anchor:hover{visibility:visible}
#content h1>a.link,h2>a.link,h3>a.link,#toctitle>a.link,.sidebarblock>.content>.title>a.link,h4>a.link,h5>a.link,h6>a.link{color:#ba3925;text-decoration:none}
#content h1>a.link:hover,h2>a.link:hover,h3>a.link:hover,#toctitle>a.link:hover,.sidebarblock>.content>.title>a.link:hover,h4>a.link:hover,h5>a.link:hover,h6>a.link:hover{color:#a53221}
.audioblock,.imageblock,.literalblock,.listingblock,.stemblock,.videoblock{margin-bottom:1.25em}
.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{text-rendering:optimizeLegibility;text-align:left;font-family:"Noto Serif","DejaVu Serif",serif;font-size:1rem;font-style:italic}
table.tableblock>caption.title{white-space:nowrap;overflow:visible;max-width:0}
.paragraph.lead>p,#preamble>.sectionbody>.paragraph:first-of-type p{color:rgba(0,0,0,.85)}
table.tableblock #preamble>.sectionbody>.paragraph:first-of-type p{font-size:inherit}
.admonitionblock>table{border-collapse:separate;border:0;background:none;width:100%}
.admonitionblock>table td.icon{text-align:center;width:80px}
.admonitionblock>table td.icon img{max-width:none}
.admonitionblock>table td.icon .title{font-weight:bold;font-family:"Open Sans","DejaVu Sans",sans-serif;text-transform:uppercase}
.admonitionblock>table td.content{padding-left:1.125em;padding-right:1.25em;border-left:1px solid #ddddd8;color:rgba(0,0,0,.6)}
.admonitionblock>table td.content>:last-child>:last-child{margin-bottom:0}
.exampleblock>.content{border-style:solid;border-width:1px;border-color:#e6e6e6;margin-bottom:1.25em;padding:1.25em;background:#fff;-webkit-border-radius:4px;border-radius:4px}
.exampleblock>.content>:first-child{margin-top:0}
.exampleblock>.content>:last-child{margin-bottom:0}
.sidebarblock{border-style:solid;border-width:1px;border-color:#e0e0dc;margin-bottom:1.25em;padding:1.25em;background:#f8f8f7;-webkit-border-radius:4px;border-radius:4px}
.sidebarblock>:first-child{margin-top:0}
.sidebarblock>:last-child{margin-bottom:0}
.sidebarblock>.content>.title{color:#7a2518;margin-top:0;text-align:center}
.exampleblock>.content>:last-child>:last-child,.exampleblock>.content .olist>ol>li:last-child>:last-child,.exampleblock>.content .ulist>ul>li:last-child>:last-child,.exampleblock>.content .qlist>ol>li:last-child>:last-child,.sidebarblock>.content>:last-child>:last-child,.sidebarblock>.content .olist>ol>li:last-child>:last-child,.sidebarblock>.content .ulist>ul>li:last-child>:last-child,.sidebarblock>.content .qlist>ol>li:last-child>:last-child{margin-bottom:0}
.literalblock pre,.listingblock pre:not(.highlight),.listingblock pre[class="highlight"],.listingblock pre[class^="highlight "],.listingblock pre.CodeRay,.listingblock pre.prettyprint{background:#f7f7f8}
.sidebarblock .literalblock pre,.sidebarblock .listingblock pre:not(.highlight),.sidebarblock .listingblock pre[class="highlight"],.sidebarblock .listingblock pre[class^="highlight "],.sidebarblock .listingblock pre.CodeRay,.sidebarblock .listingblock pre.prettyprint{background:#f2f1f1}
.literalblock pre,.literalblock pre[class],.listingblock pre,.listingblock pre[class]{-webkit-border-radius:4px;border-radius:4px;word-wrap:break-word;padding:1em;font-size:.8125em}
.literalblock pre.nowrap,.literalblock pre[class].nowrap,.listingblock pre.nowrap,.listingblock pre[class].nowrap{overflow-x:auto;white-space:pre;word-wrap:normal}
@media only screen and (min-width:768px){.literalblock pre,.literalblock pre[class],.listingblock pre,.listingblock pre[class]{font-size:.90625em}}
@media only screen and (min-width:1280px){.literalblock pre,.literalblock pre[class],.listingblock pre,.listingblock pre[class]{font-size:1em}}
.literalblock.output pre{color:#f7f7f8;background-color:rgba(0,0,0,.9)}
.listingblock pre.highlightjs{padding:0}
.listingblock pre.highlightjs>code{padding:1em;-webkit-border-radius:4px;border-radius:4px}
.listingblock pre.prettyprint{border-width:0}
.listingblock>.content{position:relative}
.listingblock code[data-lang]:before{display:none;content:attr(data-lang);position:absolute;font-size:.75em;top:.425rem;right:.5rem;line-height:1;text-transform:uppercase;color:#999}
.listingblock:hover code[data-lang]:before{display:block}
.listingblock.terminal pre .command:before{content:attr(data-prompt);padding-right:.5em;color:#999}
.listingblock.terminal pre .command:not([data-prompt]):before{content:"$"}
table.pyhltable{border-collapse:separate;border:0;margin-bottom:0;background:none}
table.pyhltable td{vertical-align:top;padding-top:0;padding-bottom:0;line-height:1.45}
table.pyhltable td.code{padding-left:.75em;padding-right:0}
pre.pygments .lineno,table.pyhltable td:not(.code){color:#999;padding-left:0;padding-right:.5em;border-right:1px solid #ddddd8}
pre.pygments .lineno{display:inline-block;margin-right:.25em}
table.pyhltable .linenodiv{background:none!important;padding-right:0!important}
.quoteblock{margin:0 1em 1.25em 1.5em;display:table}
.quoteblock>.title{margin-left:-1.5em;margin-bottom:.75em}
.quoteblock blockquote,.quoteblock blockquote p{color:rgba(0,0,0,.85);font-size:1.15rem;line-height:1.75;word-spacing:.1em;letter-spacing:0;font-style:italic;text-align:justify}
.quoteblock blockquote{margin:0;padding:0;border:0}
.quoteblock blockquote:before{content:"\201c";float:left;font-size:2.75em;font-weight:bold;line-height:.6em;margin-left:-.6em;color:#7a2518;text-shadow:0 1px 2px rgba(0,0,0,.1)}
.quoteblock blockquote>.paragraph:last-child p{margin-bottom:0}
.quoteblock .attribution{margin-top:.5em;margin-right:.5ex;text-align:right}
.quoteblock .quoteblock{margin-left:0;margin-right:0;padding:.5em 0;border-left:3px solid rgba(0,0,0,.6)}
.quoteblock .quoteblock blockquote{padding:0 0 0 .75em}
.quoteblock .quoteblock blockquote:before{display:none}
.verseblock{margin:0 1em 1.25em 1em}
.verseblock pre{font-family:"Open Sans","DejaVu Sans",sans;font-size:1.15rem;color:rgba(0,0,0,.85);font-weight:300;text-rendering:optimizeLegibility}
.verseblock pre strong{font-weight:400}
.verseblock .attribution{margin-top:1.25rem;margin-left:.5ex}
.quoteblock .attribution,.verseblock .attribution{font-size:.9375em;line-height:1.45;font-style:italic}
.quoteblock .attribution br,.verseblock .attribution br{display:none}
.quoteblock .attribution cite,.verseblock .attribution cite{display:block;letter-spacing:-.025em;color:rgba(0,0,0,.6)}
.quoteblock.abstract{margin:0 0 1.25em 0;display:block}
.quoteblock.abstract blockquote,.quoteblock.abstract blockquote p{text-align:left;word-spacing:0}
.quoteblock.abstract blockquote:before,.quoteblock.abstract blockquote p:first-of-type:before{display:none}
table.tableblock{max-width:100%;border-collapse:separate}
table.tableblock td>.paragraph:last-child p>p:last-child,table.tableblock th>p:last-child,table.tableblock td>p:last-child{margin-bottom:0}
table.tableblock,th.tableblock,td.tableblock{border:0 solid #dedede}
table.grid-all th.tableblock,table.grid-all td.tableblock{border-width:0 1px 1px 0}
table.grid-all tfoot>tr>th.tableblock,table.grid-all tfoot>tr>td.tableblock{border-width:1px 1px 0 0}
table.grid-cols th.tableblock,table.grid-cols td.tableblock{border-width:0 1px 0 0}
table.grid-all *>tr>.tableblock:last-child,table.grid-cols *>tr>.tableblock:last-child{border-right-width:0}
table.grid-rows th.tableblock,table.grid-rows td.tableblock{border-width:0 0 1px 0}
table.grid-all tbody>tr:last-child>th.tableblock,table.grid-all tbody>tr:last-child>td.tableblock,table.grid-all thead:last-child>tr>th.tableblock,table.grid-rows tbody>tr:last-child>th.tableblock,table.grid-rows tbody>tr:last-child>td.tableblock,table.grid-rows thead:last-child>tr>th.tableblock{border-bottom-width:0}
table.grid-rows tfoot>tr>th.tableblock,table.grid-rows tfoot>tr>td.tableblock{border-width:1px 0 0 0}
table.frame-all{border-width:1px}
table.frame-sides{border-width:0 1px}
table.frame-topbot{border-width:1px 0}
th.halign-left,td.halign-left{text-align:left}
th.halign-right,td.halign-right{text-align:right}
th.halign-center,td.halign-center{text-align:center}
th.valign-top,td.valign-top{vertical-align:top}
th.valign-bottom,td.valign-bottom{vertical-align:bottom}
th.valign-middle,td.valign-middle{vertical-align:middle}
table thead th,table tfoot th{font-weight:bold}
tbody tr th{display:table-cell;line-height:1.6;background:#f7f8f7}
tbody tr th,tbody tr th p,tfoot tr th,tfoot tr th p{color:rgba(0,0,0,.8);font-weight:bold}
p.tableblock>code:only-child{background:none;padding:0}
p.tableblock{font-size:1em}
td>div.verse{white-space:pre}
ol{margin-left:1.75em}
ul li ol{margin-left:1.5em}
dl dd{margin-left:1.125em}
dl dd:last-child,dl dd:last-child>:last-child{margin-bottom:0}
ol>li p,ul>li p,ul dd,ol dd,.olist .olist,.ulist .ulist,.ulist .olist,.olist .ulist{margin-bottom:.625em}
ul.unstyled,ol.unnumbered,ul.checklist,ul.none{list-style-type:none}
ul.unstyled,ol.unnumbered,ul.checklist{margin-left:.625em}
ul.checklist li>p:first-child>.fa-square-o:first-child,ul.checklist li>p:first-child>.fa-check-square-o:first-child{width:1em;font-size:.85em}
ul.checklist li>p:first-child>input[type="checkbox"]:first-child{width:1em;position:relative;top:1px}
ul.inline{margin:0 auto .625em auto;margin-left:-1.375em;margin-right:0;padding:0;list-style:none;overflow:hidden}
ul.inline>li{list-style:none;float:left;margin-left:1.375em;display:block}
ul.inline>li>*{display:block}
.unstyled dl dt{font-weight:400;font-style:normal}
ol.arabic{list-style-type:decimal}
ol.decimal{list-style-type:decimal-leading-zero}
ol.loweralpha{list-style-type:lower-alpha}
ol.upperalpha{list-style-type:upper-alpha}
ol.lowerroman{list-style-type:lower-roman}
ol.upperroman{list-style-type:upper-roman}
ol.lowergreek{list-style-type:lower-greek}
.hdlist>table,.colist>table{border:0;background:none}
.hdlist>table>tbody>tr,.colist>table>tbody>tr{background:none}
td.hdlist1,td.hdlist2{vertical-align:top;padding:0 .625em}
td.hdlist1{font-weight:bold;padding-bottom:1.25em}
.literalblock+.colist,.listingblock+.colist{margin-top:-.5em}
.colist>table tr>td:first-of-type{padding:0 .75em;line-height:1}
.colist>table tr>td:last-of-type{padding:.25em 0}
.thumb,.th{line-height:0;display:inline-block;border:solid 4px #fff;-webkit-box-shadow:0 0 0 1px #ddd;box-shadow:0 0 0 1px #ddd}
.imageblock.left,.imageblock[style*="float: left"]{margin:.25em .625em 1.25em 0}
.imageblock.right,.imageblock[style*="float: right"]{margin:.25em 0 1.25em .625em}
.imageblock>.title{margin-bottom:0}
.imageblock.thumb,.imageblock.th{border-width:6px}
.imageblock.thumb>.title,.imageblock.th>.title{padding:0 .125em}
.image.left,.image.right{margin-top:.25em;margin-bottom:.25em;display:inline-block;line-height:0}
.image.left{margin-right:.625em}
.image.right{margin-left:.625em}
a.image{text-decoration:none;display:inline-block}
a.image object{pointer-events:none}
sup.footnote,sup.footnoteref{font-size:.875em;position:static;vertical-align:super}
sup.footnote a,sup.footnoteref a{text-decoration:none}
sup.footnote a:active,sup.footnoteref a:active{text-decoration:underline}
#footnotes{padding-top:.75em;padding-bottom:.75em;margin-bottom:.625em}
#footnotes hr{width:20%;min-width:6.25em;margin:-.25em 0 .75em 0;border-width:1px 0 0 0}
#footnotes .footnote{padding:0 .375em 0 .225em;line-height:1.3334;font-size:.875em;margin-left:1.2em;text-indent:-1.05em;margin-bottom:.2em}
#footnotes .footnote a:first-of-type{font-weight:bold;text-decoration:none}
#footnotes .footnote:last-of-type{margin-bottom:0}
#content #footnotes{margin-top:-.625em;margin-bottom:0;padding:.75em 0}
.gist .file-data>table{border:0;background:#fff;width:100%;margin-bottom:0}
.gist .file-data>table td.line-data{width:99%}
div.unbreakable{page-break-inside:avoid}
.big{font-size:larger}
.small{font-size:smaller}
.underline{text-decoration:underline}
.overline{text-decoration:overline}
.line-through{text-decoration:line-through}
.aqua{color:#00bfbf}
.aqua-background{background-color:#00fafa}
.black{color:#000}
.black-background{background-color:#000}
.blue{color:#0000bf}
.blue-background{background-color:#0000fa}
.fuchsia{color:#bf00bf}
.fuchsia-background{background-color:#fa00fa}
.gray{color:#606060}
.gray-background{background-color:#7d7d7d}
.green{color:#006000}
.green-background{background-color:#007d00}
.lime{color:#00bf00}
.lime-background{background-color:#00fa00}
.maroon{color:#600000}
.maroon-background{background-color:#7d0000}
.navy{color:#000060}
.navy-background{background-color:#00007d}
.olive{color:#606000}
.olive-background{background-color:#7d7d00}
.purple{color:#600060}
.purple-background{background-color:#7d007d}
.red{color:#bf0000}
.red-background{background-color:#fa0000}
.silver{color:#909090}
.silver-background{background-color:#bcbcbc}
.teal{color:#006060}
.teal-background{background-color:#007d7d}
.white{color:#bfbfbf}
.white-background{background-color:#fafafa}
.yellow{color:#bfbf00}
.yellow-background{background-color:#fafa00}
span.icon>.fa{cursor:default}
.admonitionblock td.icon [class^="fa icon-"]{font-size:2.5em;text-shadow:1px 1px 2px rgba(0,0,0,.5);cursor:default}
.admonitionblock td.icon .icon-note:before{content:"\f05a";color:#19407c}
.admonitionblock td.icon .icon-tip:before{content:"\f0eb";text-shadow:1px 1px 2px rgba(155,155,0,.8);color:#111}
.admonitionblock td.icon .icon-warning:before{content:"\f071";color:#bf6900}
.admonitionblock td.icon .icon-caution:before{content:"\f06d";color:#bf3400}
.admonitionblock td.icon .icon-important:before{content:"\f06a";color:#bf0000}
.conum[data-value]{display:inline-block;color:#fff!important;background-color:rgba(0,0,0,.8);-webkit-border-radius:100px;border-radius:100px;text-align:center;font-size:.75em;width:1.67em;height:1.67em;line-height:1.67em;font-family:"Open Sans","DejaVu Sans",sans-serif;font-style:normal;font-weight:bold}
.conum[data-value] *{color:#fff!important}
.conum[data-value]+b{display:none}
.conum[data-value]:after{content:attr(data-value)}
pre .conum[data-value]{position:relative;top:-.125em}
b.conum *{color:inherit!important}
.conum:not([data-value]):empty{display:none}
dt,th.tableblock,td.content,div.footnote{text-rendering:optimizeLegibility}
h1,h2,p,td.content,span.alt{letter-spacing:-.01em}
p strong,td.content strong,div.footnote strong{letter-spacing:-.005em}
p,blockquote,dt,td.content,span.alt{font-size:1.0625rem}
p{margin-bottom:1.25rem}
.sidebarblock p,.sidebarblock dt,.sidebarblock td.content,p.tableblock{font-size:1em}
.exampleblock>.content{background-color:#fffef7;border-color:#e0e0dc;-webkit-box-shadow:0 1px 4px #e0e0dc;box-shadow:0 1px 4px #e0e0dc}
.print-only{display:none!important}
@media print{@page{margin:1.25cm .75cm}
*{-webkit-box-shadow:none!important;box-shadow:none!important;text-shadow:none!important}
a{color:inherit!important;text-decoration:underline!important}
a.bare,a[href^="#"],a[href^="mailto:"]{text-decoration:none!important}
a[href^="http:"]:not(.bare):after,a[href^="https:"]:not(.bare):after{content:"(" attr(href) ")";display:inline-block;font-size:.875em;padding-left:.25em}
abbr[title]:after{content:" (" attr(title) ")"}
pre,blockquote,tr,img,object,svg{page-break-inside:avoid}
thead{display:table-header-group}
svg{max-width:100%}
p,blockquote,dt,td.content{font-size:1em;orphans:3;widows:3}
h2,h3,#toctitle,.sidebarblock>.content>.title{page-break-after:avoid}
#toc,.sidebarblock,.exampleblock>.content{background:none!important}
#toc{border-bottom:1px solid #ddddd8!important;padding-bottom:0!important}
.sect1{padding-bottom:0!important}
.sect1+.sect1{border:0!important}
#header>h1:first-child{margin-top:1.25rem}
body.book #header{text-align:center}
body.book #header>h1:first-child{border:0!important;margin:2.5em 0 1em 0}
body.book #header .details{border:0!important;display:block;padding:0!important}
body.book #header .details span:first-child{margin-left:0!important}
body.book #header .details br{display:block}
body.book #header .details br+span:before{content:none!important}
body.book #toc{border:0!important;text-align:left!important;padding:0!important;margin:0!important}
body.book #toc,body.book #preamble,body.book h1.sect0,body.book .sect1>h2{page-break-before:always}
.listingblock code[data-lang]:before{display:block}
#footer{background:none!important;padding:0 .9375em}
#footer-text{color:rgba(0,0,0,.6)!important;font-size:.9em}
.hide-on-print{display:none!important}
.print-only{display:block!important}
.hide-for-print{display:none!important}
.show-for-print{display:inherit!important}}
</style>
</head>
<body class="book">
<div id="content">
<div class="sect1">
<h2 id="under-the-hood">7. Under the Hood</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="how-distributed-computing-works-in-jet">7.1. How Distributed Computing Works in Jet</h3>
<div class="paragraph">
<p>In this section we will take a deep dive into the fundamentals of
distributed computing and Jet&#8217;s specific take on it. We will do this by
dissecting one specific problem: the Word Count. This is how you&#8217;d
describe it in the <a href="https://github.com/hazelcast/hazelcast-jet-code-samples/blob/master/batch/wordcount/src/main/java/WordCount.java">Jet Pipeline API</a>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">Pattern delimiter = Pattern.compile("\\W+");
Pipeline p = Pipeline.create();
p.drawFrom(Sources.&lt;Long, String&gt;map(BOOK_LINES))
 .flatMap(e -&gt; traverseArray(delimiter.split(e.getValue().toLowerCase())))
 .filter(word -&gt; !word.isEmpty())
 .groupBy(wholeItem(), counting())
 .drainTo(Sinks.writeMap(COUNTS));</code></pre>
</div>
</div>
<div class="paragraph">
<p>We&#8217;ll step back from this and start from the single-threaded Java code
that solves the problem for a basic data structure such as an
<code>ArrayList</code> and gradually move on to a formulation that allows us to
solve it for a data source distributed over the whole cluster,
efficiently making use of all the available CPU power. Towards the end
of the section we&#8217;ll show you the Core API code that directly builds the
DAG we designed.</p>
</div>
<div class="paragraph">
<p>Here is the single-threaded code that counts the words in a <code>List</code> of
lines of text:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">List&lt;String&gt; lines = ... // a pre-existing list
Map&lt;String, Long&gt; counts = new HashMap&lt;&gt;();
for (String line : lines) {
    for (String word : line.toLowerCase().split("\\W+")) {
        if (!word.isEmpty()) {
            counts.merge(word, 1L, (count, one) -&gt; count + one);
        }
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>To move us closer to how this computation is expressed in Jet, let&#8217;s
rewrite it in terms of the Java Streams API, still single-threaded:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">Map&lt;String, Long&gt; counts =
    lines.stream()
         .flatMap(line -&gt; Arrays.stream(line.toLowerCase().split("\\W+")))
         .filter(word -&gt; !word.isEmpty())
         .collect(groupingBy(word -&gt; word, counting()));</code></pre>
</div>
</div>
<div class="paragraph">
<p>The Java Streams formulation gives us clear insight into the steps taken
to process each data item:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><code>lines.stream()</code>: read lines from the data source (we&#8217;ll call this
the "source" step).</p>
</li>
<li>
<p><code>flatMap()</code>+<code>filter()</code>: split each line into lowercase words,
avoiding empty strings (the "tokenizer" step).</p>
</li>
<li>
<p><code>collect()</code>: group equal words together and count them (the
"accumulator" step).</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Our first move will be modeling the computation as a DAG. We&#8217;ll start
with a single-threaded model and then make several transformation steps
to it to reach a parallelized, distributed one, discussing at each step
the concerns that arise and how to meet them.</p>
</div>
<div class="paragraph">
<p>Note that here we are describing a <em>batch</em> job: the input is finite
and present in full before the job starts. Later on we&#8217;ll present a
<em>streaming</em> job that keeps processing an infinite stream forever,
transforming it into another infinite stream.</p>
</div>
<div class="sect3">
<h4 id="modeling-word-count-in-terms-of-a-dag">7.1.1. Modeling Word Count in terms of a DAG</h4>
<div class="paragraph">
<p>We can represent the steps outlined above as a DAG:</p>
</div>
<div class="imageblock">
<div class="content">
<img src="./images/wordcount-dag.png" alt="Word-counting DAG" width="600" height="170">
</div>
</div>
<div class="paragraph">
<p>The simplest, single-threaded code (shown above) deals with each item as
it is produced: the outer loop reads the lines, the inner loop that runs
for each line deals with the words on that line, and inside the inner
loop we populate the result map with running counts.</p>
</div>
<div class="paragraph">
<p>However, just by modeling the computation as a DAG, we&#8217;ve split the work
into isolated steps with clear data interfaces between them. We can
perform the same computation by running a separate thread for each step.
Roughly speaking, these are the snippets the threads would be executing:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">// Source thread
for (String line : readLines()) {
    emit(line);
}</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">// Tokenizer thread
for (String line : receive()) {
    for (String word : line.toLowerCase().split("\\W+")) {
        if (!word.isEmpty()) {
            emit(word);
        }
    }
}</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">// Accumulator thread
Map&lt;String, Long&gt; counts = new HashMap&lt;&gt;();
for (String word : receive()) {
    counts.merge(word, 1L, (count, one) -&gt; count + one);
}
// finally, when done receiving:
for (Entry&lt;String, Long&gt; wordAndCount : counts.entrySet()) {
    emit(wordAndCount);
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>The source loop feeds the tokenizer loop over a concurrent queue, the
tokenizer feeds the accumulator loop, and after the accumulator is done
receiving, it emits its results to the sink. Diagrammatically it looks
like this:</p>
</div>
<div class="imageblock">
<div class="content">
<img src="./images/wordcount-dag-queue.png" alt="Word-counting DAG with concurrent queues shown" width="600" height="170">
</div>
</div>
<div class="paragraph">
<p>This transformation brought us a <em>pipelined</em> architecture: while the
tokenizer is busy with the regex work, the accumulator is updating the
map using the data the tokenizer is done with; and the source and sink
stages are pumping the data from/to the environment. Our design is now
able to engage more than one CPU core and will complete that much
sooner; however, we&#8217;re still limited by the number of vertices. We&#8217;ll be
able utilize two or three cores regardless of how many are available. To
move forward we must try to parallelize the work of each individual
vertex.</p>
</div>
<div class="paragraph">
<p>Given that our input is an in-memory list of lines, the bottleneck
occurs in the processing stages (tokenizing and accumulating). Let&#8217;s
first attack the tokenizing stage: it is a so-called "embarrassingly
parallelizable" task because the processing of each line is completely
self-contained. At this point we have to make a clear distinction
between the notions of <em>vertex</em> and <em>processor</em>: there can be several
processors doing the work of a single vertex. Let&#8217;s add another
tokenizing processor:</p>
</div>
<div class="imageblock">
<div class="content">
<img src="./images/wordcount-tokenizer.png" alt="Word-counting DAG with tokenizer vertex parallelized" width="600" height="170">
</div>
</div>
<div class="paragraph">
<p>The input processor can now use all the available tokenizers as a pool
and submit to any one whose queue has some room.</p>
</div>
<div class="paragraph">
<p>The next step is parallelizing the accumulator vertex, but this is
trickier: accumulators count word occurrences so using them as a pool
will result in each processor observing almost all distinct words
(entries taking space in its hashtable), but the counts will be partial
and will need combining. The common strategy to reduce memory usage is
to ensure that all occurrences of the same word go to the same
processor. This is called "data partitioning" and in Jet we&#8217;ll use a
<em>partitioned edge</em> between the tokenizer and the accumulator:</p>
</div>
<div class="imageblock">
<div class="content">
<img src="./images/wordcount-partitioned.png" alt="Word-counting DAG with tokenizer and accumulator parallelized" width="600" height="170">
</div>
</div>
<div class="paragraph">
<p>As a word is emitted from the tokenizer, it goes through a "switchboard"
stage where it&#8217;s routed to the correct downstream processor. To
determine where a word should be routed, we can calculate its hashcode
and use the lowest bit to address either accumulator 0 or accumulator 1.</p>
</div>
<div class="paragraph">
<p>At this point we have a blueprint for a fully functional parallelized
computation job which can max out all the CPU cores given enough
instances of tokenizing and accumulating processors. The next challenge
is making this work across machines.</p>
</div>
<div class="paragraph">
<p>For starters, our input can no longer be a simple in-memory list because
that would mean each machine processes the same data. To exploit the
cluster as a unified computation device, each cluster member must
observe only a slice of the dataset. Given that a Jet instance is also a
fully functional Hazelcast IMDG instance and a Jet cluster is also a
Hazelcast IMDG cluster, the natural choice is to pre-load our data into
an <code>IMap</code>, which will be automatically partitioned and distributed
across the members. Now each Jet member can just read the slice of data
that was stored locally on it.</p>
</div>
<div class="paragraph">
<p>When run in a cluster, Jet will instantiate a replica of the whole DAG
on each member. On a two-member cluster there will be two source
processors, four tokenizers, and so on. The trickiest part is the
partitioned edge between tokenizer and accumulator: each accumulator is
supposed to receive its own subset of words. That means that, for
example, a word emitted from tokenizer 0 will have to travel across the
network to reach accumulator 3, if that&#8217;s the one that happens to own
it. On average we can expect every other word to need network transport,
causing both serious network traffic and serialization/deserialization
CPU load.</p>
</div>
<div class="paragraph">
<p>There is a simple trick we can employ to avoid most of this traffic,
closely related to what we pointed above as a source of problems when
parallelizing locally: members of the cluster can be used as a pool,
each doing its own partial word counts, and then send their results to a
combining vertex. Note that this means sending only one item per
distinct word. Here&#8217;s the rough equivalent of the code the combining
vertex executes:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">// Combining vertex
Map&lt;String, Long&gt; combined = new HashMap&lt;&gt;();
for (Entry&lt;String, Long&gt; wordAndCount : receive()) {
    combined.merge(wordAndCount.getKey(), wordAndCount.getValue(),
                    (accCount, newCount) -&gt; accCount + newCount);
}
// finally, when done receiving:
for (Entry&lt;String, Long&gt; wordAndCount : combined.entrySet()) {
    emit(wordAndCount);
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>As noted above, such a scheme takes more memory due to more hashtable
entries on each member, but it saves network traffic (an issue we didn&#8217;t
have within a member). Given that memory costs scale with the number of
distinct keys (english words in our case), the memory cost is
more-or-less constant regardless of how much book material we process.
On the other hand, network traffic scales with the total data size so
the more material we process, the more we save on network traffic.</p>
</div>
<div class="paragraph">
<p>Jet distinguishes between <em>local</em> and <em>distributed</em> edges, so we&#8217;ll use
a <em>local partitioned</em> edge for <code>tokenize</code>&#8594;`accumulate` and a
<em>distributed partitioned</em> edge for <code>accumulate</code>&#8594;`combine`. With this
move we&#8217;ve finalized our DAG design, which can be illustrated by the
following diagram:</p>
</div>
<div class="imageblock">
<div class="content">
<img src="./images/wordcount-distributed.png" alt="Word-counting DAG parallelized and distributed" width="600" height="170">
</div>
</div>
</div>
<div class="sect3">
<h4 id="implementing-the-dag-in-jet-s-core-api">7.1.2. Implementing the DAG in Jet&#8217;s Core API</h4>
<div class="paragraph">
<p>Now that we&#8217;ve come up with a good DAG design, we can use Jet&#8217;s Core API
to implement it. We start by instantiating the DAG class and adding the
source vertex:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">DAG dag = new DAG();
Vertex source = dag.newVertex("source", SourceProcessors.readMapP("lines"));</code></pre>
</div>
</div>
<div class="paragraph">
<p>Note how we can build the DAG outside the context of any running Jet
instances: it is a pure POJO.</p>
</div>
<div class="paragraph">
<p>The source vertex will read the lines from the <code>IMap</code> and emit items of
type <code>Map.Entry&lt;Integer, String&gt;</code> to the next vertex. The key of the
entry is the line number, and the value is the line itself. The built-in
map-reading processor will do just what we want: on each member it will
read only the data local to that member.</p>
</div>
<div class="paragraph">
<p>The next vertex is the <em>tokenizer</em>, which does a simple "flat-mapping"
operation (transforms one input item into zero or more output items).
The low-level support for such a processor is a part of Jet&#8217;s library,
we just need to provide the mapping function:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">// (lineNum, line) -&gt; words
Pattern delimiter = Pattern.compile("\\W+");
Vertex tokenize = dag.newVertex("tokenize",
    Processors.flatMapP((Entry&lt;Integer, String&gt; e) -&gt;
        traverseArray(delimiter.split(e.getValue().toLowerCase()))
              .filter(word -&gt; !word.isEmpty()))
);</code></pre>
</div>
</div>
<div class="paragraph">
<p>This creates a processor that applies the given function to each
incoming item, obtaining zero or more output items, and emits them.
Specifically, our processor accepts items of type <code>Entry&lt;Integer,
String&gt;</code>, splits the entry value into lowercase words, and emits all
non-empty words. The function must return a <code>Traverser</code>, which is a
functional interface used to traverse a sequence of non-null items. Its
purpose is equivalent to the standard Java <code>Iterator</code>, but avoids the
cumbersome two-method API. Since a lot of support for cooperative
multithreading in Hazelcast Jet deals with sequence traversal, this
abstraction simplifies many of its aspects.</p>
</div>
<div class="paragraph">
<p>The next vertex will do the actual word count. We can use the built-in
<code>accumulateByKey</code> processor for this:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">// word -&gt; (word, count)
Vertex accumulate = dag.newVertex("accumulate",
        Processors.accumulateByKeyP(wholeItem(), counting())
);</code></pre>
</div>
</div>
<div class="paragraph">
<p>This processor maintains a hashtable that maps each distinct key to its
accumulated value. We specify <code>wholeItem()</code> as the <em>key extractor</em>
function: our input item is just the word, which is also the grouping
key. The second argument is the kind of aggregate operation we want to
perform: counting. We are relying on Jet&#8217;s out-of-the-box
definitions here, but it is easy to define your own aggregate operations
and key extractors. The processor emits nothing until it has received
all the input, and at that point it emits the hashtable as a stream of
<code>Entry&lt;String, Long&gt;</code>.</p>
</div>
<div class="paragraph">
<p>Next is the combining step which computes the grand totals from
individual members' contributions. This is the code:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">// (word, count) -&gt; (word, count)
Vertex combine = dag.newVertex("combine",
    Processors.combineByKeyP(counting())
);</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>combineByKey</code> is designed to be used downstream of <code>accumulateByKey</code>,
which is why it doesn&#8217;t need an explicit key extractor. The aggregate
operation must be the same as on <code>accumulateByKey</code>.</p>
</div>
<div class="paragraph">
<p>The final vertex is the sink; we want to store the output in
another <code>IMap</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">Vertex sink = dag.newVertex("sink", SinkProcessors.writeMapP("counts"));</code></pre>
</div>
</div>
<div class="paragraph">
<p>Now that we have all the vertices, we must connect them into a graph and
specify the edge type as discussed in the previous section. Here&#8217;s all
the code at once:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">dag.edge(between(source, tokenize))
   .edge(between(tokenize, accumulate)
           .partitioned(wholeItem(), Partitioner.HASH_CODE))
   .edge(between(accumulate, combine)
           .distributed()
           .partitioned(entryKey()))
   .edge(between(combine, sink));</code></pre>
</div>
</div>
<div class="paragraph">
<p>Let&#8217;s take a closer look at some of the edges. First, source to
tokenizer:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">.edge(between(tokenize, accumulate)
       .partitioned(wholeItem(), Partitioner.HASH_CODE))</code></pre>
</div>
</div>
<div class="paragraph">
<p>We chose a <em>local partitioned</em> edge. For each word, there will be a
processor responsible for it on each member so that no items must travel
across the network. In the <code>partitioned()</code> call we specify two things:
the function that extracts the partitioning key (<code>wholeItem()</code> - same as the grouping key extractor), and the policy object that decides
how to compute the partition ID from the key. Here we use the built-in
<code>HASH_CODE</code>, which will derive the ID from <code>Object.hashCode()</code>. As long
as the the definitions of <code>equals()/hashCode()</code> on the key object match
our expected notion of key equality, this policy is always safe to use
on a local edge.</p>
</div>
<div class="paragraph">
<p>Next, the edge from the accumulator to the combiner:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">.edge(between(accumulate, combine)
       .distributed()
       .partitioned(entryKey()))</code></pre>
</div>
</div>
<div class="paragraph">
<p>It is <em>distributed partitioned</em>: for each word there is a single
<code>combiner</code> processor in the whole cluster responsible for it and items
will be sent over the network if needed. The partitioning key is again
the word, but here it is the key part of the <code>Map.Entry&lt;String, Long&gt;</code>.
We are using the default partitioning policy here (Hazelcast&#8217;s own
partitioning scheme). It is the slower-but-safe choice on a distributed
edge. Detailed inspection shows that hashcode-based partitioning would
be safe as well because all of <code>String</code>, <code>Long</code>, and <code>Map.Entry</code> have
the hash function specified in their Javadoc.</p>
</div>
<div class="paragraph">
<p>You can acces a full, self-contained Java program with the above DAG code at the
<a href="https://github.com/hazelcast/hazelcast-jet-code-samples/blob/master/refman/src/main/java/refman/WordCountCoreApiRefMan.java">Hazelcast Jet code samples repository</a>.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="how-infinite-stream-processing-works-in-jet">7.2. How Infinite Stream Processing Works In Jet</h3>
<div class="paragraph">
<p>Continuing our deep dive into Jet&#8217;s fundamentals we shall now move on to
infinite stream processing. The major challenge in batch jobs was
properly parallelizing/distributing a "group by key" operation. To solve
it we introduced the idea of partitioning the data based on a formula
that takes just the grouping key as input and can be computed
independently on any member, always yielding the same result. In the
context of infinite stream processing we have the same concern and solve
it with the same means, but we also face some new challenges.</p>
</div>
<div class="sect3">
<h4 id="stream-skew">7.2.1. Stream Skew</h4>
<div class="paragraph">
<p>We
<a href="#time-ordering">already introduced</a>
the concept of the watermark and how it imposes
order onto a disordered data stream. Items arriving out of order aren&#8217;t
our only challenge; modern stream sources like Kafka are partitioned and
distributed so "the stream" is actually a set of independent substreams,
moving on in parallel. Substantial time difference may arise between
events being processed on each one, but our system must produce coherent
output as if there was only one stream. We meet this challenge by
coalescing watermarks: as the data travels over a partitioned/distributed
edge, we make sure the downstream processor observes the correct watermark
value, which is the least of watermarks received from the contributing
substreams.</p>
</div>
</div>
<div class="sect3">
<h4 id="sliding-and-tumbling-window">7.2.2. Sliding and Tumbling Window</h4>
<div class="paragraph">
<p>Many quantities, like "the current rate of change of a price" require you
to aggregate your data over some time period. This is what makes the
sliding window so important: it tracks the value of such a quantity in
real time.</p>
</div>
<div class="paragraph">
<p>Calculating a single sliding window result can be quite computationally
intensive, but we also expect it to slide smoothly and give a new result
often, even many times per second. This is why we gave special attention
to optimizing this computation.</p>
</div>
<div class="paragraph">
<p>We optimize especially heavily for those aggregate operations that have
a cheap way of combining partial results and even more so for those
which can cheaply undo the combining. For cheap combining you have to
express your operation in terms of a commutative and associative (CA for
short) function; to undo a combine you need the notion of "negating" an
argument to the function. A great many operations can be expressed
through CA functions: average, variance, standard deviation and linear
regression are some examples. All of these also support the undoing
(which we call <em>deduct</em>). The computation of extreme values (min/max) is
an example that has CA, but no good notion of negation and thus doesn&#8217;t
support deducting.</p>
</div>
<div class="paragraph">
<p>This is the way we leverage the above properties: our sliding window
actually "hops" in fixed-size steps. The length of the window is an
integer multiple of the step size. Under such a definition, the
<em>tumbling</em> window becomes just a special case with one step per window.</p>
</div>
<div class="paragraph">
<p>This allows us to divide the timestamp axis into <em>frames</em> of equal
length and assign each event to its frame. Instead of keeping the event
object, we immediately pass it to the aggregate operation&#8217;s <em>accumulate</em>
primitive. To compute a sliding window, we take all the frames covered
by it and combine them. Finally, to compute the next window, we just
<em>deduct</em> the trailing frame and <em>combine</em> the leading frame into the
existing result.</p>
</div>
<div class="paragraph">
<p>Even without <em>deduct</em> the above process is much cheaper than the most
nave approach where you&#8217;d keep all data and recompute everything from
scratch each time. After accumulating an item just once, the rest of the
process has fixed cost regardless of input size. With <em>deduct</em>, the
fixed cost approaches zero.</p>
</div>
<div class="sect4">
<h5 id="example-30-second-window-sliding-by-10-seconds">Example: 30-second Window Sliding by 10 Seconds</h5>
<div class="paragraph">
<p>We&#8217;ll now illustrate the above story with a specific example: we&#8217;ll
construct a 30-second window which slides by 10 seconds (i.e., three
steps per window). The aggregate operation is to simply count the number
of events. In the diagrams we label the events as <em>minutes:seconds</em>.
This is the outline of the process:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Throw each event into its "bucket" (the frame whose time interval it
belongs to).</p>
</li>
<li>
<p>Instead of keeping the items in the frame, just keep the item count.</p>
</li>
<li>
<p>Combine the frames into three different positions of the sliding
window, yielding the final result: the number of events that occurred
within the window&#8217;s timespan.</p>
</li>
</ol>
</div>
<div class="imageblock">
<div class="content">
<img src="./images/windowing-frames.png" alt="Grouping disordered events by frame and then to sliding window" width="800" height="800">
</div>
</div>
<div class="paragraph">
<p>This would be a useful interpretation of the results: "At the time 1:30,
the 30-second running average was 8/30 = 0.27 events per second. Over
the next 20 seconds it increased to 10/30 = 0.33 events per second."</p>
</div>
<div class="paragraph">
<p>Keep in mind that the whole diagram represents what happens on just one
cluster member and for just one grouping key. The same process is going
on simultaneously for all the keys on all the members.</p>
</div>
</div>
<div class="sect4">
<h5 id="two-stage-aggregation">Two-stage aggregation</h5>
<div class="paragraph">
<p>The concept of frame combining helps us implement two-stage aggregation
as well. In the first stage the individual members come up with their
partial results by frame and send them over a distributed edge to the
second stage, which combines the frames with the same timestamp. After
having combined all the partial frames from members, it combines the
results along the event time axis into the sliding window.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="./images/combining-frames.png" alt="Combining partial frames in two-stage aggregation" width="800" height="800">
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="session-window">7.2.3. Session Window</h4>
<div class="paragraph">
<p>In the abstract sense, the session window is a quite intuitive concept:
it simply captures a burst of events. If no new events occur within the
configured session timeout, the window closes. However, because the Jet
processor encounters events out of their original order, this kind of
window becomes quite tricky to compute.</p>
</div>
<div class="paragraph">
<p>The way Jet computes the session windows is easiest to explain in terms
of the <em>event interval</em>: the range
<code>[eventTimestamp, eventTimestamp + sessionTimeout]</code>.
Initially an event causes a new session window to be created, covering
exactly the event interval.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="./images/session-window-1.png" alt="Session window: single event" width="250" height="200">
</div>
</div>
<div class="paragraph">
<p>A following event under the same key belongs to this window iff its
interval overlaps it. The window is extended to cover the entire
interval of the new event.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="./images/session-window-2.png" alt="Session window: extend with another event" width="150" height="120">
</div>
</div>
<div class="paragraph">
<p>If the event intervals don&#8217;t overlap, a new session window is created
for the new event.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="./images/session-window-3.png" alt="Session window: create a new window after session timeout" width="300" height="110">
</div>
</div>
<div class="literalblock">
<div class="content">
<pre>width="240"/&gt;</pre>
</div>
</div>
<div class="paragraph">
<p>An event may happen to belong to two existing windows if its interval
bridges the gap between them; in that case they are combined into one.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="./images/session-window-4.png" alt="Session window: an event may merge two existing windows" width="300" height="110">
</div>
</div>
<div class="paragraph">
<p>Once the watermark has passed the closing time of a session window, Jet
can close it and emit the result of its aggregation.</p>
</div>
</div>
<div class="sect3">
<h4 id="distributed-snapshot">7.2.4. Distributed Snapshot</h4>
<div class="paragraph">
<p>The technique Jet uses to achieve
<a href="#fault-tolerance-and-processing-guarantees">fault tolerance</a>
is called a "distributed snapshot", described in a
<a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/12/Determining-Global-States-of-a-Distributed-System.pdf">paper by Chandy and Lamport</a>.
At regular intervals, Jet raises a global flag that says "it&#8217;s time for
another snapshot". All processors belonging to source vertices observe
the flag, create a checkpoint on their source, and emit a barrier item
to the downstream processors and resumes processing.</p>
</div>
<div class="paragraph">
<p>As the barrier item reaches a processor, it stops what it&#8217;s doing and
emits its state to the snapshot storage. Once complete, it forwards the
barrier item to its downstream processors.</p>
</div>
<div class="paragraph">
<p>Due to parallelism, in most cases a processor receives data from more
than one upstream processor. It will receive the barrier item from each
of them at separate times, but it must start taking a snapshot at a
single point in time. There are two approaches it can take, as explained
below.</p>
</div>
<div class="sect4">
<h5 id="exactly-once-snapshotting">Exactly-Once Snapshotting</h5>
<div class="paragraph">
<p>With <em>exactly-once</em> configured, as soon as the processor gets a barrier
item in any input stream (from any upstream processor), it must stop
consuming it until it gets the same barrier item in all the streams:</p>
</div>
<div class="imageblock">
<div class="content">
<img src="./images/exactly-once-1.png" alt="Exactly-once processing: received one barrier" width="300" height="110">
</div>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>At the barrier in stream X, but not Y. Must not accept any more X items.</p>
<div class="imageblock">
<div class="content">
<img src="./images/exactly-once-2.png" alt="Exactly-once processing: received both barriers" width="300" height="110">
</div>
</div>
</li>
<li>
<p>At the barrier in both streams, taking a snapshot.</p>
<div class="imageblock">
<div class="content">
<img src="./images/exactly-once-3.png" alt="Exactly-once processing: forward the barrier" width="300" height="110">
</div>
</div>
</li>
<li>
<p>Snapshot done, barrier forwarded. Can resume consuming all streams.</p>
</li>
</ol>
</div>
</div>
<div class="sect4">
<h5 id="at-least-once-snapshotting">At-Least-Once Snapshotting</h5>
<div class="paragraph">
<p>With <em>at-least-once</em> configured, the processor can keep consuming all
the streams until it gets all the barriers, at which point it will stop
to take the snapshot:</p>
</div>
<div class="imageblock">
<div class="content">
<img src="./images/at-least-once-1.png" alt="At-Least-once processing: received one barrier" width="300" height="110">
</div>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>At the barrier in stream X, but not Y. Carry on consuming all streams.</p>
<div class="imageblock">
<div class="content">
<img src="./images/at-least-once-2.png" alt="At-Least-once processing: received both barriers" width="300" height="110">
</div>
</div>
</li>
<li>
<p>At the barrier in both streams, already consumed <code>x1</code> and <code>x2</code>. Taking a snapshot.</p>
<div class="imageblock">
<div class="content">
<img src="./images/at-least-once-3.png" alt="At-Least-once processing: forward the barrier" width="300" height="110">
</div>
</div>
</li>
<li>
<p>Snapshot done, barrier forwarded.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Even though <code>x1</code> and <code>x2</code> occur after the barrier, the processor
consumed and processed them, updating its state accordingly. If the
computation job stops and restarts, this state will be restored from the
snapshot and then the source will replay <code>x1</code> and <code>x2</code>. The processor
will think it got two new items.</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="rules-of-watermark-propagation">7.2.5. Rules of Watermark Propagation</h4>
<div class="paragraph">
<p>Watermark objects are sent interleaved with other stream items, but are
handled specially:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>The value of the watermark a processor emits must be strictly
increasing. Jet will throw an exception if it detects a non-increasing
watermark.</p>
</li>
<li>
<p>When a processor receives and handles a watermark, it is automatically
emitted to the outbox. Therefore there should be only one processor
emitting watermarks in the pipeline.</p>
</li>
<li>
<p>The watermark item is always broadcast, regardless of the edge type.
This means that all N upstream processors send their watermark to all
M downstream processors.</p>
</li>
<li>
<p>The processor will observe only the highest watermark received from
all upstream processors and from all upstream edges. This is called
<em>watermark coalescing</em>.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Jet&#8217;s internal class
<a href="https://github.com/hazelcast/hazelcast-jet/blob/master/hazelcast-jet-core/src/main/java/com/hazelcast/jet/impl/execution/WatermarkCoalescer.java"><code>WatermarkCoalescer</code></a>
 manages watermarks received from multiple inputs. As it receives
watermark items from them, its duty is to decide when to forward the
watermark downstream. This happens at two levels:
* between multiple queues backing single edge
* between multiple input edges to single processor</p>
</div>
<div class="sect4">
<h5 id="idle-inputs">Idle inputs</h5>
<div class="paragraph">
<p>A special object called <em>idle message</em> can be emitted from source
processor when the processor sees no events for configured <em>idle
timeout</em>. This can happen in real life when some external partitions
have no events while others do.</p>
</div>
<div class="paragraph">
<p>When an <em>idle message</em> is received from an input, that input will be
excluded from watermark coalescing. This means that we will not wait to
receive watermark from idle input. It will cause that other active
inputs can be processed without any delay. When idle timeout is disabled
and some processor doesn&#8217;t emit any watermarks (because it sees no
events), the processing will stall indefinitely (unless
<a href="#max-watermark-retention">maximum retention</a>
is configured).</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="pitfalls-alo">7.2.6. The Pitfalls of At-Least-Once Processing</h4>
<div class="paragraph">
<p>In some cases <em>at-least-once</em> semantics can have consequences of quite
an unexpected magnitude, as we discuss next.</p>
</div>
<div class="sect4">
<h5 id="apparent-data-loss">Apparent Data Loss</h5>
<div class="paragraph">
<p>Imagine a very simple kind of processor: it matches up the items that
belong to a <em>pair</em> based on some rule. If it receives item A first, it
remembers it. Later on, when it receives item B, it emits that fact
to its outbound edge and forgets about the two items. It may also first
receive B and wait for A.</p>
</div>
<div class="paragraph">
<p>Now imagine this sequence: <code>A &#8594; BARRIER &#8594; B</code>. In at-least-once the
processor may observe both A and B, emit its output, and forget about
them, all before taking the snapshot. After the restart, item B will be
replayed because it occurred after the last barrier, but item A won&#8217;t.
Now the processor is stuck forever in a state where it&#8217;s expecting A and
has no idea it already got it and emitted that fact.</p>
</div>
<div class="paragraph">
<p>Problems similar to this may happen with any state the processor keeps
until it has got enough information to emit the results and then forgets
it. By the time it takes a snapshot, the post-barrier items will have
caused it to forget facts about some pre-barrier items. After a restart
it will behave as though it has never observed those pre-barrier items,
resulting in behavior equivalent to data loss.</p>
</div>
</div>
<div class="sect4">
<h5 id="non-monotonic-watermark">Non-Monotonic Watermark</h5>
<div class="paragraph">
<p>One special case of the above story concerns watermark items. Thanks to
watermark coalescing, processors are typically implemented against the
invariant that the watermark value always increases. However, in
<em>at-least-once</em> the post-barrier watermark items will advance the
processor&#8217;s watermark value. After the job restarts and the state gets
restored to the snapshotted point, the watermark will appear to have
gone back, breaking the invariant. This can again lead to apparent data
loss.</p>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="stream-processing-dag-and-code">7.3. Stream-Processing DAG and Code</h3>
<div class="paragraph">
<p>For this example we&#8217;ll build a simple Jet job that monitors trading
events on a stock market, categorizes the events by stock ticker, and
reports the number of trades per time unit (the time window). In terms
of DAG design, not much changes going from batch to streaming. This is
how it looks:</p>
</div>
<div class="imageblock">
<div class="content">
<img src="./images/stock-exchange-dag.png" alt="Trade monitoring DAG" width="300" height="900">
</div>
</div>
<div class="paragraph">
<p>We have the same cascade of source, two-stage aggregation, and sink. The
source part consists of <code>ticker-source</code> that loads stock names
(tickers) from a Hazelcast IMap and <code>generate-trades</code> that retains this
list and randomly generates an infinite stream of trade events. A
separate vertex is inserting watermark items needed by the aggregation
stage and on the sink side there&#8217;s another mapping vertex,
<code>format-output</code>, that transforms the window result items into lines of
text. The <code>sink</code> vertex writes these lines to a file.</p>
</div>
<div class="paragraph">
<p>Before we go on, let us point out that in the 0.5 release of Hazelcast
Jet, the Pipeline API is still in infancy and doesn&#8217;t support all the
features needed for stream processing. Therefore the following example
is given only in the Core API; with the next release we&#8217;ll be able to
present the much simpler code to do it in the Pipelines API.</p>
</div>
<div class="paragraph">
<p>If you studied the DAG-building code for the Word Count job, this code
should look generally familiar:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">WindowDefinition windowDef = WindowDefinition.slidingWindowDef(
        SLIDING_WINDOW_LENGTH_MILLIS, SLIDE_STEP_MILLIS);
Vertex tickerSource = dag.newVertex("ticker-source",
        SourceProcessors.readMapP(GenerateTradesP.TICKER_MAP_NAME));
Vertex generateTrades = dag.newVertex("generate-trades",
        GenerateTradesP.generateTradesP(TRADES_PER_SEC_PER_MEMBER));
Vertex insertWatermarks = dag.newVertex("insert-watermarks",
        Processors.insertWatermarksP(
                Trade::getTime,
                withFixedLag(GenerateTradesP.MAX_LAG),
                emitByFrame(windowDef)));
Vertex slidingStage1 = dag.newVertex("sliding-stage-1",
        Processors.accumulateByFrameP(
                Trade::getTicker,
                Trade::getTime, TimestampKind.EVENT,
                windowDef,
                counting()));
Vertex slidingStage2 = dag.newVertex("sliding-stage-2",
        Processors.combineToSlidingWindowP(windowDef, counting()));
Vertex formatOutput = dag.newVertex("format-output",
        formatOutput());
Vertex sink = dag.newVertex("sink",
        SinkProcessors.writeFileP(OUTPUT_DIR_NAME));

tickerSource.localParallelism(1);
generateTrades.localParallelism(1);

return dag
        .edge(between(tickerSource, generateTrades)
                .distributed().broadcast())
        .edge(between(generateTrades, insertWatermarks)
                .isolated())
        .edge(between(insertWatermarks, slidingStage1)
                .partitioned(Trade::getTicker, HASH_CODE))
        .edge(between(slidingStage1, slidingStage2)
                .partitioned(Entry&lt;String, Long&gt;::getKey, HASH_CODE)
                .distributed())
        .edge(between(slidingStage2, formatOutput)
                .isolated())
        .edge(between(formatOutput, sink)
                .isolated());</code></pre>
</div>
</div>
<div class="paragraph">
<p>The source vertex reads a Hazelcast IMap, just like it did in the word
counting example. Trade generating vertex uses a custom processor that
generates mock trades. It can be reviewed
<a href="https://github.com/hazelcast/hazelcast-jet-code-samples/blob/master/core-api/streaming/trade-generator/src/main/java/trades/tradegenerator/GenerateTradesP.java">here</a>.
The implementation of <code>complete()</code> is non-trivial, but most of the
complexity just deals with precision timing of events. For simplicity&#8217;s
sake the processor must be configured with a local parallelism of 1;
generating a precise amount of mock traffic from parallel processors
would take more code and coordination.</p>
</div>
<div class="paragraph">
<p>The major novelty is the watermark-inserting vertex. It must be added
in front of the windowing vertex and will insert watermark items
according to the configured <a href="#watermark-policy">policy</a>.
In this case we use the simplest one, <code>withFixedLag</code>, which will make
the watermark lag behind the top observed event timestamp by a fixed
amount. Emission of watermarks is additionally throttled, so that only
one watermark item per frame is emitted. The windowing processors emit
data only when the watermark reaches the next frame, so inserting it
more often than that would be just overhead.</p>
</div>
<div class="paragraph">
<p>The edge from <code>insertWatermarks</code> to <code>slidingStage1</code> is partitioned; you
may wonder how that works with watermark items, since</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>their type is different from the "main" stream item type and they
don&#8217;t have a partitioning key</p>
</li>
<li>
<p>each of them must reach all downstream processors.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>It turns out that Jet must treat them as a special case: regardless of
the configured edge type, watermarks are routed using the broadcast
policy.</p>
</div>
<div class="paragraph">
<p>The stage-1 processor will just forward the watermark it receives,
along with any aggregation results whose emission it triggers, to stage
2.</p>
</div>
<div class="paragraph">
<p>The full code of this sample is in
<a href="https://github.com/hazelcast/hazelcast-jet-code-samples/blob/master/core-api/streaming/stock-exchange/src/main/java/StockExchange.java">StockExchange.java</a>
and running it you&#8217;ll get an endless stream of data accumulating on the
disk. To spare your filesystem we&#8217;ve limited the execution time to 10
seconds.</p>
</div>
</div>
</div>
</div>
</div>
<div id="footer">
<div id="footer-text">
Last updated 2018-02-28 16:54:25 MSK
</div>
</div>
</body>
</html>