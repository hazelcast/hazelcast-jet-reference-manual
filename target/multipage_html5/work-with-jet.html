<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<!--[if IE]><meta http-equiv="X-UA-Compatible" content="IE=edge"><![endif]-->
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Asciidoctor 1.5.3">
<title>Work with Jet</title>
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700">
<style>
/* Asciidoctor default stylesheet | MIT License | http://asciidoctor.org */
/* Remove comment around @import statement below when using as a custom stylesheet */
/*@import "https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700";*/
article,aside,details,figcaption,figure,footer,header,hgroup,main,nav,section,summary{display:block}
audio,canvas,video{display:inline-block}
audio:not([controls]){display:none;height:0}
[hidden],template{display:none}
script{display:none!important}
html{font-family:sans-serif;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}
body{margin:0}
a{background:transparent}
a:focus{outline:thin dotted}
a:active,a:hover{outline:0}
h1{font-size:2em;margin:.67em 0}
abbr[title]{border-bottom:1px dotted}
b,strong{font-weight:bold}
dfn{font-style:italic}
hr{-moz-box-sizing:content-box;box-sizing:content-box;height:0}
mark{background:#ff0;color:#000}
code,kbd,pre,samp{font-family:monospace;font-size:1em}
pre{white-space:pre-wrap}
q{quotes:"\201C" "\201D" "\2018" "\2019"}
small{font-size:80%}
sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}
sup{top:-.5em}
sub{bottom:-.25em}
img{border:0}
svg:not(:root){overflow:hidden}
figure{margin:0}
fieldset{border:1px solid silver;margin:0 2px;padding:.35em .625em .75em}
legend{border:0;padding:0}
button,input,select,textarea{font-family:inherit;font-size:100%;margin:0}
button,input{line-height:normal}
button,select{text-transform:none}
button,html input[type="button"],input[type="reset"],input[type="submit"]{-webkit-appearance:button;cursor:pointer}
button[disabled],html input[disabled]{cursor:default}
input[type="checkbox"],input[type="radio"]{box-sizing:border-box;padding:0}
input[type="search"]{-webkit-appearance:textfield;-moz-box-sizing:content-box;-webkit-box-sizing:content-box;box-sizing:content-box}
input[type="search"]::-webkit-search-cancel-button,input[type="search"]::-webkit-search-decoration{-webkit-appearance:none}
button::-moz-focus-inner,input::-moz-focus-inner{border:0;padding:0}
textarea{overflow:auto;vertical-align:top}
table{border-collapse:collapse;border-spacing:0}
*,*:before,*:after{-moz-box-sizing:border-box;-webkit-box-sizing:border-box;box-sizing:border-box}
html,body{font-size:100%}
body{background:#fff;color:rgba(0,0,0,.8);padding:0;margin:0;font-family:"Noto Serif","DejaVu Serif",serif;font-weight:400;font-style:normal;line-height:1;position:relative;cursor:auto}
a:hover{cursor:pointer}
img,object,embed{max-width:100%;height:auto}
object,embed{height:100%}
img{-ms-interpolation-mode:bicubic}
.left{float:left!important}
.right{float:right!important}
.text-left{text-align:left!important}
.text-right{text-align:right!important}
.text-center{text-align:center!important}
.text-justify{text-align:justify!important}
.hide{display:none}
body{-webkit-font-smoothing:antialiased}
img,object,svg{display:inline-block;vertical-align:middle}
textarea{height:auto;min-height:50px}
select{width:100%}
.center{margin-left:auto;margin-right:auto}
.spread{width:100%}
p.lead,.paragraph.lead>p,#preamble>.sectionbody>.paragraph:first-of-type p{font-size:1.21875em;line-height:1.6}
.subheader,.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{line-height:1.45;color:#7a2518;font-weight:400;margin-top:0;margin-bottom:.25em}
div,dl,dt,dd,ul,ol,li,h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6,pre,form,p,blockquote,th,td{margin:0;padding:0;direction:ltr}
a{color:#2156a5;text-decoration:underline;line-height:inherit}
a:hover,a:focus{color:#1d4b8f}
a img{border:none}
p{font-family:inherit;font-weight:400;font-size:1em;line-height:1.6;margin-bottom:1.25em;text-rendering:optimizeLegibility}
p aside{font-size:.875em;line-height:1.35;font-style:italic}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{font-family:"Open Sans","DejaVu Sans",sans-serif;font-weight:300;font-style:normal;color:#ba3925;text-rendering:optimizeLegibility;margin-top:1em;margin-bottom:.5em;line-height:1.0125em}
h1 small,h2 small,h3 small,#toctitle small,.sidebarblock>.content>.title small,h4 small,h5 small,h6 small{font-size:60%;color:#e99b8f;line-height:0}
h1{font-size:2.125em}
h2{font-size:1.6875em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.375em}
h4,h5{font-size:1.125em}
h6{font-size:1em}
hr{border:solid #ddddd8;border-width:1px 0 0;clear:both;margin:1.25em 0 1.1875em;height:0}
em,i{font-style:italic;line-height:inherit}
strong,b{font-weight:bold;line-height:inherit}
small{font-size:60%;line-height:inherit}
code{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;font-weight:400;color:rgba(0,0,0,.9)}
ul,ol,dl{font-size:1em;line-height:1.6;margin-bottom:1.25em;list-style-position:outside;font-family:inherit}
ul,ol,ul.no-bullet,ol.no-bullet{margin-left:1.5em}
ul li ul,ul li ol{margin-left:1.25em;margin-bottom:0;font-size:1em}
ul.square li ul,ul.circle li ul,ul.disc li ul{list-style:inherit}
ul.square{list-style-type:square}
ul.circle{list-style-type:circle}
ul.disc{list-style-type:disc}
ul.no-bullet{list-style:none}
ol li ul,ol li ol{margin-left:1.25em;margin-bottom:0}
dl dt{margin-bottom:.3125em;font-weight:bold}
dl dd{margin-bottom:1.25em}
abbr,acronym{text-transform:uppercase;font-size:90%;color:rgba(0,0,0,.8);border-bottom:1px dotted #ddd;cursor:help}
abbr{text-transform:none}
blockquote{margin:0 0 1.25em;padding:.5625em 1.25em 0 1.1875em;border-left:1px solid #ddd}
blockquote cite{display:block;font-size:.9375em;color:rgba(0,0,0,.6)}
blockquote cite:before{content:"\2014 \0020"}
blockquote cite a,blockquote cite a:visited{color:rgba(0,0,0,.6)}
blockquote,blockquote p{line-height:1.6;color:rgba(0,0,0,.85)}
@media only screen and (min-width:768px){h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2}
h1{font-size:2.75em}
h2{font-size:2.3125em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.6875em}
h4{font-size:1.4375em}}
table{background:#fff;margin-bottom:1.25em;border:solid 1px #dedede}
table thead,table tfoot{background:#f7f8f7;font-weight:bold}
table thead tr th,table thead tr td,table tfoot tr th,table tfoot tr td{padding:.5em .625em .625em;font-size:inherit;color:rgba(0,0,0,.8);text-align:left}
table tr th,table tr td{padding:.5625em .625em;font-size:inherit;color:rgba(0,0,0,.8)}
table tr.even,table tr.alt,table tr:nth-of-type(even){background:#f8f8f7}
table thead tr th,table tfoot tr th,table tbody tr td,table tr td,table tfoot tr td{display:table-cell;line-height:1.6}
body{tab-size:4}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2;word-spacing:-.05em}
h1 strong,h2 strong,h3 strong,#toctitle strong,.sidebarblock>.content>.title strong,h4 strong,h5 strong,h6 strong{font-weight:400}
.clearfix:before,.clearfix:after,.float-group:before,.float-group:after{content:" ";display:table}
.clearfix:after,.float-group:after{clear:both}
*:not(pre)>code{font-size:.9375em;font-style:normal!important;letter-spacing:0;padding:.1em .5ex;word-spacing:-.15em;background-color:#f7f7f8;-webkit-border-radius:4px;border-radius:4px;line-height:1.45;text-rendering:optimizeSpeed}
pre,pre>code{line-height:1.45;color:rgba(0,0,0,.9);font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;font-weight:400;text-rendering:optimizeSpeed}
.keyseq{color:rgba(51,51,51,.8)}
kbd{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;display:inline-block;color:rgba(0,0,0,.8);font-size:.65em;line-height:1.45;background-color:#f7f7f7;border:1px solid #ccc;-webkit-border-radius:3px;border-radius:3px;-webkit-box-shadow:0 1px 0 rgba(0,0,0,.2),0 0 0 .1em white inset;box-shadow:0 1px 0 rgba(0,0,0,.2),0 0 0 .1em #fff inset;margin:0 .15em;padding:.2em .5em;vertical-align:middle;position:relative;top:-.1em;white-space:nowrap}
.keyseq kbd:first-child{margin-left:0}
.keyseq kbd:last-child{margin-right:0}
.menuseq,.menu{color:rgba(0,0,0,.8)}
b.button:before,b.button:after{position:relative;top:-1px;font-weight:400}
b.button:before{content:"[";padding:0 3px 0 2px}
b.button:after{content:"]";padding:0 2px 0 3px}
p a>code:hover{color:rgba(0,0,0,.9)}
#header,#content,#footnotes,#footer{width:100%;margin-left:auto;margin-right:auto;margin-top:0;margin-bottom:0;max-width:62.5em;*zoom:1;position:relative;padding-left:.9375em;padding-right:.9375em}
#header:before,#header:after,#content:before,#content:after,#footnotes:before,#footnotes:after,#footer:before,#footer:after{content:" ";display:table}
#header:after,#content:after,#footnotes:after,#footer:after{clear:both}
#content{margin-top:1.25em}
#content:before{content:none}
#header>h1:first-child{color:rgba(0,0,0,.85);margin-top:2.25rem;margin-bottom:0}
#header>h1:first-child+#toc{margin-top:8px;border-top:1px solid #ddddd8}
#header>h1:only-child,body.toc2 #header>h1:nth-last-child(2){border-bottom:1px solid #ddddd8;padding-bottom:8px}
#header .details{border-bottom:1px solid #ddddd8;line-height:1.45;padding-top:.25em;padding-bottom:.25em;padding-left:.25em;color:rgba(0,0,0,.6);display:-ms-flexbox;display:-webkit-flex;display:flex;-ms-flex-flow:row wrap;-webkit-flex-flow:row wrap;flex-flow:row wrap}
#header .details span:first-child{margin-left:-.125em}
#header .details span.email a{color:rgba(0,0,0,.85)}
#header .details br{display:none}
#header .details br+span:before{content:"\00a0\2013\00a0"}
#header .details br+span.author:before{content:"\00a0\22c5\00a0";color:rgba(0,0,0,.85)}
#header .details br+span#revremark:before{content:"\00a0|\00a0"}
#header #revnumber{text-transform:capitalize}
#header #revnumber:after{content:"\00a0"}
#content>h1:first-child:not([class]){color:rgba(0,0,0,.85);border-bottom:1px solid #ddddd8;padding-bottom:8px;margin-top:0;padding-top:1rem;margin-bottom:1.25rem}
#toc{border-bottom:1px solid #efefed;padding-bottom:.5em}
#toc>ul{margin-left:.125em}
#toc ul.sectlevel0>li>a{font-style:italic}
#toc ul.sectlevel0 ul.sectlevel1{margin:.5em 0}
#toc ul{font-family:"Open Sans","DejaVu Sans",sans-serif;list-style-type:none}
#toc li{line-height:1.3334;margin-top:.3334em}
#toc a{text-decoration:none}
#toc a:active{text-decoration:underline}
#toctitle{color:#7a2518;font-size:1.2em}
@media only screen and (min-width:768px){#toctitle{font-size:1.375em}
body.toc2{padding-left:15em;padding-right:0}
#toc.toc2{margin-top:0!important;background-color:#f8f8f7;position:fixed;width:15em;left:0;top:0;border-right:1px solid #efefed;border-top-width:0!important;border-bottom-width:0!important;z-index:1000;padding:1.25em 1em;height:100%;overflow:auto}
#toc.toc2 #toctitle{margin-top:0;margin-bottom:.8rem;font-size:1.2em}
#toc.toc2>ul{font-size:.9em;margin-bottom:0}
#toc.toc2 ul ul{margin-left:0;padding-left:1em}
#toc.toc2 ul.sectlevel0 ul.sectlevel1{padding-left:0;margin-top:.5em;margin-bottom:.5em}
body.toc2.toc-right{padding-left:0;padding-right:15em}
body.toc2.toc-right #toc.toc2{border-right-width:0;border-left:1px solid #efefed;left:auto;right:0}}
@media only screen and (min-width:1280px){body.toc2{padding-left:20em;padding-right:0}
#toc.toc2{width:20em}
#toc.toc2 #toctitle{font-size:1.375em}
#toc.toc2>ul{font-size:.95em}
#toc.toc2 ul ul{padding-left:1.25em}
body.toc2.toc-right{padding-left:0;padding-right:20em}}
#content #toc{border-style:solid;border-width:1px;border-color:#e0e0dc;margin-bottom:1.25em;padding:1.25em;background:#f8f8f7;-webkit-border-radius:4px;border-radius:4px}
#content #toc>:first-child{margin-top:0}
#content #toc>:last-child{margin-bottom:0}
#footer{max-width:100%;background-color:rgba(0,0,0,.8);padding:1.25em}
#footer-text{color:rgba(255,255,255,.8);line-height:1.44}
.sect1{padding-bottom:.625em}
@media only screen and (min-width:768px){.sect1{padding-bottom:1.25em}}
.sect1+.sect1{border-top:1px solid #efefed}
#content h1>a.anchor,h2>a.anchor,h3>a.anchor,#toctitle>a.anchor,.sidebarblock>.content>.title>a.anchor,h4>a.anchor,h5>a.anchor,h6>a.anchor{position:absolute;z-index:1001;width:1.5ex;margin-left:-1.5ex;display:block;text-decoration:none!important;visibility:hidden;text-align:center;font-weight:400}
#content h1>a.anchor:before,h2>a.anchor:before,h3>a.anchor:before,#toctitle>a.anchor:before,.sidebarblock>.content>.title>a.anchor:before,h4>a.anchor:before,h5>a.anchor:before,h6>a.anchor:before{content:"\00A7";font-size:.85em;display:block;padding-top:.1em}
#content h1:hover>a.anchor,#content h1>a.anchor:hover,h2:hover>a.anchor,h2>a.anchor:hover,h3:hover>a.anchor,#toctitle:hover>a.anchor,.sidebarblock>.content>.title:hover>a.anchor,h3>a.anchor:hover,#toctitle>a.anchor:hover,.sidebarblock>.content>.title>a.anchor:hover,h4:hover>a.anchor,h4>a.anchor:hover,h5:hover>a.anchor,h5>a.anchor:hover,h6:hover>a.anchor,h6>a.anchor:hover{visibility:visible}
#content h1>a.link,h2>a.link,h3>a.link,#toctitle>a.link,.sidebarblock>.content>.title>a.link,h4>a.link,h5>a.link,h6>a.link{color:#ba3925;text-decoration:none}
#content h1>a.link:hover,h2>a.link:hover,h3>a.link:hover,#toctitle>a.link:hover,.sidebarblock>.content>.title>a.link:hover,h4>a.link:hover,h5>a.link:hover,h6>a.link:hover{color:#a53221}
.audioblock,.imageblock,.literalblock,.listingblock,.stemblock,.videoblock{margin-bottom:1.25em}
.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{text-rendering:optimizeLegibility;text-align:left;font-family:"Noto Serif","DejaVu Serif",serif;font-size:1rem;font-style:italic}
table.tableblock>caption.title{white-space:nowrap;overflow:visible;max-width:0}
.paragraph.lead>p,#preamble>.sectionbody>.paragraph:first-of-type p{color:rgba(0,0,0,.85)}
table.tableblock #preamble>.sectionbody>.paragraph:first-of-type p{font-size:inherit}
.admonitionblock>table{border-collapse:separate;border:0;background:none;width:100%}
.admonitionblock>table td.icon{text-align:center;width:80px}
.admonitionblock>table td.icon img{max-width:none}
.admonitionblock>table td.icon .title{font-weight:bold;font-family:"Open Sans","DejaVu Sans",sans-serif;text-transform:uppercase}
.admonitionblock>table td.content{padding-left:1.125em;padding-right:1.25em;border-left:1px solid #ddddd8;color:rgba(0,0,0,.6)}
.admonitionblock>table td.content>:last-child>:last-child{margin-bottom:0}
.exampleblock>.content{border-style:solid;border-width:1px;border-color:#e6e6e6;margin-bottom:1.25em;padding:1.25em;background:#fff;-webkit-border-radius:4px;border-radius:4px}
.exampleblock>.content>:first-child{margin-top:0}
.exampleblock>.content>:last-child{margin-bottom:0}
.sidebarblock{border-style:solid;border-width:1px;border-color:#e0e0dc;margin-bottom:1.25em;padding:1.25em;background:#f8f8f7;-webkit-border-radius:4px;border-radius:4px}
.sidebarblock>:first-child{margin-top:0}
.sidebarblock>:last-child{margin-bottom:0}
.sidebarblock>.content>.title{color:#7a2518;margin-top:0;text-align:center}
.exampleblock>.content>:last-child>:last-child,.exampleblock>.content .olist>ol>li:last-child>:last-child,.exampleblock>.content .ulist>ul>li:last-child>:last-child,.exampleblock>.content .qlist>ol>li:last-child>:last-child,.sidebarblock>.content>:last-child>:last-child,.sidebarblock>.content .olist>ol>li:last-child>:last-child,.sidebarblock>.content .ulist>ul>li:last-child>:last-child,.sidebarblock>.content .qlist>ol>li:last-child>:last-child{margin-bottom:0}
.literalblock pre,.listingblock pre:not(.highlight),.listingblock pre[class="highlight"],.listingblock pre[class^="highlight "],.listingblock pre.CodeRay,.listingblock pre.prettyprint{background:#f7f7f8}
.sidebarblock .literalblock pre,.sidebarblock .listingblock pre:not(.highlight),.sidebarblock .listingblock pre[class="highlight"],.sidebarblock .listingblock pre[class^="highlight "],.sidebarblock .listingblock pre.CodeRay,.sidebarblock .listingblock pre.prettyprint{background:#f2f1f1}
.literalblock pre,.literalblock pre[class],.listingblock pre,.listingblock pre[class]{-webkit-border-radius:4px;border-radius:4px;word-wrap:break-word;padding:1em;font-size:.8125em}
.literalblock pre.nowrap,.literalblock pre[class].nowrap,.listingblock pre.nowrap,.listingblock pre[class].nowrap{overflow-x:auto;white-space:pre;word-wrap:normal}
@media only screen and (min-width:768px){.literalblock pre,.literalblock pre[class],.listingblock pre,.listingblock pre[class]{font-size:.90625em}}
@media only screen and (min-width:1280px){.literalblock pre,.literalblock pre[class],.listingblock pre,.listingblock pre[class]{font-size:1em}}
.literalblock.output pre{color:#f7f7f8;background-color:rgba(0,0,0,.9)}
.listingblock pre.highlightjs{padding:0}
.listingblock pre.highlightjs>code{padding:1em;-webkit-border-radius:4px;border-radius:4px}
.listingblock pre.prettyprint{border-width:0}
.listingblock>.content{position:relative}
.listingblock code[data-lang]:before{display:none;content:attr(data-lang);position:absolute;font-size:.75em;top:.425rem;right:.5rem;line-height:1;text-transform:uppercase;color:#999}
.listingblock:hover code[data-lang]:before{display:block}
.listingblock.terminal pre .command:before{content:attr(data-prompt);padding-right:.5em;color:#999}
.listingblock.terminal pre .command:not([data-prompt]):before{content:"$"}
table.pyhltable{border-collapse:separate;border:0;margin-bottom:0;background:none}
table.pyhltable td{vertical-align:top;padding-top:0;padding-bottom:0;line-height:1.45}
table.pyhltable td.code{padding-left:.75em;padding-right:0}
pre.pygments .lineno,table.pyhltable td:not(.code){color:#999;padding-left:0;padding-right:.5em;border-right:1px solid #ddddd8}
pre.pygments .lineno{display:inline-block;margin-right:.25em}
table.pyhltable .linenodiv{background:none!important;padding-right:0!important}
.quoteblock{margin:0 1em 1.25em 1.5em;display:table}
.quoteblock>.title{margin-left:-1.5em;margin-bottom:.75em}
.quoteblock blockquote,.quoteblock blockquote p{color:rgba(0,0,0,.85);font-size:1.15rem;line-height:1.75;word-spacing:.1em;letter-spacing:0;font-style:italic;text-align:justify}
.quoteblock blockquote{margin:0;padding:0;border:0}
.quoteblock blockquote:before{content:"\201c";float:left;font-size:2.75em;font-weight:bold;line-height:.6em;margin-left:-.6em;color:#7a2518;text-shadow:0 1px 2px rgba(0,0,0,.1)}
.quoteblock blockquote>.paragraph:last-child p{margin-bottom:0}
.quoteblock .attribution{margin-top:.5em;margin-right:.5ex;text-align:right}
.quoteblock .quoteblock{margin-left:0;margin-right:0;padding:.5em 0;border-left:3px solid rgba(0,0,0,.6)}
.quoteblock .quoteblock blockquote{padding:0 0 0 .75em}
.quoteblock .quoteblock blockquote:before{display:none}
.verseblock{margin:0 1em 1.25em 1em}
.verseblock pre{font-family:"Open Sans","DejaVu Sans",sans;font-size:1.15rem;color:rgba(0,0,0,.85);font-weight:300;text-rendering:optimizeLegibility}
.verseblock pre strong{font-weight:400}
.verseblock .attribution{margin-top:1.25rem;margin-left:.5ex}
.quoteblock .attribution,.verseblock .attribution{font-size:.9375em;line-height:1.45;font-style:italic}
.quoteblock .attribution br,.verseblock .attribution br{display:none}
.quoteblock .attribution cite,.verseblock .attribution cite{display:block;letter-spacing:-.025em;color:rgba(0,0,0,.6)}
.quoteblock.abstract{margin:0 0 1.25em 0;display:block}
.quoteblock.abstract blockquote,.quoteblock.abstract blockquote p{text-align:left;word-spacing:0}
.quoteblock.abstract blockquote:before,.quoteblock.abstract blockquote p:first-of-type:before{display:none}
table.tableblock{max-width:100%;border-collapse:separate}
table.tableblock td>.paragraph:last-child p>p:last-child,table.tableblock th>p:last-child,table.tableblock td>p:last-child{margin-bottom:0}
table.tableblock,th.tableblock,td.tableblock{border:0 solid #dedede}
table.grid-all th.tableblock,table.grid-all td.tableblock{border-width:0 1px 1px 0}
table.grid-all tfoot>tr>th.tableblock,table.grid-all tfoot>tr>td.tableblock{border-width:1px 1px 0 0}
table.grid-cols th.tableblock,table.grid-cols td.tableblock{border-width:0 1px 0 0}
table.grid-all *>tr>.tableblock:last-child,table.grid-cols *>tr>.tableblock:last-child{border-right-width:0}
table.grid-rows th.tableblock,table.grid-rows td.tableblock{border-width:0 0 1px 0}
table.grid-all tbody>tr:last-child>th.tableblock,table.grid-all tbody>tr:last-child>td.tableblock,table.grid-all thead:last-child>tr>th.tableblock,table.grid-rows tbody>tr:last-child>th.tableblock,table.grid-rows tbody>tr:last-child>td.tableblock,table.grid-rows thead:last-child>tr>th.tableblock{border-bottom-width:0}
table.grid-rows tfoot>tr>th.tableblock,table.grid-rows tfoot>tr>td.tableblock{border-width:1px 0 0 0}
table.frame-all{border-width:1px}
table.frame-sides{border-width:0 1px}
table.frame-topbot{border-width:1px 0}
th.halign-left,td.halign-left{text-align:left}
th.halign-right,td.halign-right{text-align:right}
th.halign-center,td.halign-center{text-align:center}
th.valign-top,td.valign-top{vertical-align:top}
th.valign-bottom,td.valign-bottom{vertical-align:bottom}
th.valign-middle,td.valign-middle{vertical-align:middle}
table thead th,table tfoot th{font-weight:bold}
tbody tr th{display:table-cell;line-height:1.6;background:#f7f8f7}
tbody tr th,tbody tr th p,tfoot tr th,tfoot tr th p{color:rgba(0,0,0,.8);font-weight:bold}
p.tableblock>code:only-child{background:none;padding:0}
p.tableblock{font-size:1em}
td>div.verse{white-space:pre}
ol{margin-left:1.75em}
ul li ol{margin-left:1.5em}
dl dd{margin-left:1.125em}
dl dd:last-child,dl dd:last-child>:last-child{margin-bottom:0}
ol>li p,ul>li p,ul dd,ol dd,.olist .olist,.ulist .ulist,.ulist .olist,.olist .ulist{margin-bottom:.625em}
ul.unstyled,ol.unnumbered,ul.checklist,ul.none{list-style-type:none}
ul.unstyled,ol.unnumbered,ul.checklist{margin-left:.625em}
ul.checklist li>p:first-child>.fa-square-o:first-child,ul.checklist li>p:first-child>.fa-check-square-o:first-child{width:1em;font-size:.85em}
ul.checklist li>p:first-child>input[type="checkbox"]:first-child{width:1em;position:relative;top:1px}
ul.inline{margin:0 auto .625em auto;margin-left:-1.375em;margin-right:0;padding:0;list-style:none;overflow:hidden}
ul.inline>li{list-style:none;float:left;margin-left:1.375em;display:block}
ul.inline>li>*{display:block}
.unstyled dl dt{font-weight:400;font-style:normal}
ol.arabic{list-style-type:decimal}
ol.decimal{list-style-type:decimal-leading-zero}
ol.loweralpha{list-style-type:lower-alpha}
ol.upperalpha{list-style-type:upper-alpha}
ol.lowerroman{list-style-type:lower-roman}
ol.upperroman{list-style-type:upper-roman}
ol.lowergreek{list-style-type:lower-greek}
.hdlist>table,.colist>table{border:0;background:none}
.hdlist>table>tbody>tr,.colist>table>tbody>tr{background:none}
td.hdlist1,td.hdlist2{vertical-align:top;padding:0 .625em}
td.hdlist1{font-weight:bold;padding-bottom:1.25em}
.literalblock+.colist,.listingblock+.colist{margin-top:-.5em}
.colist>table tr>td:first-of-type{padding:0 .75em;line-height:1}
.colist>table tr>td:last-of-type{padding:.25em 0}
.thumb,.th{line-height:0;display:inline-block;border:solid 4px #fff;-webkit-box-shadow:0 0 0 1px #ddd;box-shadow:0 0 0 1px #ddd}
.imageblock.left,.imageblock[style*="float: left"]{margin:.25em .625em 1.25em 0}
.imageblock.right,.imageblock[style*="float: right"]{margin:.25em 0 1.25em .625em}
.imageblock>.title{margin-bottom:0}
.imageblock.thumb,.imageblock.th{border-width:6px}
.imageblock.thumb>.title,.imageblock.th>.title{padding:0 .125em}
.image.left,.image.right{margin-top:.25em;margin-bottom:.25em;display:inline-block;line-height:0}
.image.left{margin-right:.625em}
.image.right{margin-left:.625em}
a.image{text-decoration:none;display:inline-block}
a.image object{pointer-events:none}
sup.footnote,sup.footnoteref{font-size:.875em;position:static;vertical-align:super}
sup.footnote a,sup.footnoteref a{text-decoration:none}
sup.footnote a:active,sup.footnoteref a:active{text-decoration:underline}
#footnotes{padding-top:.75em;padding-bottom:.75em;margin-bottom:.625em}
#footnotes hr{width:20%;min-width:6.25em;margin:-.25em 0 .75em 0;border-width:1px 0 0 0}
#footnotes .footnote{padding:0 .375em 0 .225em;line-height:1.3334;font-size:.875em;margin-left:1.2em;text-indent:-1.05em;margin-bottom:.2em}
#footnotes .footnote a:first-of-type{font-weight:bold;text-decoration:none}
#footnotes .footnote:last-of-type{margin-bottom:0}
#content #footnotes{margin-top:-.625em;margin-bottom:0;padding:.75em 0}
.gist .file-data>table{border:0;background:#fff;width:100%;margin-bottom:0}
.gist .file-data>table td.line-data{width:99%}
div.unbreakable{page-break-inside:avoid}
.big{font-size:larger}
.small{font-size:smaller}
.underline{text-decoration:underline}
.overline{text-decoration:overline}
.line-through{text-decoration:line-through}
.aqua{color:#00bfbf}
.aqua-background{background-color:#00fafa}
.black{color:#000}
.black-background{background-color:#000}
.blue{color:#0000bf}
.blue-background{background-color:#0000fa}
.fuchsia{color:#bf00bf}
.fuchsia-background{background-color:#fa00fa}
.gray{color:#606060}
.gray-background{background-color:#7d7d7d}
.green{color:#006000}
.green-background{background-color:#007d00}
.lime{color:#00bf00}
.lime-background{background-color:#00fa00}
.maroon{color:#600000}
.maroon-background{background-color:#7d0000}
.navy{color:#000060}
.navy-background{background-color:#00007d}
.olive{color:#606000}
.olive-background{background-color:#7d7d00}
.purple{color:#600060}
.purple-background{background-color:#7d007d}
.red{color:#bf0000}
.red-background{background-color:#fa0000}
.silver{color:#909090}
.silver-background{background-color:#bcbcbc}
.teal{color:#006060}
.teal-background{background-color:#007d7d}
.white{color:#bfbfbf}
.white-background{background-color:#fafafa}
.yellow{color:#bfbf00}
.yellow-background{background-color:#fafa00}
span.icon>.fa{cursor:default}
.admonitionblock td.icon [class^="fa icon-"]{font-size:2.5em;text-shadow:1px 1px 2px rgba(0,0,0,.5);cursor:default}
.admonitionblock td.icon .icon-note:before{content:"\f05a";color:#19407c}
.admonitionblock td.icon .icon-tip:before{content:"\f0eb";text-shadow:1px 1px 2px rgba(155,155,0,.8);color:#111}
.admonitionblock td.icon .icon-warning:before{content:"\f071";color:#bf6900}
.admonitionblock td.icon .icon-caution:before{content:"\f06d";color:#bf3400}
.admonitionblock td.icon .icon-important:before{content:"\f06a";color:#bf0000}
.conum[data-value]{display:inline-block;color:#fff!important;background-color:rgba(0,0,0,.8);-webkit-border-radius:100px;border-radius:100px;text-align:center;font-size:.75em;width:1.67em;height:1.67em;line-height:1.67em;font-family:"Open Sans","DejaVu Sans",sans-serif;font-style:normal;font-weight:bold}
.conum[data-value] *{color:#fff!important}
.conum[data-value]+b{display:none}
.conum[data-value]:after{content:attr(data-value)}
pre .conum[data-value]{position:relative;top:-.125em}
b.conum *{color:inherit!important}
.conum:not([data-value]):empty{display:none}
dt,th.tableblock,td.content,div.footnote{text-rendering:optimizeLegibility}
h1,h2,p,td.content,span.alt{letter-spacing:-.01em}
p strong,td.content strong,div.footnote strong{letter-spacing:-.005em}
p,blockquote,dt,td.content,span.alt{font-size:1.0625rem}
p{margin-bottom:1.25rem}
.sidebarblock p,.sidebarblock dt,.sidebarblock td.content,p.tableblock{font-size:1em}
.exampleblock>.content{background-color:#fffef7;border-color:#e0e0dc;-webkit-box-shadow:0 1px 4px #e0e0dc;box-shadow:0 1px 4px #e0e0dc}
.print-only{display:none!important}
@media print{@page{margin:1.25cm .75cm}
*{-webkit-box-shadow:none!important;box-shadow:none!important;text-shadow:none!important}
a{color:inherit!important;text-decoration:underline!important}
a.bare,a[href^="#"],a[href^="mailto:"]{text-decoration:none!important}
a[href^="http:"]:not(.bare):after,a[href^="https:"]:not(.bare):after{content:"(" attr(href) ")";display:inline-block;font-size:.875em;padding-left:.25em}
abbr[title]:after{content:" (" attr(title) ")"}
pre,blockquote,tr,img,object,svg{page-break-inside:avoid}
thead{display:table-header-group}
svg{max-width:100%}
p,blockquote,dt,td.content{font-size:1em;orphans:3;widows:3}
h2,h3,#toctitle,.sidebarblock>.content>.title{page-break-after:avoid}
#toc,.sidebarblock,.exampleblock>.content{background:none!important}
#toc{border-bottom:1px solid #ddddd8!important;padding-bottom:0!important}
.sect1{padding-bottom:0!important}
.sect1+.sect1{border:0!important}
#header>h1:first-child{margin-top:1.25rem}
body.book #header{text-align:center}
body.book #header>h1:first-child{border:0!important;margin:2.5em 0 1em 0}
body.book #header .details{border:0!important;display:block;padding:0!important}
body.book #header .details span:first-child{margin-left:0!important}
body.book #header .details br{display:block}
body.book #header .details br+span:before{content:none!important}
body.book #toc{border:0!important;text-align:left!important;padding:0!important;margin:0!important}
body.book #toc,body.book #preamble,body.book h1.sect0,body.book .sect1>h2{page-break-before:always}
.listingblock code[data-lang]:before{display:block}
#footer{background:none!important;padding:0 .9375em}
#footer-text{color:rgba(0,0,0,.6)!important;font-size:.9em}
.hide-on-print{display:none!important}
.print-only{display:block!important}
.hide-for-print{display:none!important}
.show-for-print{display:inherit!important}}
</style>
</head>
<body class="book">
<div id="content">
<div class="sect1">
<h2 id="work-with-jet">3. Work with Jet</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="start-jet">3.1. Start Jet and Submit Jobs to It</h3>
<div class="paragraph">
<p>To create a Jet cluster, we simply start some Jet instances. Normally
these would be started on separate machines, but for simple practice
we can use the same JVM for two instances. Even though they are in the
same JVM, they&#8217;ll communicate over the network interface.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">public class WordCount {
    public static void main(String[] args) {
        JetInstance jet = Jet.newJetInstance();
        Jet.newJetInstance();
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>These two instances should automatically discover each other using IP
multicast and form a cluster. You should see a log output similar to the
following:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>Members [2] {
  Member [10.0.1.3]:5701 - f1e30062-e87e-4e97-83bc-6b4756ef6ea3
  Member [10.0.1.3]:5702 - d7b66a8c-5bc1-4476-a528-795a8a2d9d97 this
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>This means the members successfully formed a cluster. Since the Jet
instances start their own threads, it is important to explicitly shut
them down at the end of your program; otherwise the Java process will
remain alive after the <code>main()</code> method completes:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">public class WordCount {
    public static void main(String[] args) {
        try {
            JetInstance jet = Jet.newJetInstance();
            Jet.newJetInstance();

            ... work with Jet ...

        } finally {
            Jet.shutdownAll();
        }
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>This is how you submit a Jet pipeline for execution:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">jet.newJob(pipeline).join();</code></pre>
</div>
</div>
<div class="paragraph">
<p>Alternatively, you can submit a Core API DAG:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">jet.newJob(dag).join();</code></pre>
</div>
</div>
<div class="paragraph">
<p>Code samples with
<a href="https://github.com/hazelcast/hazelcast-jet-code-samples/blob/master/refman/src/main/java/refman/WordCountRefMan.java">the pipeline</a>
and
<a href="https://github.com/hazelcast/hazelcast-jet-code-samples/blob/master/refman/src/main/java/refman/WordCountCoreApiRefMan.java">the Core API DAG</a>
are available at our Code Samples repo.</p>
</div>
<div class="sect3">
<h4 id="jobconfig">3.1.1. JobConfig</h4>
<div class="paragraph">
<p>To gain more control over how Jet will run your job, you can pass in
a <code>JobConfig</code> instance. For example, you can give your job a human-
readable name:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">JobConfig cfg = new JobConfig();
cfg.setName("my job");
jet.newJob(pipeline, cfg);</code></pre>
</div>
</div>
<div class="paragraph">
<p>In the <a href="#practical-considerations">Practical Considerations</a> section
we&#8217;ll deepen this story and explain how to use the <code>JobConfig</code> to
to submit a job to a Jet cluster in production.</p>
</div>
</div>
<div class="sect3">
<h4 id="manage-a-submitted-job">3.1.2. Manage a Submitted Job</h4>
<div class="paragraph">
<p><code>jet.newJob()</code> returns a <code>Job</code> object, which you can use to monitor the
job and change its status. You can get the job&#8217;s name, configuration, and
submission time via <code>job.getName()</code>, <code>job.getConfig()</code>, and
<code>job.getSubmissionTime()</code> methods. <code>job.getStatus()</code> will give you the
current status of the job (running, failed, completed etc.). You can also
call <code>Job.getFuture()</code> to block until the job completes and then get its
final outcome (either success or failure).</p>
</div>
<div class="paragraph">
<p>Jet does not support canceling the job with <code>future.cancel()</code>, instead
you must call <code>job.cancel()</code>. This is due to the mismatch in the
semantics between <code>future.cancel()</code> on one side and <code>job.cancel()</code> plus
<code>job.getStatus()</code> on the other: the future immediately transitions to
"completed by cancellation", but it will take some time until the actual
job in the cluster changes to that state. Not to confuse the users with
these differences we decided to make <code>future.cancel()</code> fail with an
exception.</p>
</div>
</div>
<div class="sect3">
<h4 id="get-a-list-of-all-submitted-jobs">3.1.3. Get a List of all Submitted Jobs</h4>
<div class="paragraph">
<p>Jet keeps an inventory of all the jobs submitted to it, including those
that have already completed. Access the full list with <code>jet.getJobs()</code>.
You can use any <code>Job</code> instance from that list to monitor and manage a
job, whether it was you or some other client that submitted it.</p>
</div>
<div class="paragraph">
<p>To get a more focused list of jobs, you can call <code>jet.getJobs(name)</code> to
get all the jobs with that name that were submitted since Jet started,
or <code>jet.getJob(name)</code> to get just the latest such job.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="pipeline-api">3.2. Build Your Computation Pipeline</h3>
<div class="sect3">
<h4 id="the-shape-of-a-pipeline">3.2.1. The Shape of a Pipeline</h4>
<div class="paragraph">
<p>The general shape of any data processing pipeline is <code>drawFromSource &#8594;
transform &#8594; drainToSink</code> and the natural way to build it is from source
to sink. The
<a href="http://docs.hazelcast.org/docs/jet/latest-dev/javadoc/com/hazelcast/jet/Pipeline.html">Pipeline</a>
API follows this pattern. For example,</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">Pipeline p = Pipeline.create();
p.drawFrom(Sources.&lt;String&gt;list("input"))
 .map(String::toUpperCase)
 .drainTo(Sinks.writeList("result");</code></pre>
</div>
</div>
<div class="paragraph">
<p>In each step, such as <code>drawFrom</code> or <code>drainTo</code>, you create a pipeline
<em>stage</em>. The stage resulting from a <code>drainTo</code> operation is called a
<em>sink stage</em> and you can&#8217;t attach more stages to it. All others are
called <em>compute stages</em> and expect you to attach stages to them.</p>
</div>
<div class="paragraph">
<p>In a more complex scenario you&#8217;ll have several sources, each starting
its own pipeline branch. Then you can merge them in a multi-input
transformation such as co-grouping:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">Pipeline p = Pipeline.create();
ComputeStage&lt;String&gt; src1 = p.drawFrom(Sources.list("src1"));
ComputeStage&lt;String&gt; src2 = p.drawFrom(Sources.list("src2"));
src1.coGroup(wholeItem(), src2, wholeItem(), counting2())
    .drainTo(Sinks.writeMap("result"));</code></pre>
</div>
</div>
<div class="paragraph">
<p>For further details on <code>coGroup</code> please refer to the <a href="#cogroup">dedicated
section</a> below.</p>
</div>
<div class="paragraph">
<p>Symmetrically, the output of a stage can be sent to more than one
destination:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">Pipeline p = Pipeline.create();
ComputeStage&lt;String&gt; src = p.drawFrom(Sources.list("src"));
src.map(String::toUpperCase)
   .drainTo(Sinks.writeList("uppercase"));
src.map(String::toLowerCase)
   .drainTo(Sinks.writeList("lowercase"));</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="choose-your-data-sources-and-sinks">3.2.2. Choose Your Data Sources and Sinks</h4>
<div class="paragraph">
<p>Hazelcast Jet has support for these data sources and sinks:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Hazelcast <code>IMap</code> and <code>ICache</code>, both as a batch source of just their
contents and their event journal as an infinite source</p>
</li>
<li>
<p>Hazelcast <code>IList</code> (batch)</p>
</li>
<li>
<p>Hadoop Distributed File System (HDFS) (batch)</p>
</li>
<li>
<p>Kafka topic (infinite stream)</p>
</li>
<li>
<p>TCP socket (infinite stream)</p>
</li>
<li>
<p>a directory on the filesystem, both as a batch source of the current
file contents and an infinite source of append events to the files</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>You can access most of them via the
<a href="http://docs.hazelcast.org/docs/jet/latest-dev/javadoc/com/hazelcast/jet/Sources.html"><code>Sources</code></a>
and
<a href="http://docs.hazelcast.org/docs/jet/latest-dev/javadoc/com/hazelcast/jet/Sinks.html"><code>Sinks</code></a>
utility classes.
<a href="http://docs.hazelcast.org/docs/jet/latest-dev/javadoc/com/hazelcast/jet/KafkaSources.html">Kafka</a>
and
<a href="http://docs.hazelcast.org/docs/jet/latest-dev/javadoc/com/hazelcast/jet/HdfsSources.html">HDFS</a>
connectors are in their separate modules.</p>
</div>
<div class="paragraph">
<p>There&#8217;s a <a href="#source-sink-connectors">dedicated section</a> that discusses
the topic of data sources and sinks in more detail.</p>
</div>
</div>
<div class="sect3">
<h4 id="compose-the-pipeline-transforms">3.2.3. Compose the Pipeline Transforms</h4>
<div class="paragraph">
<p>The simplest kind of transformation is one that can be done on each item
individually and independent of other items. The major examples are</p>
</div>
<div class="paragraph">
<p><a href="http://docs.hazelcast.org/docs/jet/latest-dev/javadoc/com/hazelcast/jet/ComputeStage.html#map-com.hazelcast.jet.function.DistributedFunction-"><code>map</code></a>,
<a href="http://docs.hazelcast.org/docs/jet/latest-dev/javadoc/com/hazelcast/jet/ComputeStage.html#filter-com.hazelcast.jet.function.DistributedPredicate-"><code>filter</code></a>
and
<a href="http://docs.hazelcast.org/docs/jet/latest-dev/javadoc/com/hazelcast/jet/ComputeStage.html#flatMap-com.hazelcast.jet.function.DistributedFunction-"><code>flatMap</code></a>.
We already saw them in use in the previous examples. <code>map</code> transforms
each item to another item; <code>filter</code> discards items that don&#8217;t match its
predicate; and <code>flatMap</code> transforms each item into zero or more output
items.</p>
</div>
<div class="sect4">
<h5 id="groupby">groupBy</h5>
<div class="paragraph">
<p>Stepping up from the simplest transforms we come to
<a href="http://docs.hazelcast.org/docs/jet/latest-dev/javadoc/com/hazelcast/jet/ComputeStage.html#groupBy-com.hazelcast.jet.function.DistributedFunction-com.hazelcast.jet.aggregate.AggregateOperation1-"><code>groupBy</code></a>,
the quintessential finite stream transform. It groups the data items by
a key computed for each item and performs an aggregate operation over
all the items in a group. The output of this transform is one
aggregation result per distinct grouping key. We saw this one used in
the introductory
<a href="#verify">Hello World</a> code with a word count pipeline:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">Pipeline p = Pipeline.create();
p.drawFrom(Sources.&lt;String&gt;list("text"))
 .flatMap(word -&gt; traverseArray(word.toLowerCase().split("\\W+")))
 .filter(word -&gt; !word.isEmpty())
 .groupBy(wholeItem(), counting())</code></pre>
</div>
</div>
<div class="paragraph">
<p>Let&#8217;s take a moment to analyze the last line. The <code>groupBy()</code> method
takes two parameters: the function to compute the grouping key and the
aggregate operation. In this case the key function is a trivial identity
because we use the word itself as the grouping key and the definition of
the aggregate operation hides behind the <code>counting()</code> method call. This
is a static method in our
<a href="http://docs.hazelcast.org/docs/jet/latest-dev/javadoc/com/hazelcast/jet/aggregate/AggregateOperations.html"><code>AggregateOperations</code></a>
utility class, which provides you with some predefined aggregate
operations. You can also implement your own aggregate operations; please
refer to the section
<a href="#implement-your-aggregate-operation">dedicated to this</a>.</p>
</div>
<div class="paragraph">
<p>If you don&#8217;t need grouping and want to aggregate the full data set
into a single result, you can supply a constant function to compute the
grouping key: <code>DistributedFunctions.constantKey()</code>. It always returns
the string <code>"ALL"</code>.</p>
</div>
<div class="paragraph">
<p>A more complex variety of pipeline transforms are those that merge
several input stages into a single resulting stage. In Hazelcast Jet
there are two such transforms of special interest: <code>coGroup</code> and
<code>hashJoin</code>. We discuss these next.</p>
</div>
</div>
<div class="sect4">
<h5 id="cogroup">coGroup</h5>
<div class="paragraph">
<p><a href="http://docs.hazelcast.org/docs/jet/latest-dev/javadoc/com/hazelcast/jet/ComputeStage.html#coGroup-com.hazelcast.jet.function.DistributedFunction-com.hazelcast.jet.ComputeStage-com.hazelcast.jet.function.DistributedFunction-com.hazelcast.jet.aggregate.AggregateOperation2-"><code>coGroup</code></a>
is a generalization of <code>groupBy</code> to more than one contributing
data stream. Instead of a single <code>accumulate</code> primitive you provide one
for each input stream so the operation can discriminate between them. In
SQL terms it can be interpreted as JOIN coupled with GROUP BY. The JOIN
condition is constrained to matching on the grouping key.</p>
</div>
<div class="paragraph">
<p>Here is the example we already used earlier on this page:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">Pipeline p = Pipeline.create();
ComputeStage&lt;String&gt; src1 = p.drawFrom(Sources.list("src1"));
ComputeStage&lt;String&gt; src2 = p.drawFrom(Sources.list("src2"));
ComputeStage&lt;Tuple2&lt;String, Long&gt;&gt; coGrouped =
        src1.coGroup(wholeItem(), src2, wholeItem(), counting2());</code></pre>
</div>
</div>
<div class="paragraph">
<p>These are the arguments:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><code>wholeItem()</code>: the key extractor function for <code>this</code> stage&#8217;s items</p>
</li>
<li>
<p><code>src2</code>: the other stage to co-group with this one</p>
</li>
<li>
<p><code>wholeItem()</code>: the key extractor function for <code>src2</code> items</p>
</li>
<li>
<p><code>counting2()</code>: the aggregate operation</p>
</li>
</ol>
</div>
<div class="paragraph">
<p><code>counting2()</code> is a factory method returning a 2-way
<a href="#implement-your-aggregate-operation">aggregate operation</a>
which may be defined as follows:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">private static AggregateOperation2&lt;Object, Object, LongAccumulator, Long&gt; counting2() {
    return AggregateOperation
            .withCreate(LongAccumulator::new)
            .andAccumulate0((count, item) -&gt; count.add(1))
            .andAccumulate1((count, item) -&gt; count.add(10))
            .andCombine(LongAccumulator::add)
            .andFinish(LongAccumulator::get);
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>This demonstrates the individual treatment of input streams: stream 1 is
weighted so that each of its items is worth ten items from stream 0.</p>
</div>
<div class="sect5">
<h6 id="cogroup-builder">coGroup Builder</h6>
<div class="paragraph">
<p>If you need to co-group more than three streams, you&#8217;ll have to use the
<a href="http://docs.hazelcast.org/docs/jet/latest-dev/javadoc/com/hazelcast/jet/ComputeStage.html#coGroupBuilder-com.hazelcast.jet.function.DistributedFunction-">co-group builder</a>
object. For example, your goal may be correlating events coming from
different systems, where all the systems serve the same user base. In an
online store you may have separate streams for product page visits,
adding to shopping cart, payments, and deliveries. You want to correlate
all the events associated with the same user. The example below
calculates statistics per category for each user:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">Pipeline p = Pipeline.create();
ComputeStage&lt;PageVisit&gt; pageVisit = p.drawFrom(Sources.list("pageVisit"));
ComputeStage&lt;AddToCart&gt; addToCart = p.drawFrom(Sources.list("addToCart"));
ComputeStage&lt;Payment&gt; payment = p.drawFrom(Sources.list("payment"));
ComputeStage&lt;Delivery&gt; delivery = p.drawFrom(Sources.list("delivery"));

CoGroupBuilder&lt;Long, PageVisit&gt; b = pageVisit.coGroupBuilder(PageVisit::userId);
Tag&lt;PageVisit&gt; pvTag = b.tag0();
Tag&lt;AddToCart&gt; atcTag = b.add(addToCart, AddToCart::userId);
Tag&lt;Payment&gt; pmtTag = b.add(payment, Payment::userId);
Tag&lt;Delivery&gt; delTag = b.add(delivery, Delivery::userId);

ComputeStage&lt;Tuple2&lt;Long, long[]&gt;&gt; coGrouped = b.build(AggregateOperation
        .withCreate(() -&gt; new LongAccumulator[] {
                new LongAccumulator(),
                new LongAccumulator(),
                new LongAccumulator(),
                new LongAccumulator()
        })
        .andAccumulate(pvTag, (accs, pv) -&gt; accs[0].add(pv.loadTime()))
        .andAccumulate(atcTag, (accs, atc) -&gt; accs[1].add(atc.quantity()))
        .andAccumulate(pmtTag, (accs, pm) -&gt; accs[2].add(pm.amount()))
        .andAccumulate(delTag, (accs, d) -&gt; accs[3].add(d.days()))
        .andCombine((accs1, accs2) -&gt; {
                    accs1[0].add(accs2[0]);
                    accs1[1].add(accs2[1]);
                    accs1[2].add(accs2[2]);
                    accs1[3].add(accs2[3]);
                })
        .andFinish(accs -&gt; new long[] {
                accs[0].get(),
                accs[1].get(),
                accs[2].get(),
                accs[3].get()
        })
);</code></pre>
</div>
</div>
<div class="paragraph">
<p>Note the interaction between the co-group building code and the
aggregate operation-building code: the co-group builder gives you type
tags that you then pass to the aggregate operation builder. This
establishes the connection between the streams contributing to the
co-group transform and the aggregate operation processing them. Refer
to the
<a href="#implement-your-aggregate-operation">section on <code>AggregateOperation</code></a>
to learn more about it.</p>
</div>
</div>
</div>
<div class="sect4">
<h5 id="hash-join">hashJoin</h5>
<div class="paragraph">
<p><a href="http://docs.hazelcast.org/docs/jet/latest-dev/javadoc/com/hazelcast/jet/ComputeStage.html#hashJoin-com.hazelcast.jet.ComputeStage-com.hazelcast.jet.JoinClause-com.hazelcast.jet.ComputeStage-com.hazelcast.jet.JoinClause-"><code>hashJoin</code></a>
is a specialization of a general "join" operation, optimized for the use
case of <em>data enrichment</em>. In this scenario there is a single,
potentially infinite data stream (the <em>primary</em> stream), that goes
through a mapping transformation which attaches to each item some more
items found by hashtable lookup. The hashtables have been populated
from all the other streams (the <em>enriching</em> streams) before the
consumption of the primary stream started.</p>
</div>
<div class="paragraph">
<p>For each enriching stream you can specify a pair of key-extracting
functions: one for the enriching item and one for the primary item. This
means that you can define a different join key for each of the enriching
streams. The following example shows a three-way hash-join between the
primary stream of stock trade events and two enriching streams:
<em>products</em> and <em>brokers</em>.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">Pipeline p = Pipeline.create();

// The primary stream: trades
ComputeStage&lt;Trade&gt; trades = p.drawFrom(Sources.&lt;Trade&gt;list("trades"));

// The enriching streams: products and brokers
ComputeStage&lt;Entry&lt;Integer, Product&gt;&gt; prodEntries =
        p.drawFrom(Sources.&lt;Integer, Product&gt;map("products"));
ComputeStage&lt;Entry&lt;Integer, Broker&gt;&gt; brokEntries =
        p.drawFrom(Sources.&lt;Integer, Broker&gt;map("brokers"));

// Join the trade stream with the product and broker streams
ComputeStage&lt;Tuple3&lt;Trade, Product, Broker&gt;&gt; joined = trades.hashJoin(
        prodEntries, joinMapEntries(Trade::productId),
        brokEntries, joinMapEntries(Trade::brokerId)
);</code></pre>
</div>
</div>
<div class="paragraph">
<p>Products are joined on <code>Trade.productId</code> and brokers on
<code>Trade.brokerId</code>. <code>joinMapEntries()</code> returns a <code>JoinClause</code>, which is a
holder of the three functions that specify how to perform a join:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>the key extractor for the primary stream&#8217;s item</p>
</li>
<li>
<p>the key extractor for the enriching stream&#8217;s item</p>
</li>
<li>
<p>the projection function that transforms the enriching stream&#8217;s item
into the item that will be used for enrichment.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Typically the enriching streams will be <code>Map.Entry`s coming from a
key-value store, but you want just the entry value to appear as the
enriching item. In that case you&#8217;ll specify `Map.Entry::getValue</code> as the
projection function. This is what <code>joinMapEntries()</code> does for you. It
takes just one function, primary stream&#8217;s key extractor, and fills in
<code>Entry::getKey</code> and <code>Entry::getValue</code> for the enriching stream key
extractor and the projection function, respectively.</p>
</div>
<div class="paragraph">
<p>In the interest of performance the entire enriching dataset resides on
each cluster member. That&#8217;s why this operation is also known as a
<em>replicated</em> join. This is something to keep in mind when estimating
the RAM requirements for a hash-join operation.</p>
</div>
<div class="sect5">
<h6 id="hashjoin-builder">hashJoin Builder</h6>
<div class="paragraph">
<p>You can hash-join a stream with up to two enriching streams using the
API we demonstrated above. If you have more than two enriching streams,
you&#8217;ll use the
<a href="http://docs.hazelcast.org/docs/jet/latest-dev/javadoc/com/hazelcast/jet/ComputeStage.html#hashJoinBuilder--">hash-join builder</a>.
For example, you may want to enrich a trade with its associated product,
broker, and market:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">Pipeline p = Pipeline.create();

// The primary stream: trades
ComputeStage&lt;Trade&gt; trades = p.drawFrom(Sources.&lt;Trade&gt;list("trades"));

// The enriching streams: products and brokers
ComputeStage&lt;Entry&lt;Integer, Product&gt;&gt; prodEntries =
        p.drawFrom(Sources.&lt;Integer, Product&gt;map("products"));
ComputeStage&lt;Entry&lt;Integer, Broker&gt;&gt; brokEntries =
        p.drawFrom(Sources.&lt;Integer, Broker&gt;map("brokers"));
ComputeStage&lt;Entry&lt;Integer, Market&gt;&gt; marketEntries =
        p.drawFrom(Sources.&lt;Integer, Market&gt;map("markets"));

HashJoinBuilder&lt;Trade&gt; b = trades.hashJoinBuilder();
Tag&lt;Product&gt; prodTag = b.add(prodEntries, joinMapEntries(Trade::productId));
Tag&lt;Broker&gt; brokTag = b.add(brokEntries, joinMapEntries(Trade::brokerId));
Tag&lt;Market&gt; marketTag = b.add(marketEntries, joinMapEntries(Trade::marketId));
ComputeStage&lt;Tuple2&lt;Trade, ItemsByTag&gt;&gt; joined = b.build();</code></pre>
</div>
</div>
<div class="paragraph">
<p>The data type on the hash-joined stage is <code>Tuple2&lt;Trade, ItemsByTag&gt;</code>.
The next snippet shows how to use it to access the primary and enriching
items:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">ComputeStage&lt;String&gt; mapped = joined.map(
        (Tuple2&lt;Trade, ItemsByTag&gt; t) -&gt; {
            Trade trade = t.f0();
            ItemsByTag ibt = t.f1();
            Product product = ibt.get(prodTag);
            Broker broker = ibt.get(brokTag);
            Market market = ibt.get(marketTag);
            return trade + ": " + product + ", " + broker + ", " + market;
        });</code></pre>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="implement-your-aggregate-operation">3.3. Implement Your Aggregate Operation</h3>
<div class="paragraph">
<p>The single most important kind of processing Jet does is aggregation. In
general it is a transformation of a set of input values into a single
output value. The function that does this transformation is called the
"aggregate function". A basic example is <code>sum</code> applied to a set of
integer numbers, but the result can also be a complex value, for example
a list of all the input items.</p>
</div>
<div class="paragraph">
<p>Jet&#8217;s library contains a range of
<a href="http://docs.hazelcast.org/docs/jet/latest-dev/javadoc/com/hazelcast/jet/aggregate/AggregateOperations.html">predefined aggregate functions</a>,
but it also exposes an abstraction, called
<a href="http://docs.hazelcast.org/docs/jet/latest-dev/javadoc/com/hazelcast/jet/aggregate/AggregateOperation.html"><code>AggregateOperation</code></a>,
that allows you to plug in your own. Since Jet does the aggregation in a
parallelized and distributed way, you can&#8217;t simply supply a piece of
Java code that does it; we need you to break it down into several
smaller pieces that fit into Jet&#8217;s processing engine.</p>
</div>
<div class="paragraph">
<p>The ability to compute the aggregate function in parallel comes at a
cost: Jet must be able to give a slice of the total data set to each
processing unit and then combine the partial results from all the units.
The combining step is crucial: it will only make sense if we&#8217;re
combining the partial results of a <em>commutative associative</em> function
(CA for short). On the example of <code>sum</code> this is trivial: we know from
elementary school that <code>+</code> is a CA operation. If you have a stream of
numbers: <code>{17, 37, 5, 11, 42}</code>, you can sum up <code>{17, 5}</code> separately from
<code>{42, 11, 37}</code> and then combine the partial sums (also note the
reordering of the elements).</p>
</div>
<div class="paragraph">
<p>If you need something more complex, like <code>average</code>, it doesn&#8217;t by itself
have this property; however if you add one more ingredient, the <code>finish</code>
function, you can express it easily. Jet allows you to first compute
some CA function, whose partial results can be combined, and then at the
very end apply the <code>finish</code> function on the fully combined result. To
compute the <code>average</code>, your CA function will output the pair <code>(sum,
count)</code>. Two such pairs are trivial to combine by summing each
component. The <code>finish</code> function will be <code>sum / count</code>.</p>
</div>
<div class="paragraph">
<p>In addition to the mathematical side, there is also the practical one:
you have to provide Jet with a specific mutable object, called the
<code>accumulator</code>, which will keep the "running score" of the operation in
progress. For the <code>average</code> example, it would be something like</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">public class AvgAccumulator {
    private long sum;
    private long count;

    public void accumulate(long value) {
        sum += value;
        count++;
    }

    public void combine(AvgAccumulator that) {
        this.sum += that.sum;
        this.count += that.sum;
    }

    public double finish() {
        return (double) sum / count;
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>This object will also have to be serializable, and preferably with
Hazelcast&#8217;s serialization instead of Java&#8217;s because in a group-by
operation there&#8217;s one accumulator per each key and all of them have to
be sent across the network to be combined and finished.</p>
</div>
<div class="paragraph">
<p>Instead of requiring you to write a complete class from scratch, Jet
separates the concern of holding the accumulated state from that of the
computation performed on it. This means that you just need one
accumulator class per the kind of structure that holds the accumulated
data, as opposed to one per each aggregate operation. Jet&#8217;s library
offers in the
<a href="http://docs.hazelcast.org/docs/jet/latest-dev/javadoc/com/hazelcast/jet/accumulator/package-summary.html"><code>com.hazelcast.jet.accumulator</code></a>
package several such classes, one of them being
<a href="http://docs.hazelcast.org/docs/jet/latest-dev/javadoc/com/hazelcast/jet/accumulator/LongLongAccumulator.html"><code>LongLongAccumulator</code></a>,
which is a match for our <code>average</code> function. You&#8217;ll just have to supply
the logic on top of it.</p>
</div>
<div class="paragraph">
<p>Specifically, you have to provide a set of five functions (we call them
"primitives"):</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>create</code> a new accumulator object.</p>
</li>
<li>
<p><code>accumulate</code> the data of an item by mutating the accumulator&#8217;s state.</p>
</li>
<li>
<p><code>combine</code> the contents of the right-hand accumulator into the
left-hand one.</p>
</li>
<li>
<p><code>deduct</code> the contents of the right-hand accumulator from the left-hand
one (undo the effects of <code>combine</code>).</p>
</li>
<li>
<p><code>finish</code> accumulation by transforming the accumulator object into the
final result.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>So far we mentioned all of these except for <code>deduct</code>. This one is
optional and Jet can manage without it, but if you are computing a
sliding window over an infinite stream, this primitive can give a
significant performance boost because it allows Jet to reuse the results
of the previous calculations.</p>
</div>
<div class="paragraph">
<p>If you happen to have a deeper familiarity with JDK&#8217;s java.util.stream
API, you&#8217;ll find <code>AggregateOperation</code> quite similar to
<a href="https://docs.oracle.com/javase/9/docs/api/java/util/stream/Collector.html"><code>Collector</code></a>,
which is also a holder of several functional primitives. Jet&#8217;s
definitions are slightly different, though, and there&#8217;s also the
additional <code>deduct</code> primitive.</p>
</div>
<div class="paragraph">
<p>Let&#8217;s see how this works with our <code>average</code> function. Using
<code>LongLongAccumulator</code> we can express our <code>accumulate</code> primitive as</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">(acc, n) -&gt; {
    acc.setValue1(acc.getValue1() + n);
    acc.setValue2(acc.getValue2() + 1);
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>The <code>finish</code> primitive will be</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">acc -&gt; (double) acc.getValue1() / acc.getValue2()</code></pre>
</div>
</div>
<div class="paragraph">
<p>Now we have to define the other three primitives to match our main
logic. For <code>create</code> we just refer to the constructor:
<code>LongLongAccumulator::new</code>. The <code>combine</code> primitive expects you to
update the left-hand accumulator with the contents of the right-hand
one, so:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">(left, right) -&gt; {
    left.setValue1(left.getValue1() + right.getValue1());
    left.setValue2(left.getValue2() + right.getValue2());
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Deducting must undo the effect of a previous <code>combine</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">(left, right) -&gt; {
    left.setValue1(left.getValue1() - right.getValue1());
    left.setValue2(left.getValue2() - right.getValue2());
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>All put together, we can define our counting operation as follows:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">AggregateOperation1&lt;Long, LongLongAccumulator, Double&gt; aggrOp = AggregateOperation
    .withCreate(LongLongAccumulator::new)
    .andAccumulate((acc, n) -&gt; {
        acc.setValue1(acc.getValue1() + n);
        acc.setValue2(acc.getValue2() + 1);
    })
    .andCombine((left, right) -&gt; {
        left.setValue1(left.getValue1() + right.getValue1());
        left.setValue2(left.getValue2() + right.getValue2());
    })
    .andDeduct((left, right) -&gt; {
        left.setValue1(left.getValue1() - right.getValue1());
        left.setValue2(left.getValue2() - right.getValue2());
    })
    .andFinish(acc -&gt; (double) acc.getValue1() / acc.getValue2());</code></pre>
</div>
</div>
<div class="paragraph">
<p>Let&#8217;s stop for a second to look at the type we got:
<code>AggregateOperation1&lt;Long, LongLongAccumulator, Double&gt;</code>. Its type
parameters are:
1. <code>Long</code>: the type of the input item
2. <code>LongLongAccumulator</code>: the type of the accumulator
3. <code>Double</code>: the type of the result</p>
</div>
<div class="paragraph">
<p>Specifically note the <code>1</code> at the end of the type&#8217;s name: it signifies
that it&#8217;s the specialization of the general <code>AggregateOperation</code> to
exactly one input stream. In Hazelcast Jet you can also perform a
<a href="#cogroup">co-grouping</a>
operation, aggregating several input streams together. Since the number
of input types is variable, the general <code>AggregateOperation</code> type cannot
statically capture them and we need separate subtypes. We decided to
statically support up to three input types; if you need more, you&#8217;ll
have to resort to the less type-safe, general <code>AggregateOperation</code>.</p>
</div>
<div class="paragraph">
<p>Let us now study a use case that calls for co-grouping. We are
interested in the behavior of users in an online shop application and
want to gather the following statistics for each user:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>total load time of the visited product pages</p>
</li>
<li>
<p>quantity of items added to the shopping cart</p>
</li>
<li>
<p>amount paid for bought items</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>This data is dispersed among separate datasets: <code>PageVisit</code>, <code>AddToCart</code>
and <code>Payment</code>. Note that in each case we&#8217;re dealing with a simple <code>sum</code>
applied to a field in the input item. We can perform a co-group
transform with the following aggregate operation:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">Pipeline p = Pipeline.create();
ComputeStage&lt;PageVisit&gt; pageVisit = p.drawFrom(Sources.list("pageVisit"));
ComputeStage&lt;AddToCart&gt; addToCart = p.drawFrom(Sources.list("addToCart"));
ComputeStage&lt;Payment&gt; payment = p.drawFrom(Sources.list("payment"));

AggregateOperation3&lt;PageVisit, AddToCart, Payment, LongAccumulator[], long[]&gt; aggrOp =
        AggregateOperation
                .withCreate(() -&gt; new LongAccumulator[] {
                        new LongAccumulator(),
                        new LongAccumulator(),
                        new LongAccumulator()
                })
                .&lt;PageVisit&gt;andAccumulate0((accs, pv) -&gt; accs[0].add(pv.loadTime()))
                .&lt;AddToCart&gt;andAccumulate1((accs, atc) -&gt; accs[1].add(atc.quantity()))
                .&lt;Payment&gt;andAccumulate2((accs, pm) -&gt; accs[2].add(pm.amount()))
                .andCombine((accs1, accs2) -&gt; {
                    accs1[0].add(accs2[0]);
                    accs1[1].add(accs2[1]);
                    accs1[2].add(accs2[2]);
                })
                .andFinish(accs -&gt; new long[] {
                        accs[0].get(),
                        accs[1].get(),
                        accs[2].get()
                });
ComputeStage&lt;Entry&lt;Long, long[]&gt;&gt; coGrouped = pageVisit.coGroup(PageVisit::userId,
        addToCart, AddToCart::userId,
        payment, Payment::userId,
        aggrOp);</code></pre>
</div>
</div>
<div class="paragraph">
<p>Note how we got an <code>AggregateOperation3</code> and how it captured each input
type. When we use it as an argument to a co-group transform, the
compiler will ensure that the `ComputeStage`s we attach it to have the
correct type and are in the correct order.</p>
</div>
<div class="paragraph">
<p>On the other hand, if you use the
<a href="#cogroup-builder">co-group builder</a>
object, you&#8217;ll construct the aggregate operation by calling
<code>andAccumulate(tag, accFn)</code> with all the tags you got from the
co-group builder, and the static type will be just <code>AggregateOperation</code>.
The compiler won&#8217;t be able to match up the inputs to their treatment in
the aggregate operation.</p>
</div>
</div>
<div class="sect2">
<h3 id="infinite-stream-processing">3.4. Infinite Stream Processing</h3>
<div class="paragraph">
<p>Distributed stream processing has two major variants: finite and
infinite. Let&#8217;s discuss this difference and some concerns specific to
infinite streams.</p>
</div>
<div class="sect3">
<h4 id="finite-aka-batch-processing">3.4.1. Finite aka. Batch Processing</h4>
<div class="paragraph">
<p>Finite stream (batch) processing is the simpler variant where you
provide one or more pre-existing datasets and order Jet to mine them for
interesting information. The most important workhorse in this area is
the "join, group and aggregate" operation: you define a classifying
function that computes a grouping key for each of the datasets and
an aggregate operation that will be performed on all the items in each
group, yielding one result item per distinct key.</p>
</div>
</div>
<div class="sect3">
<h4 id="the-importance-of-right-now">3.4.2. The Importance of "Right Now"</h4>
<div class="paragraph">
<p>In batch jobs the data we process represents a point-in-time snapshot of
our state of knowledge (for example, warehouse inventory where
individual data items represent items on stock). We can recapitulate
each business day by setting up regular snapshots and batch jobs.
However, there is more value hiding in the freshest data - our
business can win by reacting to minute-old or even second-old updates.
To get there we must make a shift from the finite to the infinite: from
the snapshot to a continuous influx of events that update our state of
knowledge. For example, an event could pop up in our stream every time
an item is checked in or out of the warehouse.</p>
</div>
<div class="paragraph">
<p>A single word that captures the above story is <em>latency</em>: we want our
system to minimize the latency from observing an event to acting upon
it.</p>
</div>
</div>
<div class="sect3">
<h4 id="windowing">3.4.3. Windowing</h4>
<div class="paragraph">
<p>In an infinite stream, the dimension of time is always there.  Consider
a batch job: it may process a dataset labeled "Wednesday", but the
computation itself doesn&#8217;t have to know this. Its results will be
understood from the outside to be "about Wednesday". An infinite stream,
on the other hand, delivers information about the reality as it is
unfolding, in near-real time, and the computation itself must deal with
time explicitly.</p>
</div>
<div class="paragraph">
<p>Another point: in a batch it is obvious when to stop aggregating and
emit the results: when we have exhausted the whole dataset. However,
with infinite streams we need a policy on how to select finite chunks
whose aggregate results we are interested in. This is called
<em>windowing</em>. We imagine the window as a time interval laid over the time
axis. A given window contains only the events that belong to that
interval.</p>
</div>
<div class="paragraph">
<p>A very basic type of window is the <em>tumbling window</em>, which can be
imagined to advance by tumbling over each time. There is no overlap
between the successive positions of the window. In other words, it
splits the time-series data into batches delimited by points on the time
axis. The result of this is very similar to running a sequence of batch
jobs, one per time interval.</p>
</div>
<div class="paragraph">
<p>A more useful and powerful policy is the <em>sliding window</em>: instead of
splitting the data at fixed boundaries, it lets it roll in
incrementally, new data gradually displacing the old. The window
(pseudo)continuously slides along the time axis.</p>
</div>
<div class="paragraph">
<p>Another popular policy is called the <em>session window</em> and it&#8217;s used to
detect bursts of activity by correlating events bunched together on the
time axis. In an analogy to a user&#8217;s session with a web application,
the session window "closes" when the specified session timeout elapses
with no further events.</p>
</div>
</div>
<div class="sect3">
<h4 id="time-ordering">3.4.4. Time Ordering and the Watermark</h4>
<div class="paragraph">
<p>Usually the time of observing an event is explicitly written in the
stream item. There is no guarantee that items will occur in the stream
ordered by the value of that field; in fact in many cases it is certain
that they won&#8217;t. Consider events gathered from users of a mobile app:
for all kinds of reasons the items will arrive to our datacenter out of
order, even with significant delays due to connectivity issues.</p>
</div>
<div class="paragraph">
<p>This disorder in the event stream makes it more difficult to formally
specify a rule that tells us at which point all the data for a given
window has been gathered, allowing us to emit the aggregated result.</p>
</div>
<div class="paragraph">
<p>To approach these challenges we use the concept of the
<a href="http://docs.hazelcast.org/docs/jet/latest-dev/javadoc/com/hazelcast/jet/core/Watermark.html"><em>watermark</em></a>.
It is a timestamped item inserted into the stream that tells us "from
this point on there will be no more items with timestamp less than
this". Unfortunately, we almost never know for sure when such a
statement becomes true and there is always a chance some events will
arrive even later. If we do observe such an offending item, we must
categorize it as "too late" and just filter it out.</p>
</div>
<div class="paragraph">
<p>Note the tension in defining the "perfect" watermark for a given use
case: it is bad both the more we wait and the less we wait to emit a
given watermark. The more we wait, the higher the latency of getting the
results of the computation; the less we wait, the worse their accuracy
due to missed events.</p>
</div>
<div class="paragraph">
<p>For the above reasons the policy to compute the watermark is not
hardcoded and you as the user must decide which one to use. Hazelcast
Jet comes with some predefined policies which you can tune with a few
configurable parameters. You can also write your own policy from
scratch.</p>
</div>
</div>
<div class="sect3">
<h4 id="fault-tolerance-and-processing-guarantees">3.4.5. Fault Tolerance and Processing Guarantees</h4>
<div class="paragraph">
<p>One less-than-obvious consequence of stepping up from finite to infinite
streams is the difficulty of forever maintaining the continuity of the
output, even in the face of changing cluster topology. A Jet node may
leave the cluster due to an internal error, loss of networking, or
deliberate shutdown for maintenance. This will cause the computation job
to be suspended. Except for the obvious problem of new data pouring in
while we&#8217;re down, we have a much more fiddly issue of restarting the
computation in a differently laid-out cluster exactly where it left off
and neither miss anything nor process it twice. The technical term for
this is the "exactly-once processing guarantee".</p>
</div>
<div class="paragraph">
<p>Hazelcast Jet transparently coordinates the execution of submitted jobs.
One member is assigned the role of the <em>coordinator</em>. It tells other
members what to do and they report to it any status changes. The
coordinator may fail and the cluster will automatically re-elect another
one. If any other member fails, the coordinator restarts the job on the
remaining members.</p>
</div>
<div class="paragraph">
<p>In Jet, job submission works on the fire-and-forget principle: once you
have submitted it, you can disconnect with no effect on the job. Any
other client or Jet member can request a local <code>Job</code> instance which
allows it to monitor and manage the job.</p>
</div>
<div class="sect4">
<h5 id="snapshotting-the-state-of-computation">Snapshotting the State of Computation</h5>
<div class="paragraph">
<p>To be able to tolerate failures, Jet takes snapshots of the entire state
of the computation at regular intervals. The snapshot is coordinated
across the cluster and synchronized with a checkpoint on the data
source. The source must ensure that, in the case of a restart, it will
be able to replay all the data it emitted after the last checkpoint.
Each of the other components must ensure it will be able to restore its
processing state to exactly what it was at the last snapshot. If a
cluster member goes away, Jet will restart the job on the remaining
members, rewind the sources to the last checkpoint, restore the state of
processing from the last snapshot, and then seamlessly
continue from that point.</p>
</div>
</div>
<div class="sect4">
<h5 id="level-of-safety">Level of Safety</h5>
<div class="paragraph">
<p>Jet stores job metadata and snapshot data in Hazelcast <code>IMap`s, which
means that you don&#8217;t have to install any other system for fault
tolerance. However, the fault tolerance mechanism is at most as safe as
the `IMap</code> itself. Therefore, it is important to configure level of
safety for the <code>IMap</code>. <code>IMap</code> is a replicated in-memory data structure,
storing each key-value pair on a configurable number of cluster members.
By default it will store one primary copy plus one backup copy,
resulting in a system that tolerates the failure of a single member at a
time. You can tweak this setting when starting Jet, for example increase
the backup count to two:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">JetConfig config = new JetConfig();
config.getInstanceConfig().setBackupCount(2);
JetInstance = Jet.newJetInstance(config);</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="exactly-once">Exactly-Once</h5>
<div class="paragraph">
<p>As always when guarantees are involved, the principle of the weakest
link applies: if any part of the system is unable to provide it, the
system as a whole fails to provide it. The critical points are the
sources and sinks because they are the boundary between the domain under
Jet&#8217;s control and the environment. A source must be able to consistently
replay data to Jet from a point it asks for, and the sink must either
support transactions or be <em>idempotent</em>, tolerating duplicate submission
of data.</p>
</div>
<div class="paragraph">
<p>As of version 0.5, Hazelcast Jet supports exactly-once with the source
being either a Hazelcast <code>IMap</code> or a Kafka topic, and the sink being a
Hazelcast <code>IMap</code>.</p>
</div>
</div>
<div class="sect4">
<h5 id="at-least-once">At-Least-Once</h5>
<div class="paragraph">
<p>A lesser, but still useful guarantee you can configure Jet for is
"at-least-once". In this case no stream item will be missed, but some
items may get processed again after a restart, as if they represented
new events. Jet can provide this guarantee at a higher throughput and
lower latency than exactly-once, and some kinds of data processing can
gracefully tolerate it. In some other cases, however, duplicate
processing of data items can have quite surprising consequences. There
is more information about this in our
<a href="#pitfalls-alo">Under the Hood</a>
chapter.</p>
</div>
<div class="paragraph">
<p>We also have an in-between case: if you configure Jet for exactly-once
but use Kafka as the sink, after a job restart you may get duplicates in
the output. As opposed to duplicating an input item, this is much more
benign because it just means getting the exact same result twice.</p>
</div>
</div>
<div class="sect4">
<h5 id="enabling-snapshotting">Enabling Snapshotting</h5>
<div class="paragraph">
<p>Fault tolerance is off by default. To activate it for a job, create a
<code>JobConfig</code> object and set the
<a href="http://docs.hazelcast.org/docs/jet/latest-dev/javadoc/com/hazelcast/jet/config/JobConfig.html#setProcessingGuarantee-com.hazelcast.jet.config.ProcessingGuarantee-"><em>processing guarantee</em></a>.
You can also configure
<a href="http://docs.hazelcast.org/docs/jet/latest-dev/javadoc/com/hazelcast/jet/config/JobConfig.html#setSnapshotIntervalMillis-long-"><em>snapshot interval</em></a>.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">JobConfig jobConfig = new JobConfig();
jobConfig.setProcessingGuarantee(ProcessingGuarantee.EXACTLY_ONCE);
jobConfig.setSnapshotIntervalMillis(SECONDS.toMillis(10));</code></pre>
</div>
</div>
<div class="paragraph">
<p>Using less frequent snapshots, more data will have to be replayed
and the temporary spike in the latency of the output will be greater.
More frequent snapshots will reduce the throughput and introduce more
latency variation during regular processing.</p>
</div>
</div>
<div class="sect4">
<h5 id="split-brain-protection">Split-Brain Protection</h5>
<div class="paragraph">
<p>A particularly nasty kind of failure is the "split brain": due to a very
specific pattern in the loss of network connectivity the cluster splits
into two parts, where within each part the members see each other, but
none of those in the other part(s). Each part by itself lives on
thinking the other members left the cluster. Now we have two
fully-functioning Jet clusters where there was supposed to be one. Each
one will recover and restart the same Jet job, making a mess in our
application.</p>
</div>
<div class="paragraph">
<p>Hazelcast Jet offers a mechanism to fight off this hazard:
<a href="http://docs.hazelcast.org/docs/jet/latest-dev/javadoc/com/hazelcast/jet/config/JobConfig.html#setSplitBrainProtection-boolean-"><em>split-brain protection</em></a>.
It works by ensuring that a job cannot be restarted in a
cluster whose size isn&#8217;t more than half of what it was before the job
was suspended. Enable split-brain protection like this:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">jobConfig.setSplitBrainProtection(true);</code></pre>
</div>
</div>
<div class="paragraph">
<p>A loophole here is that, after the split brain has occurred, you could
add more members to any of the sub-clusters and have them both grow to
more than half the previous size. Since the job will keep trying to
restart itself and by definition one cluster has no idea of the other&#8217;s
existence, it will restart as soon as the quorum value is reached.</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="scaling-up-jobs">3.4.6. Scaling up Jobs</h4>
<div class="paragraph">
<p>After a job is submitted to the cluster, new nodes can be started and
the job can be scaled up. Hazelcast Jet 0.6 introduces a new method into
the <code>Job</code> interface for this purpose. When <code>Job.restart()</code> is invoked,
ongoing execution of the job is interrupted and a new execution is
scheduled. If the snapshotting mechanism enabled, the job is restarted
from the last successful snapshot. Therefore, the restart procedure
respects to the configured processing guarantee.</p>
</div>
</div>
<div class="sect3">
<h4 id="note-for-hazelcast-jet-version-0-5">3.4.7. Note for Hazelcast Jet version 0.5</h4>
<div class="paragraph">
<p>Hazelcast Jet&#8217;s version 0.5 was released with the Pipeline API still
under construction. We started from the simple case of batch jobs and we
support the major batch operation of (co)group-and-aggregate, but still
lack the API to define the windowing and watermark policies. Other,
non-aggregating operations aren&#8217;t sensitive to the difference between
finite and infinite streams and are ready to use. The major example here
is data enrichment
(<a href="#hash-join">hash join</a>),
which is essentially a mapping stream transformation. The next release
of Jet will feature a fully developed API that supports windowed
aggregation of infinite streams and we also plan to add more batch
transforms (<code>sort</code> and <code>distinct</code> for example).</p>
</div>
<div class="paragraph">
<p>On the other hand, Jet&#8217;s core has had full-fledged support for all of the
windows described above since version 0.4. You can refer to the
<a href="#under-the-hood">Under the Hood</a> chapter for details on how to create a
Core API DAG that does infinite stream aggregation.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="source-sink-connectors">3.5. Source and Sink Connectors</h3>
<div class="sect3">
<h4 id="overview">3.5.1. Overview</h4>
<div class="paragraph">
<p>In an <a href="#pipeline-api">earlier section</a> we briefly
listed the resources you can use as sources and sinks of a Jet job&#8217;s
data and where they fit in the general outline of a pipeline. Now let&#8217;s
revisit this topic in more detail.</p>
</div>
<div class="paragraph">
<p>Jet accesses data sources and sinks via its <em>connectors</em>. They are a
computation job&#8217;s point of contact with the outside world. Although the
connectors do their best to unify the various kinds of resources under
the same "data stream" paradigm, there are still many concerns that need
your attention.</p>
</div>
<div class="sect4">
<h5 id="is-it-infinite">Is it Infinite?</h5>
<div class="paragraph">
<p>The first decision when building a Jet computation job is whether it
will deal with finite or infinite data. A typical example of a finite
resource is a persistent storage system, whereas an infinite one is
usually like a FIFO queue, discarding old data. This is true both for
sources and sinks.</p>
</div>
<div class="paragraph">
<p>Finite data is handled by batch jobs and there are less concerns to deal
with. Examples of finite resources are the Hazelcast <code>IMap</code>/<code>ICache</code> and
the Hadoop Distributed File System (HDFS). In the infinite category the
most popular choice is Kafka, but a Hazelcast <code>IMap</code>/<code>ICache</code> can also
be used as an infinite source of update events (via the Event Journal
feature). You can also set up an <code>IMap</code>/<code>ICache</code> as a sink for an
infinite amount of data, either by ensuring that the size of the keyset
will be finite or by allowing the eviction of old entries.</p>
</div>
</div>
<div class="sect4">
<h5 id="is-it-replayable">Is it Replayable?</h5>
<div class="paragraph">
<p>Most finite data sources are replayable because they come from
persistent storage. You can easily replay the whole dataset. However, an
infinite data source may be of such nature that it can be consumed only
once. An example is the TCP socket connector. Such sources are bad at
fault tolerance: if anything goes wrong during the computation, it
cannot be retried.</p>
</div>
<div class="sect5">
<h6 id="does-it-support-checkpointing">Does it Support Checkpointing?</h6>
<div class="paragraph">
<p>It would be quite impractical if you could only replay an infinite data
stream from the very beginning. This is why you need <em>checkpointing</em>:
the ability of the stream source to replay its data from the point you
choose, discarding everything before it. Both Kafka and the Hazelcast
Event Journal support this.</p>
</div>
</div>
</div>
<div class="sect4">
<h5 id="is-it-distributed">Is it Distributed?</h5>
<div class="paragraph">
<p>A distributed computation engine prefers to work with distributed data
resources. If the resource is not distributed, all Jet members will have
to contend for access to a single endpoint. Kafka, HDFS, <code>IMap</code> and
<code>ICache</code> are all distributed. On the other hand, an <code>IList</code> is not; it iss stored on a single member and all append operations to it
must be serialized. When using it as a source, only one Jet member will
be pulling its data.</p>
</div>
<div class="paragraph">
<p>A <code>file</code> source/sink is another example of a non-distributed data
source, but with a different twist: it&#8217;s more of a "manually
distributed" resource. Each member will access its own local filesystem,
which means there will be no contention, but there will also be no
global coordination of the data. To use it as a source, you have to
prepare the files on each machine so each Jet member gets its part of
the data. When used as a sink, you&#8217;ll have to manually gather all the
pieces that Jet created around the cluster.</p>
</div>
</div>
<div class="sect4">
<h5 id="what-about-data-locality">What about Data Locality?</h5>
<div class="paragraph">
<p>If you&#8217;re looking to achieve record-breaking throughput for your
application, you&#8217;ll have to think carefully how close you can deliver
your data to the location where Jet will consume and process it. For
example, if your source is HDFS, you should align the topologies of the
Hadoop and Jet clusters so that each machine that hosts an HDFS member
also hosts a Jet member. Jet will automatically figure this out and
arrange for each member to consume only the slice of data stored
locally.</p>
</div>
<div class="paragraph">
<p>If you&#8217;re using <code>IMap</code>/<code>ICache</code> as data sources, you have two basic
choices: have Jet connect to a Hazelcast IMDG cluster, or use Jet itself
to host the data (since a Jet cluster is at the same time a Hazelcast
IMDG cluster). In the second case Jet will automatically ensure a
data-local access pattern, but there&#8217;s a caveat: if the Jet job causes
an error of unrestricted scope, such as <code>OutOfMemoryError</code> or
<code>StackOverflowError</code>, it will have unpredictable consequences for the
state of the whole Jet member, jeopardizing the integrity of the data
stored on it.</p>
</div>
</div>
<div class="sect4">
<h5 id="overview-of-sources-and-sinks">Overview of Sources and Sinks</h5>
<div class="paragraph">
<p>The table below gives you a high-level overview of all the source and
sink connectors we deliver with Jet. There are links to Javadoc and
code samples. The sections following this one present each connector in
more detail.</p>
</div>
<table class="tableblock frame-all grid-all spread">
<caption class="title">Table 1. Sources and Sinks</caption>
<colgroup>
<col style="width: 12%;">
<col style="width: 12%;">
<col style="width: 12%;">
<col style="width: 12%;">
<col style="width: 12%;">
<col style="width: 12%;">
<col style="width: 12%;">
<col style="width: 12%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Resource</th>
<th class="tableblock halign-left valign-top">Javadoc</th>
<th class="tableblock halign-left valign-top">Sample</th>
<th class="tableblock halign-left valign-top">Infinite?</th>
<th class="tableblock halign-left valign-top">Replayable?</th>
<th class="tableblock halign-left valign-top">Checkpointing?</th>
<th class="tableblock halign-left valign-top">Distributed?</th>
<th class="tableblock halign-left valign-top">Data Locality</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">IMap</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="http://docs.hazelcast.org/docs/jet/latest-dev/javadoc/com/hazelcast/jet/Sources.html#map-java.lang.String-com.hazelcast.query.Predicate-com.hazelcast.projection.Projection-">Source</a>
</p><p class="tableblock"><a href="http://docs.hazelcast.org/docs/jet/latest-dev/javadoc/com/hazelcast/jet/Sinks.html#map-java.lang.String-">Sink</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://github.com/hazelcast/hazelcast-jet-code-samples/blob/master/batch/hazelcast-connectors/src/main/java/MapSourceAndSink.java">Sample</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">❌</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">✅</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">❌</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">✅</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Src ✅
</p><p class="tableblock">Sink ❌</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">ICache</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="http://docs.hazelcast.org/docs/jet/latest-dev/javadoc/com/hazelcast/jet/Sources.html#cache-java.lang.String-">Source</a>
</p><p class="tableblock"><a href="http://docs.hazelcast.org/docs/jet/latest-dev/javadoc/com/hazelcast/jet/Sinks.html#cache-java.lang.String-">Sink</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://github.com/hazelcast/hazelcast-jet-code-samples/blob/master/batch/hazelcast-connectors/src/main/java/CacheSourceAndSink.java">Sample</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">❌</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">✅</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">❌</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">✅</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Src ✅
</p><p class="tableblock">Sink ❌</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">IMap in another cluster</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="http://docs.hazelcast.org/docs/jet/latest-dev/javadoc/com/hazelcast/jet/Sources.html#remoteMap-java.lang.String-com.hazelcast.client.config.ClientConfig-com.hazelcast.query.Predicate-com.hazelcast.projection.Projection-">Source</a>
</p><p class="tableblock"><a href="http://docs.hazelcast.org/docs/jet/latest-dev/javadoc/com/hazelcast/jet/Sinks.html#remoteMap-java.lang.String-com.hazelcast.client.config.ClientConfig-">Sink</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://github.com/hazelcast/hazelcast-jet-code-samples/blob/master/batch/hazelcast-connectors/src/main/java/RemoteMapSourceAndSink.java">Sample</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">❌</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">✅</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">❌</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">✅</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">✅</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">ICache in another cluster</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="http://docs.hazelcast.org/docs/jet/latest-dev/javadoc/com/hazelcast/jet/Sources.html#remoteCache-java.lang.String-com.hazelcast.client.config.ClientConfig-">Source</a>
</p><p class="tableblock"><a href="http://docs.hazelcast.org/docs/jet/latest-dev/javadoc/com/hazelcast/jet/Sinks.html#remoteCache-java.lang.String-com.hazelcast.client.config.ClientConfig-">Sink</a></p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">❌</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">✅</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">❌</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">✅</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">✅</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">IMap&#8217;s Event Journal</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="http://docs.hazelcast.org/docs/jet/latest-dev/javadoc/com/hazelcast/jet/Sources.html#mapJournal-java.lang.String-com.hazelcast.jet.function.DistributedPredicate-com.hazelcast.jet.function.DistributedFunction-boolean-">Source</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://github.com/hazelcast/hazelcast-jet-code-samples/blob/master/streaming/map-journal-source/src/main/java/MapJournalSource.java">Sample</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">✅</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">✅</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">✅</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">✅</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">✅</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">ICache&#8217;s Event Journal</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="http://docs.hazelcast.org/docs/jet/latest-dev/javadoc/com/hazelcast/jet/Sources.html#cacheJournal-java.lang.String-com.hazelcast.jet.function.DistributedPredicate-com.hazelcast.jet.function.DistributedFunction-boolean-">Source</a></p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">✅</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">✅</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">✅</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">✅</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">✅</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Event Journal of IMap in another cluster</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="http://docs.hazelcast.org/docs/jet/latest-dev/javadoc/com/hazelcast/jet/Sources.html#remoteMapJournal-java.lang.String-com.hazelcast.client.config.ClientConfig-com.hazelcast.jet.function.DistributedPredicate-com.hazelcast.jet.function.DistributedFunction-boolean-">Source</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://github.com/hazelcast/hazelcast-jet-code-samples/blob/master/streaming/map-journal-source/src/main/java/RemoteMapJournalSource.java">Sample</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">✅</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">✅</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">✅</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">✅</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">❌</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Event Journal of ICache in another cluster</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="http://docs.hazelcast.org/docs/jet/latest-dev/javadoc/com/hazelcast/jet/Sources.html#remoteCacheJournal-java.lang.String-com.hazelcast.client.config.ClientConfig-com.hazelcast.jet.function.DistributedPredicate-com.hazelcast.jet.function.DistributedFunction-boolean-">Source</a></p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">✅</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">✅</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">✅</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">✅</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">❌</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">IList</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="http://docs.hazelcast.org/docs/jet/latest-dev/javadoc/com/hazelcast/jet/Sources.html#list-java.lang.String-">Source</a>
</p><p class="tableblock"><a href="http://docs.hazelcast.org/docs/jet/latest-dev/javadoc/com/hazelcast/jet/Sinks.html#list-java.lang.String-">Sink</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://github.com/hazelcast/hazelcast-jet-code-samples/blob/master/batch/hazelcast-connectors/src/main/java/ListSourceAndSink.java">Sample</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">❌</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">✅</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">❌</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">❌</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">❌</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">IList in another cluster</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="http://docs.hazelcast.org/docs/jet/latest-dev/javadoc/com/hazelcast/jet/Sources.html#remoteList-java.lang.String-com.hazelcast.client.config.ClientConfig-">Source</a>
</p><p class="tableblock"><a href="http://docs.hazelcast.org/docs/jet/latest-dev/javadoc/com/hazelcast/jet/Sinks.html#remoteList-java.lang.String-com.hazelcast.client.config.ClientConfig-">Sink</a></p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">❌</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">✅</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">❌</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">❌</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">❌</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">HDFS</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="http://docs.hazelcast.org/docs/jet/latest-dev/javadoc/com/hazelcast/jet/HdfsSources.html">Source</a>
</p><p class="tableblock"><a href="http://docs.hazelcast.org/docs/jet/latest-dev/javadoc/com/hazelcast/jet/HdfsSinks.html">Sink</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://github.com/hazelcast/hazelcast-jet-code-samples/blob/master/batch/wordcount-hadoop/src/main/java/HadoopWordCount.java">Sample</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">❌</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">✅</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">❌</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">✅</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">✅</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Kafka</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="http://docs.hazelcast.org/docs/jet/latest-dev/javadoc/com/hazelcast/jet/KafkaSources.html">Source</a>
</p><p class="tableblock"><a href="http://docs.hazelcast.org/docs/jet/latest-dev/javadoc/com/hazelcast/jet/KafkaSinks.html">Sink</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://github.com/hazelcast/hazelcast-jet-code-samples/blob/master/streaming/kafka-source/src/main/java/KafkaSource.java">Source</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">✅</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">✅</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">✅</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">✅</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">❌</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Files</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="http://docs.hazelcast.org/docs/jet/latest-dev/javadoc/com/hazelcast/jet/Sources.html#files-java.lang.String-java.nio.charset.Charset-java.lang.String-">Source</a>
</p><p class="tableblock"><a href="http://docs.hazelcast.org/docs/jet/latest-dev/javadoc/com/hazelcast/jet/Sinks.html#files-java.lang.String-com.hazelcast.jet.function.DistributedFunction-java.nio.charset.Charset-boolean-">Sink</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://github.com/hazelcast/hazelcast-jet-code-samples/blob/master/batch/access-log-analyzer/src/main/java/AccessLogAnalyzer.java">Sample</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">❌</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">✅</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">❌</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">❌</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">✅</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">File Watcher</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="http://docs.hazelcast.org/docs/jet/latest-dev/javadoc/com/hazelcast/jet/Sources.html#fileWatcher-java.lang.String-java.nio.charset.Charset-java.lang.String-">Source</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://github.com/hazelcast/hazelcast-jet-code-samples/blob/master/core-api/streaming/access-stream-analyzer/src/main/java/AccessStreamAnalyzer.java">Sample (Core API)</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">✅</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">❌</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">❌</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">❌</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">✅</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">TCP Socket</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="http://docs.hazelcast.org/docs/jet/latest-dev/javadoc/com/hazelcast/jet/Sources.html#socket-java.lang.String-int-java.nio.charset.Charset-">Source</a>
</p><p class="tableblock"><a href="http://docs.hazelcast.org/docs/jet/latest-dev/javadoc/com/hazelcast/jet/Sinks.html#socket-java.lang.String-int-com.hazelcast.jet.function.DistributedFunction-java.nio.charset.Charset-">Sink</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://github.com/hazelcast/hazelcast-jet-code-samples/blob/master/streaming/socket-connector/src/main/java/StreamTextSocket.java">Source</a>
</p><p class="tableblock"><a href="https://github.com/hazelcast/hazelcast-jet-code-samples/blob/master/streaming/socket-connector/src/main/java/WriteTextSocket.java">Sink</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">✅</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">❌</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">❌</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">❌</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">❌</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Application Log</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="http://docs.hazelcast.org/docs/jet/latest-dev/javadoc/com/hazelcast/jet/Sinks.html#writeLogger-com.hazelcast.jet.function.DistributedFunction-">Sink</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://github.com/hazelcast/hazelcast-jet-code-samples/blob/master/streaming/enrichment/src/main/java/Enrichment.java">Sink</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">N/A</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">N/A</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">❌</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">❌</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">✅</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="sect3">
<h4 id="hazelcast-imdg">3.5.2. Hazelcast IMDG</h4>
<div class="sect4">
<h5 id="imap-and-icache">IMap and ICache</h5>
<div class="paragraph">
<p>Hazelcast IMDG&#8217;s <code>IMap</code> and <code>ICache</code> are very similar in the way Jet
uses them and largely interchangeable. <code>IMap</code> has a bit more features.
The simplest way to use them is as finite sources of their contents, but
if you enable the Event Journal on a map/cache, you&#8217;ll be able to use
it as a source of an infinite stream of update events
(<a href="#receive">see below</a>).</p>
</div>
<div class="paragraph">
<p>The most basic usage is very simple, here are snippets to use <code>IMap</code>
and <code>ICache</code> as a source and a sink:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">Pipeline p = p.create();
ComputeStage&lt;Entry&lt;String, Long&gt;&gt; stage =
        p.drawFrom(Sources.&lt;String, Long&gt;map("myMap"));
stage.drainTo(Sinks.map("myMap"));</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">Pipeline p = p.create();
ComputeStage&lt;Entry&lt;String, Long&gt;&gt; stage =
        p.drawFrom(Sources.&lt;String, Long&gt;cache("myCache"));
stage.drainTo(Sinks.cache("myCache"));</code></pre>
</div>
</div>
<div class="paragraph">
<p>In these snippets we draw from and drain to the same kind of structure,
but you can use any combination.</p>
</div>
<div class="sect5">
<h6 id="update-entries-in-imap">Update Entries in IMap</h6>
<div class="paragraph">
<p>When you use an <code>IMap</code> as a sink, instead of just pushing the data into
it you may have to merge the new with the existing data or delete the
existing data. Hazelcast Jet supports this with map-updating sinks which
rely on Hazelcast IMDG&#8217;s
<a href="http://docs.hazelcast.org/docs/3.9/manual/html-single/index.html#entry-processor">Entry Processor</a>
feature. An entry processor allows you to atomically execute a piece of
code against a map entry, in a data-local manner.</p>
</div>
<div class="paragraph">
<p>The updating sinks come in three variants:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><a href="http://docs.hazelcast.org/docs/jet/latest-dev/javadoc/com/hazelcast/jet/Sinks.html#mapWithMerging-java.lang.String-com.hazelcast.jet.function.DistributedFunction-com.hazelcast.jet.function.DistributedFunction-com.hazelcast.jet.function.DistributedBinaryOperator-"><code>mapWithMerging</code></a>,
where you provide a a function that computes the map value from the
stream item and a merging function that gets called if a value already
exists in the map. Here&#8217;s an example that concatenates string values:</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">    Pipeline pipeline = Pipeline.create();
    pipeline.drawFrom(Sources.map("mymap"))
            .drainTo(
                    Sinks.mapWithMerging(
                            "mymap",
                            item -&gt; item.getKey(),
                            item -&gt; item.getValue(),
                            (oldValue, newValue) -&gt; oldValue + newValue
                    )
            );</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
This operation is <strong>NOT</strong> lock-aware, it will process the entries no matter if they are locked or not. The reason for this behavior is that under the hood, we are applying the update function on keys in batches for performance reasons and this operation does not respect locked entries. So if you use this method on locked entries, your entries will be updated without respecting the lock and mutual exclusion contract will be broken. Use <code>mapWithEntryProcessor</code> if you need locking behavior which respects the locks on entries.
</td>
</tr>
</table>
</div>
</li>
<li>
<p><a href="http://docs.hazelcast.org/docs/jet/latest-dev/javadoc/com/hazelcast/jet/Sinks.html#mapWithUpdating-java.lang.String-com.hazelcast.jet.function.DistributedFunction-com.hazelcast.jet.function.DistributedBiFunction-"><code>mapWithUpdating</code></a>,
where you provide a single updating function that combines the roles of
the two functions in <code>mapWithMerging</code>. It will be called on the stream
item and the existing value, if any. Here&#8217;s an example that concatenates
string values:</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">    Pipeline pipeline = Pipeline.create();
    pipeline.drawFrom(Sources.map("mymap"))
            .drainTo(
                    Sinks.mapWithUpdating(
                            "mymap",
                            item -&gt; item.getKey(),
                            (oldValue, item) -&gt; (oldValue != null ? oldValue : "")
                                                 + item.getValue()
                    )
            );</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
This operation is <strong>NOT</strong> lock-aware, it will process the entries no matter if they are locked or not. The reason for this behavior is that under the hood, we are applying the merge function on keys in batches for performance reasons and this operation does not respect locked entries. So if you use this method on locked entries, your entries will be updated without respecting the lock and mutual exclusion contract will be broken. Use <code>mapWithEntryProcessor</code> if you need locking behavior which respects the locks on entries.
</td>
</tr>
</table>
</div>
</li>
<li>
<p><a href="http://docs.hazelcast.org/docs/jet/latest-dev/javadoc/com/hazelcast/jet/Sinks.html#mapWithEntryProcessor-java.lang.String-com.hazelcast.jet.function.DistributedFunction-com.hazelcast.jet.function.DistributedFunction-"><code>mapWithEntryProcessor</code></a>,
where you provide a function that returns a full-blown <code>EntryProcessor</code>
instance that will be submitted to the map. This is the most general
variant, but can&#8217;t use batching that the other variants do and thus has
a higher cost per item. You should use it only if you need a specialized
entry processor that can&#8217;t be expressed in terms of the other variants.
This example takes the values of the map and submits an entry processor
that increments the values by 5 :</p>
</li>
</ol>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">    Pipeline pipeline = Pipeline.create();
    pipeline.drawFrom(Sources.map("mymap"))
            .drainTo(
                    Sinks.mapWithEntryProcessor(
                            "mymap",
                            item -&gt; item.getKey(),
                            item -&gt; new IncrementEntryProcessor(5)
                    )
            );

    static class IncrementEntryProcessor implements EntryProcessor&lt;Integer, Integer&gt; {

        private int incrementBy;

        public IncrementEntryProcessor(int incrementBy) {
                this.incrementBy = incrementBy;
        }

        @Override
        public Object process(Entry&lt;Integer, Integer&gt; entry) {
                return entry.setValue(entry.getValue() + incrementBy);
        }

        @Override
        public EntryBackupProcessor&lt;Integer, Integer&gt; getBackupProcessor() {
                return null;
        }
    }</code></pre>
</div>
</div>
</div>
<div class="sect5">
<h6 id="access-an-external-cluster">Access an External Cluster</h6>
<div class="paragraph">
<p>To access a Hazelcast IMDG cluster separate from the Jet cluster, you
have to provide Hazelcast client configuration for the connection. In
this simple example we use programmatic configuration to draw from and
drain to remote <code>IMap</code> and <code>ICache</code>. Just for variety, we funnel the
data from <code>IMap</code> to <code>ICache</code> and vice versa:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">ClientConfig cfg = new ClientConfig();
cfg.getGroupConfig().setName("myGroup").setPassword("pAssw0rd");
cfg.getNetworkConfig().addAddress("node1.mydomain.com", "node2.mydomain.com");

Pipeline p = p.create();
ComputeStage&lt;Entry&lt;String, Long&gt;&gt; fromMap =
        p.drawFrom(Sources.&lt;String, Long&gt;remoteMap("inputMap", cfg));
ComputeStage&lt;Entry&lt;String, Long&gt;&gt; fromCache =
        p.drawFrom(Sources.&lt;String, Long&gt;remoteCache("inputCache", cfg));
fromMap.drainTo(Sinks.remoteCache("outputCache", cfg));
fromCache.drainTo(Sinks.remoteMap("outputMap", cfg));</code></pre>
</div>
</div>
<div class="paragraph">
<p>For a full discussion on how to configure your client connection, refer
to the
<a href="http://docs.hazelcast.org/docs/3.9/manual/html-single/index.html#configuring-java-client">Hazelcast IMDG documentation</a>
on this topic.</p>
</div>
</div>
<div class="sect5">
<h6 id="optimize-data-traffic-at-the-source">Optimize Data Traffic at the Source</h6>
<div class="paragraph">
<p>If your use case calls for some filtering and/or transformation of the
data you retrieve, you can optimize the traffic volume by providing a
filtering predicate and an arbitrary transformation function to the
source connector itself and they&#8217;ll get applied on the remote side,
before sending:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">Pipeline p = p.create();
p.drawFrom(Sources.&lt;String, Person, Integer&gt;remoteMap(
        "inputMap", clientConfig,
        e -&gt; e.getValue().getAge() &gt; 21,
        e -&gt; e.getValue().getAge()));</code></pre>
</div>
</div>
<div class="paragraph">
<p>The same optimization works on a local <code>IMap</code>, too, but has less impact.
However, Hazelcast IMDG goes a step further in optimizing your filtering
and mapping to a degree that matters even locally. If you don&#8217;t need
fully general functions, but can express your predicate via
<a href="http://docs.hazelcast.org/docs/latest/javadoc/com/hazelcast/query/Predicates.html"><code>Predicates</code></a>
or
<a href="http://docs.hazelcast.org/docs/latest/javadoc/com/hazelcast/query/PredicateBuilder.html"><code>PredicateBuilder</code></a>,
they will create a specialized predicate instance that can test the
object without deserializing it. Similarly, if the mapping you need is
of a constrained kind where you just extract one or more object fields
(attributes), you can specify a <em>projection</em> instead of a general
mapping lambda:
<a href="http://docs.hazelcast.org/docs/latest/javadoc/com/hazelcast/projection/Projections.html#singleAttribute-java.lang.String-"><code>Projections.singleAttribute()</code></a>
or <a href="http://docs.hazelcast.org/docs/latest/javadoc/com/hazelcast/projection/Projections.html#multiAttribute-java.lang.String&#8230;&#8203;-">
<code>Projections.multiAttribute()</code></a>.
These will extract the listed attributes without deserializing the whole
object. For these optimizations to work, however, your objects must
employ Hazelcast&#8217;s <a href="http://docs.hazelcast.org/docs/latest/manual/html-single/index.html#implementing-portable-serialization">portable serialization</a>.
They are especially relevant if the volume of data you need in the Jet
job is significantly less than the volume of the stored data.</p>
</div>
<div class="paragraph">
<p>Note that the above feature is not available on <code>ICache</code>. It is,
however, available on `ICache&#8217;s event journal, which we introduce next.</p>
</div>
</div>
<div class="sect5">
<h6 id="receive">Receive an Infinite Stream of Update Events</h6>
<div class="paragraph">
<p>You can use <code>IMap</code>/<code>ICache</code> as sources of infinite event streams. For
this to work you have to enable the Event Journal on your data
structure. This is a feature you set in the Jet/IMDG instance
configuration, which means you cannot change it while the cluster is
running.</p>
</div>
<div class="paragraph">
<p>This is how you enable the Event Journal on an <code>IMap</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">JetConfig cfg = new JetConfig();
cfg.getHazelcastConfig()
   .getMapEventJournalConfig("inputMap")
   .setEnabled(true)
   .setCapacity(1000) // how many events to keep before evicting
   .setTimeToLiveSeconds(10); // evict events older than this
JetInstance jet = Jet.newJetInstance(cfg);</code></pre>
</div>
</div>
<div class="paragraph">
<p>The default journal capacity is 10,000 and the default time-to-live is 0
(which means "unlimited"). Since the entire event journal is kept in
RAM, you should take care to adjust these values to match your use case.</p>
</div>
<div class="paragraph">
<p>The configuration API for <code>ICache</code> is identical:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">cfg.getHazelcastConfig()
   .getCacheEventJournalConfig("inputCache")
   .setEnabled(true)
   .setCapacity(1000)
   .setTimeToLiveSeconds(10);</code></pre>
</div>
</div>
<div class="paragraph">
<p>Once properly configured, you use Event Journal sources like this:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">Pipeline p = Pipeline.create();
ComputeStage&lt;Entry&lt;String, Long&gt;&gt; fromMap =
        p.drawFrom(Sources.&lt;String, Long&gt;mapJournal("inputMap", START_FROM_CURRENT));
ComputeStage&lt;Entry&lt;String, Long&gt;&gt; fromCache =
        p.drawFrom(Sources.&lt;String, Long&gt;cacheJournal("inputCache", START_FROM_CURRENT));</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>IMap</code> and <code>ICache</code> are on an equal footing here. The second argument,
<code>START_FROM_CURRENT</code> here, means "start receiving from events that occur
after the processing starts". If you specify <code>START_FROM_OLDEST</code>, you&#8217;ll
get all the events still on record.</p>
</div>
<div class="paragraph">
<p>This version of methods will only emit <code>ADDED</code> and <code>UPDATED</code> event
types. Also, it will map the event object to simple <code>Map.Entry</code> with the
key and new value. If you want to receive all types of events, use the
second version of methods:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">ComputeStage&lt;EventJournalMapEvent&lt;String, Long&gt;&gt; allFromMap =
        p.drawFrom(Sources.&lt;String, Long, EventJournalMapEvent&lt;String, Long&gt;&gt;mapJournal("inputMap",
                alwaysTrue(), identity(), START_FROM_CURRENT));
ComputeStage&lt;EventJournalCacheEvent&lt;String, Long&gt;&gt; allFromCache =
        p.drawFrom(Sources.&lt;String, Long, EventJournalCacheEvent&lt;String, Long&gt;&gt;cacheJournal("inputCache",
                alwaysTrue(), identity(), START_FROM_CURRENT));</code></pre>
</div>
</div>
<div class="paragraph">
<p>Note the type of the stream element: <code>EventJournalMapEvent</code> and
<code>EventJournalCacheEvent</code>. These are almost the same and have these
methods:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>getKey()</code></p>
</li>
<li>
<p><code>getOldValue()</code></p>
</li>
<li>
<p><code>getNewValue()</code></p>
</li>
<li>
<p><code>getType()</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The only difference is the return type of <code>getType()</code> which is specific
to each kind of structure and gives detailed insight into what kind of
event it reports. <em>Add</em>, <em>remove</em> and <em>update</em> are the basic ones, but
there are also <em>evict</em>, <em>clear</em>, <em>expire</em> and some others.</p>
</div>
<div class="paragraph">
<p>Finally, you can get all of the above from a map/cache in another
cluster, you just have to prepend <code>remote</code> to the source names and add a
<code>ClientConfig</code>, for example:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">ComputeStage&lt;Entry&lt;String, Long&gt;&gt; fromRemoteMap = p.drawFrom(
        Sources.&lt;String, Long&gt;remoteMapJournal("inputMap", clientConfig(), START_FROM_CURRENT));
ComputeStage&lt;Entry&lt;String, Long&gt;&gt; fromRemoteCache = p.drawFrom(
        Sources.&lt;String, Long&gt;remoteCacheJournal("inputCache", clientConfig(), START_FROM_CURRENT));</code></pre>
</div>
</div>
</div>
</div>
<div class="sect4">
<h5 id="ilist">IList</h5>
<div class="paragraph">
<p>Whereas <code>IMap</code> and <code>ICache</code> are the recommended choice of data sources
and sinks in Jet jobs, Jet supports <code>IList</code> purely for convenience
during prototyping, unit testing and similar non-production situations.
It is not a partitioned and distributed data structure and only one
cluster member has all the contents. In a distributed Jet job all the
members will compete for access to the single member holding it.</p>
</div>
<div class="paragraph">
<p>With that said, <code>IList</code> is very simple to use. Here&#8217;s an example how to
fill it with test data, consume it in a Jet job, dump its results into
another list, and fetch the results (we assume you already have a Jet
instance in the variable <code>jet</code>):</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">IList&lt;Integer&gt; inputList = jet.getList("inputList");
for (int i = 0; i &lt; 10; i++) {
    inputList.add(i);
}

Pipeline p = Pipeline.create();
p.drawFrom(Sources.&lt;Integer&gt;list("inputList"))
 .map(i -&gt; "item" + i)
 .drainTo(Sinks.list("resultList"));

jet.newJob(p).join();

IList&lt;String&gt; resultList = jet.getList("resultList");
System.out.println("Results: " + new ArrayList&lt;&gt;(resultList));</code></pre>
</div>
</div>
<div class="paragraph">
<p>You can access a list in an external cluster as well, by providing a
 <code>ClientConfig</code> object:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">ClientConfig clientConfig = new ClientConfig();
clientConfig.getGroupConfig().setName("myGroup").setPassword("pAssw0rd");
clientConfig.getNetworkConfig().addAddress("node1.mydomain.com", "node2.mydomain.com");

Pipeline p = Pipeline.create();
ComputeStage&lt;Object&gt; stage = p.drawFrom(Sources.remoteList("inputlist", clientConfig));
stage.drainTo(Sinks.remoteList("resultList", clientConfig));</code></pre>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="file-and-socket">3.5.3. File and Socket</h4>
<div class="paragraph">
<p>Hazelcast Jet provides a few connectors that have limited production
use, but are simple and can be very useful in an early rapid prototyping
phase. These are the connectors for the local file system and TCP/IP
sockets. They assume the data is in the form of plain text and
emit/receive data items which represent individual lines of text.</p>
</div>
<div class="paragraph">
<p>Some of these sources are infinite, but when used in a stream processing
job they don&#8217;t offer any fault tolerance because they are not
replayable. The finite variant of the file source is trivially
replayable: it just reads the same files again.</p>
</div>
<div class="sect4">
<h5 id="file">File</h5>
<div class="paragraph">
<p>These connectors work with a directory in the file system on each member.
Since each member has its own file system, these are to some extent
distributed sources and sinks; however there is no unified view of all
the data on all members. The user must manually distribute the source
data and collect the sink data from all the cluster members.</p>
</div>
<div class="sect5">
<h6 id="source">Source</h6>
<div class="paragraph">
<p>Jet provides two main ways to use the filesystem as a source:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><a href="http://docs.hazelcast.org/docs/jet/latest-dev/javadoc/com/hazelcast/jet/Sources.html#files-java.lang.String-java.nio.charset.Charset-java.lang.String-"><code>Sources.files()</code></a>: read all the files in a
directory and complete. The files should not change while being read.</p>
</li>
<li>
<p><a href="http://docs.hazelcast.org/docs/jet/latest-dev/javadoc/com/hazelcast/jet/Sources.html#fileWatcher-java.lang.String-java.nio.charset.Charset-java.lang.String-"><code>Sources.fileWatcher()</code></a>:
first emit the contents of the files present in the directory and then
continue watching the directory for further changes. Each time a
complete line of text appears in an existing or a newly created file,
the source emits another data item. The existing content in the files
should not change. This source completes only if the watched directory
is deleted.</p>
</li>
</ol>
</div>
</div>
<div class="sect5">
<h6 id="sink">Sink</h6>
<div class="paragraph">
<p>The
<a href="http://docs.hazelcast.org/docs/jet/latest-dev/javadoc/com/hazelcast/jet/Sinks.html#files-java.lang.String-com.hazelcast.jet.function.DistributedFunction-java.nio.charset.Charset-boolean-"><code>Sources.files()</code></a>
sink writes output to several files in the configured directory. Each
underlying processor writes to its own file to avoid contention.</p>
</div>
<div class="paragraph">
<p>The file sink only guarantees that items have been flushed to the
operating system on a snapshot, but it doesn&#8217;t guarantee that the
content is actually written to disk.</p>
</div>
<div class="paragraph">
<p>The socket source can be used to receive text input over a network socket.</p>
</div>
</div>
</div>
<div class="sect4">
<h5 id="socket">Socket</h5>
<div class="paragraph">
<p>These connectors open a blocking client TCP/IP socket and
send/receive data over it. As already noted, the data must be in the
form of lines of plain text.</p>
</div>
<div class="sect5">
<h6 id="source-2">Source</h6>
<div class="paragraph">
<p>Each underlying processor of the Socket Source connector opens its
own client socket and asks for data from it. The user supplies the
<code>host:port</code> connection details. The server side should ensure a
meaningful dispersion of data among all the connected clients, but
how it does it is outside of Jet&#8217;s control.</p>
</div>
<div class="paragraph">
<p>You can study a comprehensive
<a href="https://github.com/hazelcast/hazelcast-jet-code-samples/blob/master/streaming/socket-connector/src/main/java/StreamTextSocket.java">code sample</a>
including a sample socket server using Netty.</p>
</div>
</div>
<div class="sect5">
<h6 id="sink-2">Sink</h6>
<div class="paragraph">
<p>The Socket Sink also opens one client socket per processor and
pushes lines of text into it. It is the duty of the server-side
system to collect the data from all the concurrently connected
clients.</p>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="hdfs">3.5.4. HDFS</h4>
<div class="paragraph">
<p>The Hadoop Distributed File System is a production-worthy choice for
both a data source and sink in a batch computation job. It is a
distributed, replicated storage system that handles these concerns
automatically, exposing a simple unified view to the client.</p>
</div>
<div class="paragraph">
<p>The HDFS source and sink require a configuration object of type
<a href="https://hadoop.apache.org/docs/r2.7.3/api/org/apache/hadoop/mapred/JobConf.html">JobConf</a>
which supplies the input and output paths and formats. No actual
MapReduce job is created, this config is simply used to describe the
required inputs and outputs. The same <code>JobConf</code> instance can be shared
between the source and the sink.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">JobConf jobConfig = new JobConf();
jobConfig.setInputFormat(TextInputFormat.class);
jobConfig.setOutputFormat(TextOutputFormat.class);
TextOutputFormat.setOutputPath(jobConfig, "output-path");
TextInputFormat.addInputPath(jobConfig, "input-path");</code></pre>
</div>
</div>
<div class="paragraph">
<p>The word count pipeline can then be expressed using HDFS as follows</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-Java" data-lang="Java">Pipeline p = Pipeline.create();
p.drawFrom(HdfsSources.hdfs(jobConfig, (k, v) -&gt; v.toString()))
 .flatMap(line -&gt; traverseArray(delimiter.split(line.toLowerCase())).filter(w -&gt; !w.isEmpty()))
 .groupBy(wholeItem(), counting())
 .drainTo(HdfsSinks.hdfs(jobConfig));</code></pre>
</div>
</div>
<div class="sect4">
<h5 id="data-locality-when-reading">Data Locality When Reading</h5>
<div class="paragraph">
<p>Jet will split the input data across the cluster, with each processor
instance reading a part of the input. If the Jet nodes are running along
the HDFS datanodes, then Jet can make use of data locality by reading
the blocks locally where possible. This can bring a significant increase
in read speed.</p>
</div>
</div>
<div class="sect4">
<h5 id="output">Output</h5>
<div class="paragraph">
<p>Each processor will write to a different file in the output folder
identified by the unique processor id. The files will be in a temporary
state until the job is completed and will be committed when the job is
complete. For streaming jobs, they will be committed when the job is
cancelled. We have plans to introduce a rolling sink for HDFS in the future
to have better streaming support.</p>
</div>
</div>
<div class="sect4">
<h5 id="dealing-with-writables">Dealing with Writables</h5>
<div class="paragraph">
<p>Hadoop types implement their own serialization mechanism through the use
of <a href="https://hadoop.apache.org/docs/stable/api/org/apache/hadoop/io/Writable.html">Writable</a>.
Jet provides an adapter to register a <code>Writable</code> for
<a href="http://docs.hazelcast.org/docs/latest/manual/html-single/index.html#serialization">Hazelcast serialization</a>
without having to write additional serialization code. To use this
adapter, you can register your own <code>Writable</code> types by extending
<code>WritableSerializerHook</code> and
<a href="http://docs.hazelcast.org/docs/latest/manual/html-single/index.html#serialization-configuration-wrap-up">registering the hook</a>.</p>
</div>
</div>
<div class="sect4">
<h5 id="hadoop-jars-and-classpath">Hadoop JARs and Classpath</h5>
<div class="paragraph">
<p>When submitting JARs along with a Job, sending Hadoop JARs should be
avoided and instead Hadoop JARs should be present on the classpath of
the running members. Hadoop JARs contain some JVM hooks and can keep
lingering references inside the JVM long after the job has ended,
causing memory leaks.</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="kafka">3.5.5. Kafka</h4>
<div class="paragraph">
<p>Apache Kafka is a production-worthy choice of both source and sink
for infinite stream processing jobs. It supports fault tolerance and
snapshotting. The basic paradigm is that of a distributed
publish/subscribe message queue. Jet&#8217;s Kafka Source subscribes to a
Kafka topic and the sink publishes events to a Kafka topic.</p>
</div>
<div class="paragraph">
<p>The following code will consume from topics <code>t1</code> and <code>t2</code> and then write to
<code>t3</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">Properties props = new Properties();
props.setProperty("bootstrap.servers", "localhost:9092");
props.setProperty("key.serializer", StringSerializer.class.getCanonicalName());
props.setProperty("key.deserializer", StringDeserializer.class.getCanonicalName());
props.setProperty("value.serializer", IntegerSerializer.class.getCanonicalName());
props.setProperty("value.deserializer", IntegerDeserializer.class.getCanonicalName());
props.setProperty("auto.offset.reset", "earliest");

p.drawFrom(KafkaSources.kafka(props, "t1", "t2"))
 .drainTo(KafkaSinks.kafka(props, "t3"));</code></pre>
</div>
</div>
<div class="sect4">
<h5 id="using-kafka-as-a-source">Using Kafka as a Source</h5>
<div class="paragraph">
<p>The Kafka source emits entries of type <code>Map.Entry&lt;Key,Value&gt;</code> which
can be transformed using an optional mapping function. It never
completes. The job will end only if explicitly cancelled or aborted
due to an error.</p>
</div>
<div class="paragraph">
<p>Internally Jet creates one <code>KafkaConsumer</code> per <code>Processor</code> instance
using the supplied properties. Jet uses manual partition assignment
to arrange the available Kafka partitions among the available
processors and will ignore the <code>group.id</code> property.</p>
</div>
<div class="paragraph">
<p>Currently there is a requirement that the global parallelism of the
Kafka source be at most the number of partitions you are subscribing
to. The local parallelism of the Kafka source is 2 and if your Jet
cluster has 4 members, this means that a minimum of 8 Kafka
partitions must be available.</p>
</div>
<div class="paragraph">
<p>If any new partitions are added while the job is running, Jet will
automatically assign them to the existing processors and consume
them from the beginning.</p>
</div>
</div>
<div class="sect4">
<h5 id="processing-guarantees">Processing Guarantees</h5>
<div class="paragraph">
<p>The Kafka source supports snapshots. Upon each snapshot it saves the
current offset for each partition. When the job is restarted from a
snapshot, the source can continue reading from the saved offset.</p>
</div>
<div class="paragraph">
<p>If snapshots are disabled, the source will commit the offset of the
last record it read to the Kafka cluster. Since the fact that the
source read an item doesn&#8217;t mean that the whole Jet pipeline
processed it, this doesn&#8217;t guarantee against data loss.</p>
</div>
</div>
<div class="sect4">
<h5 id="using-kafka-as-a-sink">Using Kafka as a Sink</h5>
<div class="paragraph">
<p>The Kafka sink creates one <code>KafkaProducer</code> per cluster member and
shares it among all the sink processors on that member. You can
provide a mapping function that transforms the items the sink
receives into `ProducerRecord`s.</p>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="practical-considerations">3.6. Practical Considerations</h3>
<div class="sect3">
<h4 id="remember-that-a-jet-job-is-distributed">3.6.1. Remember that a Jet Job is Distributed</h4>
<div class="paragraph">
<p>The API to submit a job to Jet is in a way deceptively simple: "just
call a method." As long as you&#8217;re toying around with Jet instances
started locally in a single JVM, everything will indeed work. However,
as soon as you try to deploy to an actual cluster, you&#8217;ll face the
consequences of the fact that your job definition must travel over the
wire to reach remote members which don&#8217;t have your code on their
classpath.</p>
</div>
<div class="paragraph">
<p>Your custom code must be packaged with the Jet job. For simple examples
you can have everything in a single class and use code like this:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">class JetExample {
    static Job createJob(JetInstance jet) {
        JobConfig jobConfig = new JobConfig();
        jobConfig.addClass(JetExample.class);
        return jet.newJob(createPipeline(), jobConfig);
    }
    ...
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>If you forget to do this, or don&#8217;t add all the classes involved, you
may get a quite confusing exception:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-text" data-lang="text">java.lang.ClassCastException:
cannot assign instance of java.lang.invoke.SerializedLambda
to field com.hazelcast.jet.core.ProcessorMetaSupplier$1.val$addressToSupplier
of type com.hazelcast.jet.function.DistributedFunction
in instance of com.hazelcast.jet.core.ProcessorMetaSupplier$1</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>SerializedLambda</code> actually declares <code>readResolve()</code>, which would
normally transform it into an instance of the correct functional
interface type. If this method throws an exception, Java doesn&#8217;t report
it but keeps the <code>SerializedLambda</code> instance and continues the
deserialization. Later in the process it will try to assign it to
a field whose type is the target type of the lambda
(<code>DistributedFunction</code> in the example above) and at that point it will
fail with the <code>ClassCastException</code>. So, if you see this kind of error,
double-check the list of classes you have added to the Jet job.</p>
</div>
<div class="paragraph">
<p>For more complex jobs it will become more practical to first package the
job in a JAR and then use a command-line utility to submit it, as
explained next.</p>
</div>
</div>
<div class="sect3">
<h4 id="submit-a-job-from-the-command-line">3.6.2. Submit a Job from the Command Line</h4>
<div class="paragraph">
<p>Jet comes with the <code>jet-submit.sh</code> script, which allows you to submit a
Jet job packaged in a JAR file. You can find it in the Jet distribution
zipfile, in the <code>bin</code> directory. On Windows use <code>jet-submit.bat</code>. To use
it, follow these steps:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Write your <code>main()</code> method and your Jet code the usual way, except
for calling
<a href="http://docs.hazelcast.org/docs/jet/latest-dev/javadoc/com/hazelcast/jet/server/JetBootstrap.html"><code>JetBootstrap.getInstance()</code></a>
to acquire a Jet client instance (instead of <code>Jet.newJetClient()</code>).</p>
</li>
<li>
<p>Create a runnable JAR which declares its <code>Main-Class</code> in</p>
</li>
<li>
<p><code>MANIFEST.MF</code>.</p>
</li>
<li>
<p>Run your JAR, but instead of <code>java -jar jetjob.jar</code> use <code>jet-submit.sh
jetjob.jar</code>.</p>
</li>
<li>
<p>The script will create a Jet client and configure it from
<code>hazelcast-client.xml</code> located in the <code>config</code> directory of Jet&#8217;s
distribution. Adjust that file to suit your needs.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>For example, write a class like this:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">public class CustomJetJob {
    public static void main(String[] args) {
        JetInstance jet = JetBootstrap.getInstance();
        jet.newJob(buildPipeline()).join();
    }

    static Pipeline buildPipeline() {
        // ...
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>After building the JAR, submit the job:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>$ jet-submit.sh jetjob.jar</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="watch-out-for-capturing-lambdas">3.6.3. Watch out for Capturing Lambdas</h4>
<div class="paragraph">
<p>A typical Jet pipeline involves lambda expressions. Since the whole
pipeline definition must be serialized to be sent to the cluster, the
lambda expressions must be serializable as well. The Java standard
provides an essential building block: if the static type of the lambda
is a subtype of <code>Serializable</code>, you will automatically get a lambda
instance that can serialize itself.</p>
</div>
<div class="paragraph">
<p>None of the functional interfaces in the JDK extend <code>Serializable</code>, so
we had to mirror the entire <code>java.util.function</code> package in our own
<code>com.hazelcast.jet.function</code> with all the interfaces subtyped and made
<code>Serializable</code>. Each subtype has the name of the original with
<code>Distributed</code> prepended. For example, a <code>DistributedFunction</code> is just
like <code>Function</code>, but implements <code>Serializable</code>. We use these types
everywhere in the Pipeline API.</p>
</div>
<div class="paragraph">
<p>As always with this kind of magic, auto-serializability of lambdas has its
flipside: it is easy to overlook what&#8217;s going on.</p>
</div>
<div class="paragraph">
<p>If the lambda references a variable in the outer scope, the variable is
captured and must also be serializable. If it references an instance
variable of the enclosing class, it implicitly captures <code>this</code> so the
entire class will be serialized. For example, this will fail because
<code>JetJob</code> doesn&#8217;t implement <code>Serializable</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">class JetJob {
    private String instanceVar;

    Pipeline buildPipeline() {
        Pipeline p = Pipeline.create();
        p.drawFrom(readList("input"))
         // Refers to instanceVar, capturing "this", but JetJob is not
         // Serializable so this call will fail.
         .filter(item -&gt; item.equals(instanceVar));
        return p;
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Just adding <code>implements Serializable</code> to <code>JetJob</code> would be a viable
workaround here. However, consider something just a bit different:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">class JetJob {
    private String instanceVar;
    private OutputStream fileOut; // a non-serializable field

    Pipeline buildPipeline() {
        Pipeline p = Pipeline.create();
        p.drawFrom(readList("input"))
         // Refers to instanceVar, capturing "this". JetJob is declared
         // Serializable, but has a non-serializable field and this fails.
         .filter(item -&gt; item.equals(instanceVar));
        return p;
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Even though we never refer to <code>fileOut</code>, we are still capturing the
entire <code>JetJob</code> instance. We might mark <code>fileOut</code> as <code>transient</code>, but
the sane approach is to avoid referring to instance variables of the
surrounding class. This can be simply achieved by assigning to a local
variable, then referring to that variable inside the lambda:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">class JetJob {
    private String instanceVar;

    Pipeline buildPipeline() {
        Pipeline p = Pipeline.create();
        String findMe = instanceVar;
        p.drawFrom(readList("input"))
         // By referring to the local variable "findMe" we avoid
         // capturing "this" and the job runs fine.
         .filter(item -&gt; item.equals(findMe));
        return p;
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Another common pitfall is capturing an instance of <code>DateTimeFormatter</code>
or a similar non-serializable class:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">DateTimeFormatter formatter =
        DateTimeFormatter.ofPattern("HH:mm:ss.SSS")
                         .withZone(ZoneId.systemDefault());
Pipeline p = Pipeline.create();
ComputeStage&lt;Long&gt; src = p.drawFrom(readList("input"));
// Captures the non-serializable formatter, so this fails
src.map((Long tstamp) -&gt; formatter.format(Instant.ofEpochMilli(tstamp)));</code></pre>
</div>
</div>
<div class="paragraph">
<p>Sometimes we can get away by using one of the preconfigured formatters
available in the JDK:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">// Accesses the static final field ISO_LOCAL_TIME. Static fields are
// not subject to lambda capture, they are dereferenced when the code
// runs on the target machine.
src.map((Long tstamp) -&gt;
    DateTimeFormatter.ISO_LOCAL_TIME.format(
        Instant.ofEpochMilli(tstamp).atZone(ZoneId.systemDefault())));</code></pre>
</div>
</div>
<div class="paragraph">
<p>This refers to a <code>static final</code> field in the JDK, so the instance is
available on any JVM. A similar approach is to declare our own <code>static
final</code> field; however in that case we must add the declaring class as a
job resource:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">class JetJob {

    // Our own static field
    private static final DateTimeFormatter formatter =
            DateTimeFormatter.ofPattern("HH:mm:ss.SSS")
                             .withZone(ZoneId.systemDefault());

    Pipeline buildPipeline() {
        Pipeline p = Pipeline.create();
        ComputeStage&lt;Long&gt; src = p.drawFrom(readList("input"));
        src.map((Long tstamp) -&gt; formatter.format(Instant.ofEpochMilli(tstamp)));
        return p;
    }

    // The job will fail unless we attach the JetJob class as a
    // resource, making the formatter instance available at the
    // target machine.
    void runJob(JetInstance jet) throws Exception {
        JobConfig c = new JobConfig();
        c.addClass(JetJob.class);
        jet.newJob(buildPipeline(), c).join();
    }
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="standard-java-serialization-is-slow">3.6.4. Standard Java Serialization is Slow</h4>
<div class="paragraph">
<p>When it comes to serializing the description of a Jet job, performance
is not critical. However, for the data passing through the pipeline,
the cost of the serialize-deserialize cycle can easily dwarf the cost of
actual data transfer, especially on high-end LANs typical for data
centers. In this context the performance of Java serialization is so
poor that it regularly becomes the bottleneck. This is due to its heavy
usage of reflection, overheads in the serialized form, etc.</p>
</div>
<div class="paragraph">
<p>Since Hazelcast IMDG faced the same problem a long time ago, we have
mature support for optimized custom serialization and in Jet you can
use it for stream data. In essence, you must implement a
<code>StreamSerializer</code> for the objects you emit from your processors and
register it in Jet configuration:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">SerializerConfig serializerConfig = new SerializerConfig()
        .setImplementation(new MyItemSerializer())
        .setTypeClass(MyItem.class);
JetConfig config = new JetConfig();
config.getHazelcastConfig().getSerializationConfig()
      .addSerializerConfig(serializerConfig);
JetInstance jet = Jet.newJetInstance(config);</code></pre>
</div>
</div>
<div class="paragraph">
<p>Consult the chapter on
<a href="http://docs.hazelcast.org/docs/latest/manual/html-single/index.html#custom-serialization">custom serialization</a>
in Hazelcast IMDG&#8217;s reference manual for more details.</p>
</div>
<div class="paragraph">
<p>Note the limitation implied here: the serializers must be registered
with Jet on startup because this is how it is supported in Hazelcast
IMDG. There is a plan to improve this and allow serializers to be
registered on individual Jet jobs.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="logging-and-debugging">3.7. Logging and Debugging</h3>
<div class="sect3">
<h4 id="configuring-logging">3.7.1. Configuring Logging</h4>
<div class="paragraph">
<p>Jet, like Hazelcast IMDG does not depend on a specific logging framework
and has built-in adapters for a variety of logging frameworks. You can
also write a new adapter to integrate with loggers Jet doesn&#8217;t natively
support. To use one of the built-in adapters, set the
<code>hazelcast.logging.type</code> property to one of the following:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>jdk</code>: java.util.logging (default)</p>
</li>
<li>
<p><code>log4j</code>: Apache Log4j</p>
</li>
<li>
<p><code>log4j2</code>: Apache Log4j 2</p>
</li>
<li>
<p><code>slf4j</code>: SLF4J</p>
</li>
<li>
<p><code>none</code>: Turn off logging</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>For example, to configure Jet to use Log4j, you can do one of the following:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">System.setProperty("hazelcast.logging.type", "log4j");</code></pre>
</div>
</div>
<div class="paragraph">
<p>or</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">JetConfig config = new JetConfig() ;
config.getHazelcastConfig().setProperty( "hazelcast.logging.type", "log4j" );</code></pre>
</div>
</div>
<div class="paragraph">
<p>For more detailed information about how to configure logging, please
refer to the
<a href="http://docs.hazelcast.org/docs/latest/manual/html-single/index.html#logging-configuration">IMDG reference manual</a>.</p>
</div>
</div>
<div class="sect3">
<h4 id="inspecting-output-of-individual-stages">3.7.2. Inspecting Output of Individual Stages</h4>
<div class="paragraph">
<p>When building pipelines, it&#8217;s often useful to see what the  output of
each stage is. This can be achieved by using the
<a href="http://docs.hazelcast.org/docs/jet/latest-dev/javadoc/com/hazelcast/jet/ComputeStage.html#peek--"><code>peek()</code></a>
stage. For example:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">p.drawFrom(Sources.&lt;Long, String&gt;map(...))
   .flatMap(e -&gt; traverseArray(delimiter.split(e.getValue().toLowerCase())))
   .filter(word -&gt; !word.isEmpty())
   .groupBy(wholeItem(), counting())
   .peek()
   .drainTo(Sinks.map(COUNTS));</code></pre>
</div>
</div>
<div class="paragraph">
<p>In this pipeline, the output of the <code>groupBy</code> stage will be logged using
the configured logging framework:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>16:05:29,650  INFO || - [com.hazelcast.jet.impl.processor.PeekWrappedP.groupByKey.cd6373be.stage2#0] hz._hzInstance_1_jet.jet.cooperative.thread-1 - [10.0.1.3]:5701 [jet] [0.6-SNAPSHOT] Output to 0: accusers=6
16:05:29,650  INFO || - [com.hazelcast.jet.impl.processor.PeekWrappedP.groupByKey.cd6373be.stage2#0] hz._hzInstance_1_jet.jet.cooperative.thread-1 - [10.0.1.3]:5701 [jet] [0.6-SNAPSHOT] Output to 0: mutability=2
16:05:29,650  INFO || - [com.hazelcast.jet.impl.processor.PeekWrappedP.groupByKey.cd6373be.stage2#0] hz._hzInstance_1_jet.jet.cooperative.thread-1 - [10.0.1.3]:5701 [jet] [0.6-SNAPSHOT] Output to 0: lovely=53</code></pre>
</div>
</div>
<div class="paragraph">
<p>The logger name of
<code>com.hazelcast.jet.impl.processor.PeekWrappedP.groupByKey.cd6373be.stage2#0</code>
can be decomposed as follows:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>com.hazelcast.jet.impl.processor.PeekWrappedP</code>: class of the processor
writing the log message</p>
</li>
<li>
<p><code>groupByKey.cd6373be.stage2</code>: Name of the vertex the processor belongs
to</p>
</li>
<li>
<p><code>#0</code>: the unique index (per vertex) of the processor instance</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Keep in mind that this can create a large amount of output when dealing
with large volumes of data, and should strictly be used in a
non-production environment.</p>
</div>
<div class="paragraph">
<p>For more information about logging when using the Core API, see the
<a href="#inspecting-processor-input-and-output">Best Practices</a>
section.</p>
</div>
</div>
</div>
</div>
</div>
</div>
<div id="footer">
<div id="footer-text">
Last updated 2018-02-28 16:54:25 MSK
</div>
</div>
</body>
</html>