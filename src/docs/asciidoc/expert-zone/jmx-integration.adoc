= JMX and Management Center Integration

== Configuration

The metrics collection is enabled by default. You can configure it
using the `hazelcast-jet.xml` file:

[source,xml,subs="attributes+"]
----
<metrics enabled="true" jmxEnabled="true">
    <!-- The number of seconds the metrics will be retained on
         the instance -->
    <retention-seconds>5</retention-seconds>

    <!-- The metrics collection interval in seconds -->
    <collection-interval-seconds>5</collection-interval-seconds>

    <!-- whether metrics should be collected for data structures.
         Metrics collection can have some overhead if there is a
         large number of data structures -->
    <metrics-for-data-structures>false</metrics-for-data-structures>
</metrics>
----

or using `JetConfig` object:

[source]
----
include::{javasource}/JmxIntegration.java[tag=s1]
----

== Exposed JMX MBeans

Jet exposes metrics using the JVM's standard JMX interface. You can use
tools such as Java Mission Control or JConsole to display them. All
Jet-related beans are stored under
`com.hazelcast.jet/Metrics/<instanceName>/` node.

=== List of the Beans and their Attributes

[cols="2,3"]
|===
|Property|Description

|`cooperativeWorker-<N>`

|* **iterationCount**: The total number of iterations the driver of tasklets in cooperative
thread N makes. It should increase by at least 250 iterations/s. Lower
value means some of the cooperative processors blocks for too long.

* **taskletCount**:The number of assigned tasklets to cooperative thread N

|*Job-related metrics, nested under* +
`job=<jobId>` +
&nbsp;&nbsp; `/exec=<executionId>` +
&nbsp;&nbsp; `/vertex=<vertexName>`
|All job-related metrics are nested under these nodes. If the vertex is
a source or a sink, additionally `source=true` or `sink=true` is
inserted to the tree.

|`/ordinal=<N>`

|This MBean groups metrics for input or output ordinal _N_.

Values in this section are 0 for non-distributed edges, they only
account for data actually transmitted over the network between members.
This numbers include watermarks, snapshot barriers etc.

* **distributedBytesIn**: Total number of bytes received from remote
members

* **distributedBytesOut**: Total number of bytes sent to remote members

* **distributedItemsIn**: Total number of items received from remote
members

* **distributedItemsOut**: Total number of items sent to remote members

|`/proc=N`
|This MBean groups metrics for processor instance _N_. The _N_ is
global processor index. Processor is the parallel worker doing the work
of the vertex.

* **lastReceivedWm**: The value of watermark received last

* **queuesCapacity**: The total capacity of input queues +
* **queuesSize**: The total number of items waiting in input queues

All input queues for all edges to the processor are added in the above
two metrics. If size is close to capacity, backpressure is applied and
this processor is a bottleneck.

If input edges are of different priority, edges with higher priority
are reflected first. After these are completed, the next priority edges
are reflected etc.

|`/proc=N` +
&nbsp;&nbsp; `/ordinal=<M>`
|This MBean groups metrics pertaining to processor instance _N_ and
input or output edge _M_. _M_ can be a number, or it can be `snapshot`
for output items written to state snapshot.

* **emittedCount**: The number of emitted items. This number includes
watermarks, snapshot barriers etc. Unlike `distributedItemsOut`, it
includes items emitted items to local processors.

* **receivedCount**: The number of received items. This number does not
include watermarks, snapshot barriers etc. It's the number of items the
`Processor.process` method will receive.

* **receivedBatches**: The number of received batches.
`Processor.process` receives a batch of items at a time, this is the
number of such batches. By dividing _receivedCount_ by
_receivedBatches_, you get the average batch size. It will be 1 under
low load.

|===

== Jet Management Center

The above metrics are also exposed in the Jet Management Center. Please
refer to its reference manual for more information.
